{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18f85155",
   "metadata": {
    "papermill": {
     "duration": 0.005846,
     "end_time": "2025-05-07T02:05:00.065034",
     "exception": false,
     "start_time": "2025-05-07T02:05:00.059188",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Import and Configuration Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "689dcb46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T02:05:00.075281Z",
     "iopub.status.busy": "2025-05-07T02:05:00.074909Z",
     "iopub.status.idle": "2025-05-07T02:05:05.755731Z",
     "shell.execute_reply": "2025-05-07T02:05:05.755070Z"
    },
    "papermill": {
     "duration": 5.687657,
     "end_time": "2025-05-07T02:05:05.757308",
     "exception": false,
     "start_time": "2025-05-07T02:05:00.069651",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import json\n",
    "import optuna\n",
    "from functools import partial\n",
    "from joblib import Memory\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01783e65",
   "metadata": {
    "papermill": {
     "duration": 0.004406,
     "end_time": "2025-05-07T02:05:05.766661",
     "exception": false,
     "start_time": "2025-05-07T02:05:05.762255",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Configuration Class\n",
    "\n",
    "Configuration class  \n",
    "Defines key parameters for the model:\n",
    "- TARGET: The target variable to predict ('AWS' - Accumulated Water Sum)\n",
    "- USE_LAG_FEATURES: Whether to use lagged values of the target as features\n",
    "- USE_ROLLING_STATISTICS: Whether to include rolling mean and std as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb3671e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T02:05:05.776508Z",
     "iopub.status.busy": "2025-05-07T02:05:05.776172Z",
     "iopub.status.idle": "2025-05-07T02:05:05.779782Z",
     "shell.execute_reply": "2025-05-07T02:05:05.779195Z"
    },
    "papermill": {
     "duration": 0.009852,
     "end_time": "2025-05-07T02:05:05.780990",
     "exception": false,
     "start_time": "2025-05-07T02:05:05.771138",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup memory cache\n",
    "cache_dir = './joblib_cache'\n",
    "memory = Memory(cache_dir, verbose=0)\n",
    "\n",
    "class Config:\n",
    "    TARGET = 'AWS'\n",
    "    USE_LAG_FEATURES = True\n",
    "    USE_ROLLING_STATISTICS = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c4f4bc",
   "metadata": {
    "papermill": {
     "duration": 0.004234,
     "end_time": "2025-05-07T02:05:05.789848",
     "exception": false,
     "start_time": "2025-05-07T02:05:05.785614",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Paths and Feature Selection\n",
    "\n",
    "Paths and Feature Selection  \n",
    "- Setting up the base path for the dataset  \n",
    "- Defining the months and folds for cross-validation  \n",
    "- Selected features represent atmospheric variables most relevant for prediction  \n",
    "- DEVICE configuration for CPU/GPU usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "469e04d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T02:05:05.799356Z",
     "iopub.status.busy": "2025-05-07T02:05:05.799140Z",
     "iopub.status.idle": "2025-05-07T02:05:05.850228Z",
     "shell.execute_reply": "2025-05-07T02:05:05.849564Z"
    },
    "papermill": {
     "duration": 0.057194,
     "end_time": "2025-05-07T02:05:05.851404",
     "exception": false,
     "start_time": "2025-05-07T02:05:05.794210",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Paths\n",
    "base_path = \"/kaggle/input/ai-dataimputedataset-k-fold\"\n",
    "months = [\"2019-04\", \"2019-10\", \"2020-04\", \"2020-10\"]\n",
    "folds = [f\"fold_{i}\" for i in range(1, 6)]\n",
    "\n",
    "# Define selected features\n",
    "selected_features = [\n",
    "    'TCW', 'TCLW', 'R250', 'R500', 'R850', 'U850', 'V850', 'EWSS', 'KX', 'CAPE', 'SSHF', 'PEV'\n",
    "]\n",
    "\n",
    "# Device configuration\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Model parameters - now configurable via Optuna\n",
    "MODEL_CONFIG = {\n",
    "    \"04\": {\"BATCH_SIZE\": 64, \"EPOCHS\": 10},\n",
    "    \"10\": {\"BATCH_SIZE\": 128, \"EPOCHS\": 15},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd195ad7",
   "metadata": {
    "papermill": {
     "duration": 0.004292,
     "end_time": "2025-05-07T02:05:05.860376",
     "exception": false,
     "start_time": "2025-05-07T02:05:05.856084",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Feature Engineering Functions\n",
    "\n",
    "### Lag Feature Creation\n",
    "\n",
    "This cached function creates time-lagged features of the target variable:\n",
    "- Important for time series forecasting as past values help predict future values  \n",
    "- Groups by ROW, COL to maintain spatial context  \n",
    "- Returns test dataframe with added lag features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0e5bffe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T02:05:05.870288Z",
     "iopub.status.busy": "2025-05-07T02:05:05.869931Z",
     "iopub.status.idle": "2025-05-07T02:05:05.874756Z",
     "shell.execute_reply": "2025-05-07T02:05:05.874212Z"
    },
    "papermill": {
     "duration": 0.010948,
     "end_time": "2025-05-07T02:05:05.875850",
     "exception": false,
     "start_time": "2025-05-07T02:05:05.864902",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create lag features\n",
    "@memory.cache\n",
    "def create_lag_features(train_df, test_df, target_column, lag_steps, groupby_cols):\n",
    "    \"\"\"Create lag features for the target column\"\"\"\n",
    "    result_df = test_df.copy()\n",
    "    \n",
    "    # Combine train and test for continuous time series\n",
    "    combined_df = pd.concat([train_df, test_df]).sort_values('DATETIME').reset_index(drop=True)\n",
    "    \n",
    "    # Create lag features\n",
    "    for lag in lag_steps:\n",
    "        combined_df[f'{target_column}_lag{lag}'] = combined_df.groupby(groupby_cols)[target_column].shift(lag)\n",
    "    \n",
    "    # Extract only the test portion with lag features\n",
    "    result_df = combined_df.iloc[len(train_df):].reset_index(drop=True)\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba89053",
   "metadata": {
    "papermill": {
     "duration": 0.004405,
     "end_time": "2025-05-07T02:05:05.884796",
     "exception": false,
     "start_time": "2025-05-07T02:05:05.880391",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Rolling Statistics Creation\n",
    "\n",
    "Creates rolling window statistics (mean and standard deviation):\n",
    "- Captures trends and volatility in the time series  \n",
    "- Uses different window sizes to capture short and long-term patterns  \n",
    "- Groups by ROW, COL to maintain spatial relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b48b43b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T02:05:05.894465Z",
     "iopub.status.busy": "2025-05-07T02:05:05.894255Z",
     "iopub.status.idle": "2025-05-07T02:05:05.899312Z",
     "shell.execute_reply": "2025-05-07T02:05:05.898732Z"
    },
    "papermill": {
     "duration": 0.011265,
     "end_time": "2025-05-07T02:05:05.900515",
     "exception": false,
     "start_time": "2025-05-07T02:05:05.889250",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create rolling statistics\n",
    "@memory.cache\n",
    "def create_rolling_statistics(train_df, test_df, target_column, window_sizes, groupby_cols):\n",
    "    \"\"\"Create rolling statistics features for the target column\"\"\"\n",
    "    result_df = test_df.copy()\n",
    "    \n",
    "    # Combine train and test for continuous rolling stats\n",
    "    combined_df = pd.concat([train_df, test_df]).sort_values('DATETIME').reset_index(drop=True)\n",
    "    \n",
    "    # Create rolling features\n",
    "    for window in window_sizes:\n",
    "        # Rolling mean\n",
    "        combined_df[f'{target_column}_rollmean_{window}'] = combined_df.groupby(groupby_cols)[target_column].transform(\n",
    "            lambda x: x.rolling(window, min_periods=1).mean())\n",
    "        # Rolling std\n",
    "        combined_df[f'{target_column}_rollstd_{window}'] = combined_df.groupby(groupby_cols)[target_column].transform(\n",
    "            lambda x: x.rolling(window, min_periods=1).std())\n",
    "    \n",
    "    # Extract only the test portion with rolling features\n",
    "    result_df = combined_df.iloc[len(train_df):].reset_index(drop=True)\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf542835",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T02:05:05.910353Z",
     "iopub.status.busy": "2025-05-07T02:05:05.910148Z",
     "iopub.status.idle": "2025-05-07T02:05:05.914807Z",
     "shell.execute_reply": "2025-05-07T02:05:05.914243Z"
    },
    "papermill": {
     "duration": 0.010932,
     "end_time": "2025-05-07T02:05:05.916011",
     "exception": false,
     "start_time": "2025-05-07T02:05:05.905079",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "@memory.cache\n",
    "def handle_missing_values(df, lag_steps, window_sizes):\n",
    "    \"\"\"Handle missing values in the dataframe\"\"\"\n",
    "    result_df = df.copy()\n",
    "    \n",
    "    # Fill NaN values in lag features with 0\n",
    "    for lag in lag_steps:\n",
    "        lag_col = f'{Config.TARGET}_lag{lag}'\n",
    "        if lag_col in result_df.columns:\n",
    "            result_df[lag_col] = result_df[lag_col].fillna(0)\n",
    "    \n",
    "    # Fill NaN values in rolling features with 0\n",
    "    for window in window_sizes:\n",
    "        mean_col = f'{Config.TARGET}_rollmean_{window}'\n",
    "        std_col = f'{Config.TARGET}_rollstd_{window}'\n",
    "        \n",
    "        if mean_col in result_df.columns:\n",
    "            result_df[mean_col] = result_df[mean_col].fillna(0)\n",
    "        \n",
    "        if std_col in result_df.columns:\n",
    "            result_df[std_col] = result_df[std_col].fillna(0)\n",
    "    \n",
    "    # Fill remaining NaNs with 0\n",
    "    result_df = result_df.fillna(0)\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ac6fe5",
   "metadata": {
    "papermill": {
     "duration": 0.00431,
     "end_time": "2025-05-07T02:05:05.924808",
     "exception": false,
     "start_time": "2025-05-07T02:05:05.920498",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Loading and Processing\n",
    "\n",
    "Load and Process Data Function  \n",
    "Core function for data preparation:\n",
    "1. Loads data from CSV  \n",
    "2. Filters to keep only selected features  \n",
    "3. Handles target variable conversion and NaN/inf values  \n",
    "4. Creates lag features and rolling statistics when appropriate  \n",
    "5. Returns cleaned and feature-enhanced dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c35672f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T02:05:05.934496Z",
     "iopub.status.busy": "2025-05-07T02:05:05.934294Z",
     "iopub.status.idle": "2025-05-07T02:05:05.941758Z",
     "shell.execute_reply": "2025-05-07T02:05:05.941185Z"
    },
    "papermill": {
     "duration": 0.013681,
     "end_time": "2025-05-07T02:05:05.942922",
     "exception": false,
     "start_time": "2025-05-07T02:05:05.929241",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Modified load_and_process_data function to filter features\n",
    "@memory.cache\n",
    "def load_and_process_data(file_path, train_file_path=None, lag_steps=None, window_sizes=None):\n",
    "    \"\"\"\n",
    "    Load and process data from file_path with optional lag features and rolling statistics\n",
    "    If train_file_path is provided, use it for creating lag and rolling features\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        raw_df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Filter to keep only selected features plus essential columns\n",
    "        essential_cols = ['DATETIME', 'ROW', 'COL', Config.TARGET]\n",
    "        feature_cols = [col for col in selected_features if col in raw_df.columns]\n",
    "        filtered_cols = essential_cols + feature_cols\n",
    "        \n",
    "        # Keep only needed columns\n",
    "        raw_df = raw_df[filtered_cols]\n",
    "        \n",
    "        # Convert target to numeric and handle NaN/inf values\n",
    "        raw_df[Config.TARGET] = pd.to_numeric(raw_df[Config.TARGET], errors='coerce')\n",
    "        raw_df = raw_df.replace([np.inf, -np.inf], np.nan)\n",
    "        df = raw_df.dropna(subset=[Config.TARGET]).copy()\n",
    "        \n",
    "        # Sort by datetime for proper sequence handling\n",
    "        if 'DATETIME' in df.columns:\n",
    "            df = df.sort_values(\"DATETIME\").reset_index(drop=True)\n",
    "        \n",
    "        # If we're in train mode or not creating lag/rolling features\n",
    "        if train_file_path is None or (lag_steps is None and window_sizes is None):\n",
    "            return df\n",
    "        \n",
    "        # Otherwise, we're in eval mode and need to carefully create features\n",
    "        train_df = pd.read_csv(train_file_path)\n",
    "        \n",
    "        # Filter training data to keep only selected features\n",
    "        train_df = train_df[filtered_cols]\n",
    "        \n",
    "        train_df[Config.TARGET] = pd.to_numeric(train_df[Config.TARGET], errors='coerce')\n",
    "        train_df = train_df.replace([np.inf, -np.inf], np.nan)\n",
    "        train_df = train_df.dropna(subset=[Config.TARGET]).copy()\n",
    "        \n",
    "        if 'DATETIME' in train_df.columns:\n",
    "            train_df = train_df.sort_values(\"DATETIME\").reset_index(drop=True)\n",
    "        \n",
    "        # Create lag features if needed\n",
    "        if Config.USE_LAG_FEATURES and lag_steps:\n",
    "            df = create_lag_features(train_df, df, Config.TARGET, lag_steps, ['ROW', 'COL'])\n",
    "        \n",
    "        # Create rolling statistics if needed\n",
    "        if Config.USE_ROLLING_STATISTICS and window_sizes:\n",
    "            df = create_rolling_statistics(train_df, df, Config.TARGET, window_sizes, ['ROW', 'COL'])\n",
    "\n",
    "        if lag_steps or window_sizes:\n",
    "            df = handle_missing_values(df, lag_steps or [], window_sizes or [])\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"[ERRORS] Error loading or processing data: {str(e)}\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc49df8",
   "metadata": {
    "papermill": {
     "duration": 0.004316,
     "end_time": "2025-05-07T02:05:05.951929",
     "exception": false,
     "start_time": "2025-05-07T02:05:05.947613",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model Definition\n",
    "\n",
    "LSTM Model Architecture  \n",
    "Neural network model for time series forecasting:\n",
    "- Uses LSTM (Long Short-Term Memory) layers for sequence modeling  \n",
    "- Configurable input size, hidden size, and number of layers  \n",
    "- Dropout for regularization to prevent overfitting  \n",
    "- Final fully connected layer maps to prediction output  \n",
    "- Supports multi-step forecasting with configurable time_step_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae3bceaf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T02:05:05.962087Z",
     "iopub.status.busy": "2025-05-07T02:05:05.961856Z",
     "iopub.status.idle": "2025-05-07T02:05:05.965904Z",
     "shell.execute_reply": "2025-05-07T02:05:05.965318Z"
    },
    "papermill": {
     "duration": 0.010294,
     "end_time": "2025-05-07T02:05:05.967087",
     "exception": false,
     "start_time": "2025-05-07T02:05:05.956793",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Enhanced LSTM Model\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=64, num_layers=2, dropout=0.0, time_step_out=1):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_size, time_step_out)\n",
    "        self.time_step_out = time_step_out\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        return self.fc(out[:, -1, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9873f4bb",
   "metadata": {
    "papermill": {
     "duration": 0.004461,
     "end_time": "2025-05-07T02:05:05.976086",
     "exception": false,
     "start_time": "2025-05-07T02:05:05.971625",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Sequence Creation\n",
    "\n",
    "Transforms tabular data into sequences for LSTM training:\n",
    "- Creates sliding windows of input sequences and target values  \n",
    "- Maintains spatial grouping by ROW, COL  \n",
    "- Configurable input length (time_step_in), prediction horizon (time_step_out)  \n",
    "- Supports stride parameter to control overlap between sequences  \n",
    "- Returns PyTorch tensors ready for model input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d409a59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T02:05:05.986001Z",
     "iopub.status.busy": "2025-05-07T02:05:05.985777Z",
     "iopub.status.idle": "2025-05-07T02:05:05.991332Z",
     "shell.execute_reply": "2025-05-07T02:05:05.990711Z"
    },
    "papermill": {
     "duration": 0.011829,
     "end_time": "2025-05-07T02:05:05.992412",
     "exception": false,
     "start_time": "2025-05-07T02:05:05.980583",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create sequences with configurable input and output time steps\n",
    "def create_sequences(df, input_cols, target_col, time_step_in, time_step_out=1, stride=1):\n",
    "    \"\"\"\n",
    "    Create sequences from dataframe with configurable input and output time steps\n",
    "    - time_step_in: number of time steps for input\n",
    "    - time_step_out: number of future steps to predict\n",
    "    - stride: step size for sliding window\n",
    "    \"\"\"\n",
    "    sequences, targets = [], []\n",
    "    grouped = df.groupby(['ROW', 'COL'])\n",
    "    \n",
    "    for _, group in grouped:\n",
    "        # Make sure group is sorted by time\n",
    "        if 'DATETIME' in group.columns:\n",
    "            group = group.sort_values(\"DATETIME\")\n",
    "            \n",
    "        data = group[input_cols].values\n",
    "        target_data = group[target_col].values\n",
    "        \n",
    "        if len(data) < time_step_in + time_step_out:\n",
    "            continue\n",
    "        \n",
    "        for i in range(0, len(data) - time_step_in - time_step_out + 1, stride):\n",
    "            seq = data[i:i+time_step_in]\n",
    "            if time_step_out == 1:\n",
    "                target = target_data[i+time_step_in]\n",
    "                targets.append(target)\n",
    "            else:\n",
    "                target = target_data[i+time_step_in:i+time_step_in+time_step_out]\n",
    "                targets.append(target)\n",
    "            sequences.append(seq)\n",
    "            \n",
    "    if not sequences:\n",
    "        return torch.tensor([]), torch.tensor([])\n",
    "    \n",
    "    if time_step_out == 1:\n",
    "        return torch.tensor(sequences, dtype=torch.float32), torch.tensor(targets, dtype=torch.float32).unsqueeze(1)\n",
    "    else:\n",
    "        return torch.tensor(sequences, dtype=torch.float32), torch.tensor(targets, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680c52e3",
   "metadata": {
    "papermill": {
     "duration": 0.004426,
     "end_time": "2025-05-07T02:05:06.001371",
     "exception": false,
     "start_time": "2025-05-07T02:05:05.996945",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Loader Preparation\n",
    "\n",
    "Comprehensive function that:\n",
    "1. Loads train, validation, and test datasets  \n",
    "2. Creates lag features and rolling statistics consistently across datasets  \n",
    "3. Constructs feature columns based on configuration  \n",
    "4. Creates input sequences and targets for each dataset  \n",
    "5. Returns PyTorch DataLoaders ready for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72af6ccd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T02:05:06.011409Z",
     "iopub.status.busy": "2025-05-07T02:05:06.011214Z",
     "iopub.status.idle": "2025-05-07T02:05:06.025605Z",
     "shell.execute_reply": "2025-05-07T02:05:06.025020Z"
    },
    "papermill": {
     "duration": 0.020759,
     "end_time": "2025-05-07T02:05:06.026652",
     "exception": false,
     "start_time": "2025-05-07T02:05:06.005893",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_data_loaders(month, fold, lag_steps, window_sizes, time_step_in, time_step_out, batch_size, stride=1):\n",
    "    \"\"\"Prepare data loaders with specific time steps and features\"\"\"\n",
    "    folder = os.path.join(base_path, month, fold)\n",
    "    \n",
    "    # Load train data\n",
    "    train_df = load_and_process_data(os.path.join(folder, \"processed_train.csv\"))\n",
    "    \n",
    "    # Load validation data\n",
    "    val_df = load_and_process_data(os.path.join(folder, \"processed_val.csv\"))\n",
    "    \n",
    "    # Load test data\n",
    "    test_df = load_and_process_data(os.path.join(folder, \"merged_test.csv\"))\n",
    "    \n",
    "    if train_df.empty or val_df.empty or test_df.empty:\n",
    "        print(\"[WARNINGS] One or more datasets are empty\")\n",
    "        return None, None, None, 0\n",
    "    \n",
    "    # Sort data by time\n",
    "    if 'DATETIME' in train_df.columns:\n",
    "        train_df = train_df.sort_values(\"DATETIME\").reset_index(drop=True)\n",
    "    if 'DATETIME' in val_df.columns:\n",
    "        val_df = val_df.sort_values(\"DATETIME\").reset_index(drop=True)\n",
    "    if 'DATETIME' in test_df.columns:\n",
    "        test_df = test_df.sort_values(\"DATETIME\").reset_index(drop=True)\n",
    "    \n",
    "    # Create features before further processing\n",
    "    # 1. Create lag features separately for each dataset\n",
    "    if Config.USE_LAG_FEATURES and lag_steps:\n",
    "        # Create lag features for train set using itself\n",
    "        for lag in lag_steps:\n",
    "            train_df[f'{Config.TARGET}_lag{lag}'] = train_df.groupby(['ROW', 'COL'])[Config.TARGET].shift(lag)\n",
    "        \n",
    "        # Create lag features for validation set using train + val\n",
    "        train_val_df = pd.concat([train_df, val_df]).sort_values('DATETIME').reset_index(drop=True)\n",
    "        for lag in lag_steps:\n",
    "            train_val_df[f'{Config.TARGET}_lag{lag}'] = train_val_df.groupby(['ROW', 'COL'])[Config.TARGET].shift(lag)\n",
    "        val_df = train_val_df.iloc[len(train_df):].reset_index(drop=True)\n",
    "        \n",
    "        # Create lag features for test set using train + val + test\n",
    "        full_df = pd.concat([train_df, val_df, test_df]).sort_values('DATETIME').reset_index(drop=True)\n",
    "        for lag in lag_steps:\n",
    "            full_df[f'{Config.TARGET}_lag{lag}'] = full_df.groupby(['ROW', 'COL'])[Config.TARGET].shift(lag)\n",
    "        test_df = full_df.iloc[len(train_df) + len(val_df):].reset_index(drop=True)\n",
    "    \n",
    "    # 2. Create rolling statistics separately for each dataset\n",
    "    if Config.USE_ROLLING_STATISTICS and window_sizes:\n",
    "        # Create rolling stats for train set\n",
    "        for window in window_sizes:\n",
    "            train_df[f'{Config.TARGET}_rollmean_{window}'] = train_df.groupby(['ROW', 'COL'])[Config.TARGET].transform(\n",
    "                lambda x: x.rolling(window, min_periods=1).mean())\n",
    "            train_df[f'{Config.TARGET}_rollstd_{window}'] = train_df.groupby(['ROW', 'COL'])[Config.TARGET].transform(\n",
    "                lambda x: x.rolling(window, min_periods=1).std())\n",
    "        \n",
    "        # Create rolling stats for validation set\n",
    "        train_val_df = pd.concat([train_df, val_df]).sort_values('DATETIME').reset_index(drop=True)\n",
    "        for window in window_sizes:\n",
    "            train_val_df[f'{Config.TARGET}_rollmean_{window}'] = train_val_df.groupby(['ROW', 'COL'])[Config.TARGET].transform(\n",
    "                lambda x: x.rolling(window, min_periods=1).mean())\n",
    "            train_val_df[f'{Config.TARGET}_rollstd_{window}'] = train_val_df.groupby(['ROW', 'COL'])[Config.TARGET].transform(\n",
    "                lambda x: x.rolling(window, min_periods=1).std())\n",
    "        val_df = train_val_df.iloc[len(train_df):].reset_index(drop=True)\n",
    "        \n",
    "        # Create rolling stats for test set\n",
    "        full_df = pd.concat([train_df, val_df, test_df]).sort_values('DATETIME').reset_index(drop=True)\n",
    "        for window in window_sizes:\n",
    "            full_df[f'{Config.TARGET}_rollmean_{window}'] = full_df.groupby(['ROW', 'COL'])[Config.TARGET].transform(\n",
    "                lambda x: x.rolling(window, min_periods=1).mean())\n",
    "            full_df[f'{Config.TARGET}_rollstd_{window}'] = full_df.groupby(['ROW', 'COL'])[Config.TARGET].transform(\n",
    "                lambda x: x.rolling(window, min_periods=1).std())\n",
    "        test_df = full_df.iloc[len(train_df) + len(val_df):].reset_index(drop=True)\n",
    "    \n",
    "    # Handle missing values\n",
    "    train_df = train_df.fillna(0)\n",
    "    val_df = val_df.fillna(0)\n",
    "    test_df = test_df.fillna(0)\n",
    "    \n",
    "    basic_cols = [col for col in selected_features if col in train_df.columns]\n",
    "    lag_cols = [f'{Config.TARGET}_lag{lag}' for lag in lag_steps if f'{Config.TARGET}_lag{lag}' in train_df.columns]\n",
    "    roll_cols = []\n",
    "    \n",
    "    for window in window_sizes:\n",
    "        mean_col = f'{Config.TARGET}_rollmean_{window}'\n",
    "        std_col = f'{Config.TARGET}_rollstd_{window}'\n",
    "        if mean_col in train_df.columns:\n",
    "            roll_cols.append(mean_col)\n",
    "        if std_col in train_df.columns:\n",
    "            roll_cols.append(std_col)\n",
    "    \n",
    "    feature_cols = basic_cols + lag_cols + roll_cols\n",
    "    \n",
    "    # Check if we have any features\n",
    "    if not feature_cols:\n",
    "        print(\"[WARNINGS] No features detected! Creating default lag feature.\")\n",
    "        # Create at least one default lag feature\n",
    "        default_lag = 1\n",
    "        for df in [train_df, val_df, test_df]:\n",
    "            df[f'{Config.TARGET}_lag{default_lag}'] = df.groupby(['ROW', 'COL'])[Config.TARGET].shift(default_lag)\n",
    "            df = df.fillna(0)\n",
    "        \n",
    "        feature_cols = [f'{Config.TARGET}_lag{default_lag}']\n",
    "    \n",
    "    \n",
    "    # Create sequences\n",
    "    train_x, train_y = create_sequences(train_df, feature_cols, Config.TARGET, time_step_in, time_step_out, stride)\n",
    "    val_x, val_y = create_sequences(val_df, feature_cols, Config.TARGET, time_step_in, time_step_out, stride)\n",
    "    test_x, test_y = create_sequences(test_df, feature_cols, Config.TARGET, time_step_in, time_step_out, stride)\n",
    "    \n",
    "    if train_x.numel() == 0 or val_x.numel() == 0 or test_x.numel() == 0:\n",
    "        print(\"[WARNINGS] One or more sequence sets are empty\")\n",
    "        return None, None, None, 0\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(TensorDataset(train_x, train_y), batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(TensorDataset(val_x, val_y), batch_size=batch_size)\n",
    "    test_loader = DataLoader(TensorDataset(test_x, test_y), batch_size=batch_size)\n",
    "    \n",
    "    return train_loader, val_loader, test_loader, train_x.shape[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3d9d41",
   "metadata": {
    "papermill": {
     "duration": 0.004416,
     "end_time": "2025-05-07T02:05:06.035662",
     "exception": false,
     "start_time": "2025-05-07T02:05:06.031246",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model Training\n",
    "\n",
    "Model Training Function  \n",
    "Implements the training loop with early stopping:\n",
    "- Tracks loss on each batch and epoch  \n",
    "- Implements patience-based early stopping to prevent overfitting  \n",
    "- Moves data to the appropriate device (CPU/GPU)  \n",
    "- Returns best loss value for monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2475915",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T02:05:06.045577Z",
     "iopub.status.busy": "2025-05-07T02:05:06.045382Z",
     "iopub.status.idle": "2025-05-07T02:05:06.050272Z",
     "shell.execute_reply": "2025-05-07T02:05:06.049631Z"
    },
    "papermill": {
     "duration": 0.011206,
     "end_time": "2025-05-07T02:05:06.051457",
     "exception": false,
     "start_time": "2025-05-07T02:05:06.040251",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(model, loader, optimizer, loss_fn, epochs, patience=3):\n",
    "    \"\"\"Train model with early stopping\"\"\"\n",
    "    model.train()\n",
    "    best_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for xb, yb in loader:\n",
    "            xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(xb)\n",
    "            loss = loss_fn(preds, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * xb.size(0)\n",
    "        \n",
    "        avg_loss = running_loss / len(loader.dataset)\n",
    "        print(f\"   Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}\")\n",
    "        \n",
    "        # Early stopping check\n",
    "        if avg_loss < best_loss:\n",
    "            best_loss = avg_loss\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"   Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "    \n",
    "    return best_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf1d73e",
   "metadata": {
    "papermill": {
     "duration": 0.004491,
     "end_time": "2025-05-07T02:05:06.060620",
     "exception": false,
     "start_time": "2025-05-07T02:05:06.056129",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model Evaluation\n",
    "\n",
    "Model Evaluation  \n",
    "Calculates performance metrics on validation/test data:\n",
    "- RMSE (Root Mean Squared Error)  \n",
    "- Bias  \n",
    "- R-squared  \n",
    "- CSI (Critical Success Index)  \n",
    "- Handles both single-step and multi-step prediction evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b88f404",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T02:05:06.070793Z",
     "iopub.status.busy": "2025-05-07T02:05:06.070583Z",
     "iopub.status.idle": "2025-05-07T02:05:06.076349Z",
     "shell.execute_reply": "2025-05-07T02:05:06.075755Z"
    },
    "papermill": {
     "duration": 0.0121,
     "end_time": "2025-05-07T02:05:06.077428",
     "exception": false,
     "start_time": "2025-05-07T02:05:06.065328",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, loader):\n",
    "    \"\"\"Evaluate model and return metrics\"\"\"\n",
    "    model.eval()\n",
    "    preds, targets = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            xb = xb.to(DEVICE)\n",
    "            pred = model(xb).cpu()\n",
    "            preds.append(pred)\n",
    "            targets.append(yb)\n",
    "    \n",
    "    preds = torch.cat(preds).squeeze().numpy()\n",
    "    targets = torch.cat(targets).squeeze().numpy()\n",
    "    \n",
    "    # Handle multi-step output\n",
    "    if len(preds.shape) > 1 and preds.shape[1] > 1:\n",
    "        # For multi-step evaluation, we'll calculate metrics on the last predicted step\n",
    "        preds_last = preds[:, -1]\n",
    "        targets_last = targets[:, -1] if len(targets.shape) > 1 else targets\n",
    "        \n",
    "        rmse = mean_squared_error(targets_last, preds_last, squared=False)\n",
    "        bias = np.mean(preds_last - targets_last)\n",
    "        r = r2_score(targets_last, preds_last)\n",
    "        csi = np.sum((preds_last > 0.1) & (targets_last > 0.1)) / (np.sum((preds_last > 0.1) | (targets_last > 0.1)) + 1e-9)\n",
    "    else:\n",
    "        rmse = mean_squared_error(targets, preds, squared=False)\n",
    "        bias = np.mean(preds - targets)\n",
    "        r = r2_score(targets, preds)\n",
    "        csi = np.sum((preds > 0.1) & (targets > 0.1)) / (np.sum((preds > 0.1) | (targets > 0.1)) + 1e-9)\n",
    "    \n",
    "    return rmse, bias, r, csi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d2f816",
   "metadata": {
    "papermill": {
     "duration": 0.004455,
     "end_time": "2025-05-07T02:05:06.086559",
     "exception": false,
     "start_time": "2025-05-07T02:05:06.082104",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Optuna Hyperparameter Optimization\n",
    "\n",
    "Optuna Objective Function  \n",
    "Defines the optimization objective for hyperparameter tuning:\n",
    "- Searches over model architecture parameters (hidden size, layers, dropout)  \n",
    "- Optimizes learning rate and sequence configurations  \n",
    "- Tunes feature engineering parameters (lag steps, window sizes)  \n",
    "- Performs cross-validation across folds for robust parameter selection  \n",
    "- Returns mean validation RMSE as the objective to minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46f4f091",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T02:05:06.096753Z",
     "iopub.status.busy": "2025-05-07T02:05:06.096533Z",
     "iopub.status.idle": "2025-05-07T02:05:06.103609Z",
     "shell.execute_reply": "2025-05-07T02:05:06.103014Z"
    },
    "papermill": {
     "duration": 0.013573,
     "end_time": "2025-05-07T02:05:06.104764",
     "exception": false,
     "start_time": "2025-05-07T02:05:06.091191",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(trial, month):\n",
    "    \"\"\"Optuna objective function using cross-validation across folds\"\"\"\n",
    "    # Hyperparameters to tune\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 32, 256)\n",
    "    num_layers = trial.suggest_int(\"num_layers\", 1, 3)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.0, 0.5)\n",
    "    lr = trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)\n",
    "    time_step_in = trial.suggest_int(\"time_step_in\", 12, 48)\n",
    "    time_step_out = trial.suggest_int(\"time_step_out\", 1, 6)\n",
    "    stride = trial.suggest_int(\"stride\", 1, 6)\n",
    "    \n",
    "    # Lag steps and window sizes\n",
    "    num_lags = trial.suggest_int(\"num_lags\", 1, 3)\n",
    "    lag_steps = [trial.suggest_int(f\"lag_{i}\", 1, 12) for i in range(num_lags)]\n",
    "    \n",
    "    num_windows = trial.suggest_int(\"num_windows\", 1, 3)\n",
    "    window_sizes = [trial.suggest_int(f\"window_{i}\", 3, 24) for i in range(num_windows)]\n",
    "    \n",
    "    # Get batch size from config\n",
    "    config_key = month.split(\"-\")[1]\n",
    "    config = MODEL_CONFIG[config_key]\n",
    "    batch_size = config[\"BATCH_SIZE\"]\n",
    "    \n",
    "    # Cross-validation across folds\n",
    "    fold_val_rmses = []\n",
    "    \n",
    "    for fold in folds:\n",
    "        try:\n",
    "            # Prepare data loaders (only train and validation, no test)\n",
    "            train_loader, val_loader, _, input_size = prepare_data_loaders(\n",
    "                month, fold, lag_steps, window_sizes, time_step_in, time_step_out, batch_size, stride\n",
    "            )\n",
    "            \n",
    "            if train_loader is None or val_loader is None:\n",
    "                # Skip this fold if data preparation failed\n",
    "                continue\n",
    "            \n",
    "            # Create model with trial parameters\n",
    "            model = LSTMModel(\n",
    "                input_size=input_size, \n",
    "                hidden_size=hidden_size, \n",
    "                num_layers=num_layers, \n",
    "                dropout=dropout,\n",
    "                time_step_out=time_step_out\n",
    "            ).to(DEVICE)\n",
    "            \n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "            loss_fn = nn.MSELoss()\n",
    "            \n",
    "            # Train for a small number of epochs during hyperparameter search\n",
    "            train_model(model, train_loader, optimizer, loss_fn, epochs=5, patience=2)\n",
    "            \n",
    "            # Evaluate on validation set only\n",
    "            val_rmse, _, _, _ = evaluate_model(model, val_loader)\n",
    "            fold_val_rmses.append(val_rmse)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in fold {fold}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # Return mean validation RMSE across folds\n",
    "    if fold_val_rmses:\n",
    "        mean_val_rmse = sum(fold_val_rmses) / len(fold_val_rmses)\n",
    "        return mean_val_rmse\n",
    "    else:\n",
    "        return float('inf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d01b62a",
   "metadata": {
    "papermill": {
     "duration": 0.00477,
     "end_time": "2025-05-07T02:05:06.114248",
     "exception": false,
     "start_time": "2025-05-07T02:05:06.109478",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Testing and Final Evaluation\n",
    "\n",
    "Test Set Evaluation  \n",
    "Uses best hyperparameters to train final models:\n",
    "1. Trains model with optimal hyperparameters  \n",
    "2. Evaluates on validation and test sets  \n",
    "3. Saves model weights  \n",
    "4. Returns comprehensive metrics dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e496b0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T02:05:06.124429Z",
     "iopub.status.busy": "2025-05-07T02:05:06.124232Z",
     "iopub.status.idle": "2025-05-07T02:05:06.132097Z",
     "shell.execute_reply": "2025-05-07T02:05:06.131472Z"
    },
    "papermill": {
     "duration": 0.014343,
     "end_time": "2025-05-07T02:05:06.133232",
     "exception": false,
     "start_time": "2025-05-07T02:05:06.118889",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_on_test(month, fold, best_params):\n",
    "    \"\"\"Train and evaluate model with best parameters on test set\"\"\"\n",
    "    print(f\"\\n====== Training model for {month}, {fold} with best parameters\")\n",
    "    \n",
    "    # Extract parameters\n",
    "    hidden_size = best_params[\"hidden_size\"]\n",
    "    num_layers = best_params[\"num_layers\"]\n",
    "    dropout = best_params[\"dropout\"]\n",
    "    lr = best_params[\"lr\"]\n",
    "    time_step_in = best_params[\"time_step_in\"]\n",
    "    time_step_out = best_params[\"time_step_out\"]\n",
    "    stride = best_params[\"stride\"]\n",
    "    \n",
    "    # Extract lag steps and window sizes\n",
    "    num_lags = best_params[\"num_lags\"]\n",
    "    lag_steps = [best_params[f\"lag_{i}\"] for i in range(num_lags)]\n",
    "    \n",
    "    num_windows = best_params[\"num_windows\"]\n",
    "    window_sizes = [best_params[f\"window_{i}\"] for i in range(num_windows)]\n",
    "    \n",
    "    # Get config\n",
    "    config_key = month.split(\"-\")[1]\n",
    "    config = MODEL_CONFIG[config_key]\n",
    "    batch_size = config[\"BATCH_SIZE\"]\n",
    "    epochs = config[\"EPOCHS\"]\n",
    "    \n",
    "    # Prepare data\n",
    "    train_loader, val_loader, test_loader, input_size = prepare_data_loaders(\n",
    "        month, fold, lag_steps, window_sizes, time_step_in, time_step_out, batch_size, stride\n",
    "    )\n",
    "    \n",
    "    if train_loader is None or val_loader is None or test_loader is None:\n",
    "        print(\"[ERRORS] Failed to prepare data\")\n",
    "        return None\n",
    "    \n",
    "    # Create model\n",
    "    model = LSTMModel(\n",
    "        input_size=input_size,\n",
    "        hidden_size=hidden_size,\n",
    "        num_layers=num_layers,\n",
    "        dropout=dropout,\n",
    "        time_step_out=time_step_out\n",
    "    ).to(DEVICE)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_fn = nn.MSELoss()\n",
    "    \n",
    "    # Train model on train set\n",
    "    print(f\"====== Training model on train set...\")\n",
    "    train_model(model, train_loader, optimizer, loss_fn, epochs=epochs, patience=5)\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    print(\"====== Evaluating on validation set...\")\n",
    "    val_rmse, val_bias, val_r, val_csi = evaluate_model(model, val_loader)\n",
    "    print(f\"  Val RMSE: {val_rmse:.4f}, Bias: {val_bias:.4f}, R²: {val_r:.4f}, CSI: {val_csi:.4f}\")\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    print(\"====== Evaluating on test set...\")\n",
    "    test_rmse, test_bias, test_r, test_csi = evaluate_model(model, test_loader)\n",
    "    print(f\"  Test RMSE: {test_rmse:.4f}, Bias: {test_bias:.4f}, R²: {test_r:.4f}, CSI: {test_csi:.4f}\")\n",
    "    \n",
    "    # Save model for this fold\n",
    "    model_path = f\"model_{month}_{fold}.pt\"\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print(f\" Model saved to {model_path}\")\n",
    "    \n",
    "    return {\n",
    "        \"month\": month,\n",
    "        \"fold\": fold,\n",
    "        \"test_rmse\": round(test_rmse, 4),\n",
    "        \"test_bias\": round(test_bias, 4),\n",
    "        \"test_r\": round(test_r, 4),\n",
    "        \"test_csi\": round(test_csi, 4),\n",
    "        \"val_rmse\": round(val_rmse, 4),\n",
    "        \"val_bias\": round(val_bias, 4),\n",
    "        \"val_r\": round(val_r, 4),\n",
    "        \"val_csi\": round(val_csi, 4),\n",
    "        \"model\": model\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd80883",
   "metadata": {
    "papermill": {
     "duration": 0.004637,
     "end_time": "2025-05-07T02:05:06.142588",
     "exception": false,
     "start_time": "2025-05-07T02:05:06.137951",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Main Execution Function\n",
    "\n",
    "Optuna Optimization Main Function  \n",
    "Orchestrates the entire model building process:\n",
    "1. For each month:\n",
    "   a. Runs hyperparameter optimization with cross-validation  \n",
    "   b. Saves best parameters  \n",
    "   c. Evaluates on test set for each fold  \n",
    "   d. Saves best model  \n",
    "2. Calculates and reports performance metrics:\n",
    "   a. Per-month metrics  \n",
    "   b. Overall mean performance  \n",
    "3. Saves results to CSV files for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a568b58b",
   "metadata": {
    "_cell_guid": "0d428d71-24a7-41ca-b8ef-91a62c6351bb",
    "_uuid": "777f311e-aaab-4cbf-8427-94523806e0a8",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-05-07T02:05:06.152838Z",
     "iopub.status.busy": "2025-05-07T02:05:06.152631Z",
     "iopub.status.idle": "2025-05-07T02:05:06.164892Z",
     "shell.execute_reply": "2025-05-07T02:05:06.164289Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.018845,
     "end_time": "2025-05-07T02:05:06.166122",
     "exception": false,
     "start_time": "2025-05-07T02:05:06.147277",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_optuna_optimization():\n",
    "    \"\"\"Run Optuna optimization with cross-validation and final test evaluation\"\"\"\n",
    "    month_results = {}\n",
    "    \n",
    "    for month in months:\n",
    "        print(f\"\\n###### Processing month: {month}\")\n",
    "        \n",
    "        # Step 1: Find the best hyperparameters using cross-validation\n",
    "        study_name = f\"{month}_study\"\n",
    "        study = optuna.create_study(direction=\"minimize\", study_name=study_name)\n",
    "        \n",
    "        # Create a partial function with fixed month\n",
    "        objective_func = partial(objective, month=month)\n",
    "        \n",
    "        # Run optimization with cross-validation\n",
    "        try:\n",
    "            study.optimize(objective_func, n_trials=20, timeout=3600)  # 1 hour timeout\n",
    "            \n",
    "            best_params = study.best_params\n",
    "            print(f\" Best parameters for {month}:\")\n",
    "            for key, value in best_params.items():\n",
    "                print(f\"  {key}: {value}\")\n",
    "            \n",
    "            # Save best parameters for the month\n",
    "            best_params_path = f\"best_params_{month}.json\"\n",
    "            with open(best_params_path, \"w\") as f:\n",
    "                json.dump(best_params, f, indent=2)\n",
    "            \n",
    "            print(f\" Best parameters saved to {best_params_path}\")\n",
    "            \n",
    "            # Step 2: Final evaluation on test set for each fold\n",
    "            fold_test_results = []\n",
    "            for fold in folds:\n",
    "                print(f\"\\n Final evaluation on {month}, {fold} test set\")\n",
    "                result = evaluate_on_test(month, fold, best_params)\n",
    "                if result:\n",
    "                    fold_test_results.append(result)\n",
    "            \n",
    "            # Calculate mean performance across folds\n",
    "            if fold_test_results:\n",
    "                mean_rmse = sum(r[\"test_rmse\"] for r in fold_test_results) / len(fold_test_results)\n",
    "                mean_bias = sum(r[\"test_bias\"] for r in fold_test_results) / len(fold_test_results)\n",
    "                mean_r = sum(r[\"test_r\"] for r in fold_test_results) / len(fold_test_results)\n",
    "                mean_csi = sum(r[\"test_csi\"] for r in fold_test_results) / len(fold_test_results)\n",
    "                \n",
    "                # Save best fold result (lowest RMSE)\n",
    "                best_fold_result = min(fold_test_results, key=lambda x: x[\"test_rmse\"])\n",
    "                best_model = best_fold_result[\"model\"]\n",
    "                best_model_path = f\"best_model_{month}.pt\"\n",
    "                torch.save(best_model.state_dict(), best_model_path)\n",
    "                \n",
    "                # Store results for this month\n",
    "                month_results[month] = {\n",
    "                    \"month\": month,\n",
    "                    \"best_fold\": best_fold_result[\"fold\"],\n",
    "                    \"best_test_rmse\": best_fold_result[\"test_rmse\"],\n",
    "                    \"best_test_bias\": best_fold_result[\"test_bias\"],\n",
    "                    \"best_test_r\": best_fold_result[\"test_r\"],\n",
    "                    \"best_test_csi\": best_fold_result[\"test_csi\"],\n",
    "                    \"mean_test_rmse\": round(mean_rmse, 4),\n",
    "                    \"mean_test_bias\": round(mean_bias, 4),\n",
    "                    \"mean_test_r\": round(mean_r, 4),\n",
    "                    \"mean_test_csi\": round(mean_csi, 4),\n",
    "                    \"best_params\": best_params,\n",
    "                    \"fold_results\": fold_test_results\n",
    "                }\n",
    "                \n",
    "                print(f\"\\n Mean test performance for {month}:\")\n",
    "                print(f\"  RMSE: {mean_rmse:.4f}, Bias: {mean_bias:.4f}, R²: {mean_r:.4f}, CSI: {mean_csi:.4f}\")\n",
    "                print(f\" Best fold test performance for {month} (fold {best_fold_result['fold']}):\")\n",
    "                print(f\"  RMSE: {best_fold_result['test_rmse']:.4f}, Bias: {best_fold_result['test_bias']:.4f}, R²: {best_fold_result['test_r']:.4f}, CSI: {best_fold_result['test_csi']:.4f}\")\n",
    "                print(f\" Best model for {month} saved to {best_model_path}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"[ERRORS] Error during optimization for {month}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # Calculate overall mean performance across months\n",
    "    if month_results:\n",
    "        overall_mean_rmse = sum(r[\"best_test_rmse\"] for r in month_results.values()) / len(month_results)\n",
    "        overall_mean_bias = sum(r[\"best_test_bias\"] for r in month_results.values()) / len(month_results)\n",
    "        overall_mean_r = sum(r[\"best_test_r\"] for r in month_results.values()) / len(month_results)\n",
    "        overall_mean_csi = sum(r[\"best_test_csi\"] for r in month_results.values()) / len(month_results)\n",
    "        \n",
    "        print(\"\\n Overall mean performance across all months:\")\n",
    "        print(f\"  RMSE: {overall_mean_rmse:.4f}, Bias: {overall_mean_bias:.4f}, R²: {overall_mean_r:.4f}, CSI: {overall_mean_csi:.4f}\")\n",
    "    \n",
    "    # Create a dataframe with month results\n",
    "    month_results_df = pd.DataFrame([\n",
    "        {\n",
    "            \"month\": month,\n",
    "            \"best_fold\": data[\"best_fold\"],\n",
    "            \"best_test_rmse\": data[\"best_test_rmse\"],\n",
    "            \"best_test_bias\": data[\"best_test_bias\"],\n",
    "            \"best_test_r\": data[\"best_test_r\"],\n",
    "            \"best_test_csi\": data[\"best_test_csi\"],\n",
    "            \"mean_test_rmse\": data[\"mean_test_rmse\"],\n",
    "            \"mean_test_bias\": data[\"mean_test_bias\"],\n",
    "            \"mean_test_r\": data[\"mean_test_r\"],\n",
    "            \"mean_test_csi\": data[\"mean_test_csi\"],\n",
    "        } for month, data in month_results.items()\n",
    "    ])\n",
    "    \n",
    "    # Display month-wise results\n",
    "    print(\"\\n Results by Month:\")\n",
    "    print(month_results_df)\n",
    "    \n",
    "    # Save results\n",
    "    month_results_df.to_csv(\"lstm_month_results.csv\", index=False)\n",
    "    \n",
    "    # Save detailed results\n",
    "    all_fold_results = []\n",
    "    for month, data in month_results.items():\n",
    "        for fold_result in data[\"fold_results\"]:\n",
    "            all_fold_results.append({\n",
    "                \"month\": month,\n",
    "                \"fold\": fold_result[\"fold\"],\n",
    "                \"test_rmse\": fold_result[\"test_rmse\"],\n",
    "                \"test_bias\": fold_result[\"test_bias\"],\n",
    "                \"test_r\": fold_result[\"test_r\"],\n",
    "                \"test_csi\": fold_result[\"test_csi\"],\n",
    "                \"val_rmse\": fold_result[\"val_rmse\"],\n",
    "                \"val_bias\": fold_result[\"val_bias\"],\n",
    "                \"val_r\": fold_result[\"val_r\"],\n",
    "                \"val_csi\": fold_result[\"val_csi\"],\n",
    "            })\n",
    "    \n",
    "    all_fold_results_df = pd.DataFrame(all_fold_results)\n",
    "    all_fold_results_df.to_csv(\"lstm_all_fold_results.csv\", index=False)\n",
    "    \n",
    "    print(\" Results saved to lstm_month_results.csv and lstm_all_fold_results.csv\")\n",
    "    \n",
    "    return month_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0447e9b0",
   "metadata": {
    "_cell_guid": "38e66a54-7a7f-4e7a-b9ab-fcfb79033a41",
    "_uuid": "7922e199-526e-4772-b295-c9433b89ab77",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-05-07T02:05:06.176268Z",
     "iopub.status.busy": "2025-05-07T02:05:06.176077Z",
     "iopub.status.idle": "2025-05-07T05:18:02.290199Z",
     "shell.execute_reply": "2025-05-07T05:18:02.288954Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 11576.121078,
     "end_time": "2025-05-07T05:18:02.291924",
     "exception": false,
     "start_time": "2025-05-07T02:05:06.170846",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 02:05:06,176] A new study created in memory with name: 2019-04_study\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###### Processing month: 2019-04\n",
      "   Epoch 1/5, Loss: 0.5852\n",
      "   Epoch 2/5, Loss: 0.5628\n",
      "   Epoch 3/5, Loss: 0.5295\n",
      "   Epoch 4/5, Loss: 0.4946\n",
      "   Epoch 5/5, Loss: 0.4759\n",
      "   Epoch 1/5, Loss: 0.3093\n",
      "   Epoch 2/5, Loss: 0.2883\n",
      "   Epoch 3/5, Loss: 0.2711\n",
      "   Epoch 4/5, Loss: 0.2579\n",
      "   Epoch 5/5, Loss: 0.2459\n",
      "   Epoch 1/5, Loss: 0.2926\n",
      "   Epoch 2/5, Loss: 0.2747\n",
      "   Epoch 3/5, Loss: 0.2611\n",
      "   Epoch 4/5, Loss: 0.2512\n",
      "   Epoch 5/5, Loss: 0.2395\n",
      "   Epoch 1/5, Loss: 0.3414\n",
      "   Epoch 2/5, Loss: 0.3209\n",
      "   Epoch 3/5, Loss: 0.3106\n",
      "   Epoch 4/5, Loss: 0.3009\n",
      "   Epoch 5/5, Loss: 0.2942\n",
      "   Epoch 1/5, Loss: 0.2669\n",
      "   Epoch 2/5, Loss: 0.2514\n",
      "   Epoch 3/5, Loss: 0.2410\n",
      "   Epoch 4/5, Loss: 0.2339\n",
      "   Epoch 5/5, Loss: 0.2292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 02:08:21,243] Trial 0 finished with value: 0.42700807750225067 and parameters: {'hidden_size': 162, 'num_layers': 1, 'dropout': 0.43565981286398253, 'lr': 0.0003321592347988165, 'time_step_in': 16, 'time_step_out': 2, 'stride': 1, 'num_lags': 3, 'lag_0': 10, 'lag_1': 2, 'lag_2': 7, 'num_windows': 3, 'window_0': 21, 'window_1': 14, 'window_2': 22}. Best is trial 0 with value: 0.42700807750225067.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1/5, Loss: 0.6807\n",
      "   Epoch 2/5, Loss: 0.6696\n",
      "   Epoch 3/5, Loss: 0.6513\n",
      "   Epoch 4/5, Loss: 0.6205\n",
      "   Epoch 5/5, Loss: 0.6089\n",
      "   Epoch 1/5, Loss: 0.3186\n",
      "   Epoch 2/5, Loss: 0.3110\n",
      "   Epoch 3/5, Loss: 0.3018\n",
      "   Epoch 4/5, Loss: 0.3025\n",
      "   Epoch 5/5, Loss: 0.2947\n",
      "   Epoch 1/5, Loss: 0.2488\n",
      "   Epoch 2/5, Loss: 0.2499\n",
      "   Epoch 3/5, Loss: 0.2480\n",
      "   Epoch 4/5, Loss: 0.2458\n",
      "   Epoch 5/5, Loss: 0.2466\n",
      "   Epoch 1/5, Loss: 0.3509\n",
      "   Epoch 2/5, Loss: 0.3467\n",
      "   Epoch 3/5, Loss: 0.3510\n",
      "   Epoch 4/5, Loss: 0.3464\n",
      "   Epoch 5/5, Loss: 0.3422\n",
      "   Epoch 1/5, Loss: 0.2731\n",
      "   Epoch 2/5, Loss: 0.2674\n",
      "   Epoch 3/5, Loss: 0.2654\n",
      "   Epoch 4/5, Loss: 0.2636\n",
      "   Epoch 5/5, Loss: 0.2618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 02:10:07,691] Trial 1 finished with value: 0.32690627723932264 and parameters: {'hidden_size': 187, 'num_layers': 2, 'dropout': 0.4508534705344154, 'lr': 0.0051643475523695526, 'time_step_in': 35, 'time_step_out': 6, 'stride': 5, 'num_lags': 2, 'lag_0': 8, 'lag_1': 7, 'num_windows': 3, 'window_0': 24, 'window_1': 7, 'window_2': 3}. Best is trial 1 with value: 0.32690627723932264.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1/5, Loss: 0.8270\n",
      "   Epoch 2/5, Loss: 0.8030\n",
      "   Epoch 3/5, Loss: 0.7914\n",
      "   Epoch 4/5, Loss: 0.7653\n",
      "   Epoch 5/5, Loss: 0.7318\n",
      "   Epoch 1/5, Loss: 0.3358\n",
      "   Epoch 2/5, Loss: 0.3304\n",
      "   Epoch 3/5, Loss: 0.3291\n",
      "   Epoch 4/5, Loss: 0.3254\n",
      "   Epoch 5/5, Loss: 0.3248\n",
      "   Epoch 1/5, Loss: 0.2522\n",
      "   Epoch 2/5, Loss: 0.2506\n",
      "   Epoch 3/5, Loss: 0.2504\n",
      "   Epoch 4/5, Loss: 0.2469\n",
      "   Epoch 5/5, Loss: 0.2504\n",
      "   Epoch 1/5, Loss: 0.3607\n",
      "   Epoch 2/5, Loss: 0.3549\n",
      "   Epoch 3/5, Loss: 0.3588\n",
      "   Epoch 4/5, Loss: 0.3566\n",
      "   Early stopping at epoch 4\n",
      "   Epoch 1/5, Loss: 0.2763\n",
      "   Epoch 2/5, Loss: 0.2723\n",
      "   Epoch 3/5, Loss: 0.2682\n",
      "   Epoch 4/5, Loss: 0.2672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 02:11:16,582] Trial 2 finished with value: 0.38291517198085784 and parameters: {'hidden_size': 68, 'num_layers': 3, 'dropout': 0.0634383180311241, 'lr': 0.009213723701809375, 'time_step_in': 45, 'time_step_out': 4, 'stride': 3, 'num_lags': 2, 'lag_0': 4, 'lag_1': 5, 'num_windows': 1, 'window_0': 24}. Best is trial 1 with value: 0.32690627723932264.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 5/5, Loss: 0.2639\n",
      "   Epoch 1/5, Loss: 0.9149\n",
      "   Epoch 2/5, Loss: 0.9048\n",
      "   Epoch 3/5, Loss: 0.9001\n",
      "   Epoch 4/5, Loss: 0.8891\n",
      "   Epoch 5/5, Loss: 0.8765\n",
      "   Epoch 1/5, Loss: 0.3797\n",
      "   Epoch 2/5, Loss: 0.3647\n",
      "   Epoch 3/5, Loss: 0.3490\n",
      "   Epoch 4/5, Loss: 0.3446\n",
      "   Epoch 5/5, Loss: 0.3374\n",
      "   Epoch 1/5, Loss: 0.2742\n",
      "   Epoch 2/5, Loss: 0.2709\n",
      "   Epoch 3/5, Loss: 0.2659\n",
      "   Epoch 4/5, Loss: 0.2645\n",
      "   Epoch 5/5, Loss: 0.2535\n",
      "   Epoch 1/5, Loss: 0.4015\n",
      "   Epoch 2/5, Loss: 0.3905\n",
      "   Epoch 3/5, Loss: 0.3839\n",
      "   Epoch 4/5, Loss: 0.3741\n",
      "   Epoch 5/5, Loss: 0.3621\n",
      "   Epoch 1/5, Loss: 0.2880\n",
      "   Epoch 2/5, Loss: 0.2791\n",
      "   Epoch 3/5, Loss: 0.2712\n",
      "   Epoch 4/5, Loss: 0.2658\n",
      "   Epoch 5/5, Loss: 0.2613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 02:13:00,209] Trial 3 finished with value: 0.27653692066669466 and parameters: {'hidden_size': 153, 'num_layers': 3, 'dropout': 0.03325110439437351, 'lr': 0.000387997897226857, 'time_step_in': 43, 'time_step_out': 3, 'stride': 6, 'num_lags': 3, 'lag_0': 10, 'lag_1': 4, 'lag_2': 12, 'num_windows': 1, 'window_0': 10}. Best is trial 3 with value: 0.27653692066669466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1/5, Loss: 0.6293\n",
      "   Epoch 2/5, Loss: 0.6248\n",
      "   Epoch 3/5, Loss: 0.6228\n",
      "   Epoch 4/5, Loss: 0.6200\n",
      "   Epoch 5/5, Loss: 0.6153\n",
      "   Epoch 1/5, Loss: 0.3409\n",
      "   Epoch 2/5, Loss: 0.3355\n",
      "   Epoch 3/5, Loss: 0.3309\n",
      "   Epoch 4/5, Loss: 0.3250\n",
      "   Epoch 5/5, Loss: 0.3193\n",
      "   Epoch 1/5, Loss: 0.3192\n",
      "   Epoch 2/5, Loss: 0.3123\n",
      "   Epoch 3/5, Loss: 0.3098\n",
      "   Epoch 4/5, Loss: 0.3005\n",
      "   Epoch 5/5, Loss: 0.2999\n",
      "   Epoch 1/5, Loss: 0.3621\n",
      "   Epoch 2/5, Loss: 0.3587\n",
      "   Epoch 3/5, Loss: 0.3535\n",
      "   Epoch 4/5, Loss: 0.3487\n",
      "   Epoch 5/5, Loss: 0.3432\n",
      "   Epoch 1/5, Loss: 0.2870\n",
      "   Epoch 2/5, Loss: 0.2830\n",
      "   Epoch 3/5, Loss: 0.2806\n",
      "   Epoch 4/5, Loss: 0.2787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 02:13:46,349] Trial 4 finished with value: 0.42735969424247744 and parameters: {'hidden_size': 226, 'num_layers': 2, 'dropout': 0.3750988917248107, 'lr': 0.000140500484382055, 'time_step_in': 15, 'time_step_out': 4, 'stride': 5, 'num_lags': 3, 'lag_0': 2, 'lag_1': 3, 'lag_2': 2, 'num_windows': 2, 'window_0': 15, 'window_1': 7}. Best is trial 3 with value: 0.27653692066669466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 5/5, Loss: 0.2776\n",
      "   Epoch 1/5, Loss: 0.6203\n",
      "   Epoch 2/5, Loss: 0.6148\n",
      "   Epoch 3/5, Loss: 0.6106\n",
      "   Epoch 4/5, Loss: 0.6078\n",
      "   Epoch 5/5, Loss: 0.6045\n",
      "   Epoch 1/5, Loss: 0.3312\n",
      "   Epoch 2/5, Loss: 0.3240\n",
      "   Epoch 3/5, Loss: 0.3195\n",
      "   Epoch 4/5, Loss: 0.3139\n",
      "   Epoch 5/5, Loss: 0.3094\n",
      "   Epoch 1/5, Loss: 0.3290\n",
      "   Epoch 2/5, Loss: 0.3243\n",
      "   Epoch 3/5, Loss: 0.3208\n",
      "   Epoch 4/5, Loss: 0.3169\n",
      "   Epoch 5/5, Loss: 0.3148\n",
      "   Epoch 1/5, Loss: 0.3639\n",
      "   Epoch 2/5, Loss: 0.3582\n",
      "   Epoch 3/5, Loss: 0.3530\n",
      "   Epoch 4/5, Loss: 0.3481\n",
      "   Epoch 5/5, Loss: 0.3434\n",
      "   Epoch 1/5, Loss: 0.2843\n",
      "   Epoch 2/5, Loss: 0.2763\n",
      "   Epoch 3/5, Loss: 0.2729\n",
      "   Epoch 4/5, Loss: 0.2689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 02:14:45,278] Trial 5 finished with value: 0.4055803149938583 and parameters: {'hidden_size': 126, 'num_layers': 1, 'dropout': 0.3976450986595923, 'lr': 0.00018893041965793532, 'time_step_in': 19, 'time_step_out': 2, 'stride': 3, 'num_lags': 1, 'lag_0': 6, 'num_windows': 3, 'window_0': 12, 'window_1': 19, 'window_2': 12}. Best is trial 3 with value: 0.27653692066669466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 5/5, Loss: 0.2662\n",
      "   Epoch 1/5, Loss: 0.5532\n",
      "   Epoch 2/5, Loss: 0.5165\n",
      "   Epoch 3/5, Loss: 0.5139\n",
      "   Epoch 4/5, Loss: 0.4875\n",
      "   Epoch 5/5, Loss: 0.4799\n",
      "   Epoch 1/5, Loss: 0.2566\n",
      "   Epoch 2/5, Loss: 0.2512\n",
      "   Epoch 3/5, Loss: 0.2412\n",
      "   Epoch 4/5, Loss: 0.2357\n",
      "   Epoch 5/5, Loss: 0.2418\n",
      "   Epoch 1/5, Loss: 0.2050\n",
      "   Epoch 2/5, Loss: 0.2007\n",
      "   Epoch 3/5, Loss: 0.1965\n",
      "   Epoch 4/5, Loss: 0.1948\n",
      "   Epoch 5/5, Loss: 0.1906\n",
      "   Epoch 1/5, Loss: 0.2908\n",
      "   Epoch 2/5, Loss: 0.2819\n",
      "   Epoch 3/5, Loss: 0.2769\n",
      "   Epoch 4/5, Loss: 0.2705\n",
      "   Epoch 5/5, Loss: 0.2737\n",
      "   Epoch 1/5, Loss: 0.2294\n",
      "   Epoch 2/5, Loss: 0.2259\n",
      "   Epoch 3/5, Loss: 0.2225\n",
      "   Epoch 4/5, Loss: 0.2228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 02:15:53,974] Trial 6 finished with value: 0.3442407786846161 and parameters: {'hidden_size': 72, 'num_layers': 1, 'dropout': 0.19503725396482552, 'lr': 0.007431353026587681, 'time_step_in': 36, 'time_step_out': 1, 'stride': 3, 'num_lags': 1, 'lag_0': 11, 'num_windows': 3, 'window_0': 4, 'window_1': 12, 'window_2': 11}. Best is trial 3 with value: 0.27653692066669466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 5/5, Loss: 0.2187\n",
      "   Epoch 1/5, Loss: 0.7746\n",
      "   Epoch 2/5, Loss: 0.7667\n",
      "   Epoch 3/5, Loss: 0.7559\n",
      "   Epoch 4/5, Loss: 0.7374\n",
      "   Epoch 5/5, Loss: 0.7059\n",
      "   Epoch 1/5, Loss: 0.3366\n",
      "   Epoch 2/5, Loss: 0.3135\n",
      "   Epoch 3/5, Loss: 0.3007\n",
      "   Epoch 4/5, Loss: 0.2927\n",
      "   Epoch 5/5, Loss: 0.2823\n",
      "   Epoch 1/5, Loss: 0.2529\n",
      "   Epoch 2/5, Loss: 0.2479\n",
      "   Epoch 3/5, Loss: 0.2416\n",
      "   Epoch 4/5, Loss: 0.2337\n",
      "   Epoch 5/5, Loss: 0.2251\n",
      "   Epoch 1/5, Loss: 0.3637\n",
      "   Epoch 2/5, Loss: 0.3511\n",
      "   Epoch 3/5, Loss: 0.3348\n",
      "   Epoch 4/5, Loss: 0.3233\n",
      "   Epoch 5/5, Loss: 0.3195\n",
      "   Epoch 1/5, Loss: 0.2802\n",
      "   Epoch 2/5, Loss: 0.2741\n",
      "   Epoch 3/5, Loss: 0.2679\n",
      "   Epoch 4/5, Loss: 0.2570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 02:17:25,907] Trial 7 finished with value: 0.43418746888637544 and parameters: {'hidden_size': 79, 'num_layers': 2, 'dropout': 0.08303409411607982, 'lr': 0.00023490220123018266, 'time_step_in': 38, 'time_step_out': 6, 'stride': 2, 'num_lags': 2, 'lag_0': 7, 'lag_1': 6, 'num_windows': 1, 'window_0': 23}. Best is trial 3 with value: 0.27653692066669466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 5/5, Loss: 0.2521\n",
      "   Epoch 1/5, Loss: 0.5750\n",
      "   Epoch 2/5, Loss: 0.5605\n",
      "   Epoch 3/5, Loss: 0.5561\n",
      "   Epoch 4/5, Loss: 0.5547\n",
      "   Epoch 5/5, Loss: 0.5541\n",
      "   Epoch 1/5, Loss: 0.2931\n",
      "   Epoch 2/5, Loss: 0.2889\n",
      "   Epoch 3/5, Loss: 0.2873\n",
      "   Epoch 4/5, Loss: 0.2852\n",
      "   Epoch 5/5, Loss: 0.2831\n",
      "   Epoch 1/5, Loss: 0.2238\n",
      "   Epoch 2/5, Loss: 0.2220\n",
      "   Epoch 3/5, Loss: 0.2213\n",
      "   Epoch 4/5, Loss: 0.2207\n",
      "   Epoch 5/5, Loss: 0.2200\n",
      "   Epoch 1/5, Loss: 0.3198\n",
      "   Epoch 2/5, Loss: 0.3178\n",
      "   Epoch 3/5, Loss: 0.3165\n",
      "   Epoch 4/5, Loss: 0.3151\n",
      "   Epoch 5/5, Loss: 0.3138\n",
      "   Epoch 1/5, Loss: 0.2526\n",
      "   Epoch 2/5, Loss: 0.2411\n",
      "   Epoch 3/5, Loss: 0.2374\n",
      "   Epoch 4/5, Loss: 0.2361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 02:18:02,967] Trial 8 finished with value: 0.4205039143562317 and parameters: {'hidden_size': 59, 'num_layers': 1, 'dropout': 0.27318157634023715, 'lr': 0.00011097546006014463, 'time_step_in': 32, 'time_step_out': 4, 'stride': 6, 'num_lags': 1, 'lag_0': 12, 'num_windows': 2, 'window_0': 13, 'window_1': 17}. Best is trial 3 with value: 0.27653692066669466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 5/5, Loss: 0.2346\n",
      "   Epoch 1/5, Loss: 0.7245\n",
      "   Epoch 2/5, Loss: 0.7171\n",
      "   Epoch 3/5, Loss: 0.6914\n",
      "   Epoch 4/5, Loss: 0.7164\n",
      "   Epoch 5/5, Loss: 0.6890\n",
      "   Epoch 1/5, Loss: 0.3401\n",
      "   Epoch 2/5, Loss: 0.3323\n",
      "   Epoch 3/5, Loss: 0.3265\n",
      "   Epoch 4/5, Loss: 0.3128\n",
      "   Epoch 5/5, Loss: 0.3009\n",
      "   Epoch 1/5, Loss: 0.2614\n",
      "   Epoch 2/5, Loss: 0.2553\n",
      "   Epoch 3/5, Loss: 0.2499\n",
      "   Epoch 4/5, Loss: 0.2406\n",
      "   Epoch 5/5, Loss: 0.2402\n",
      "   Epoch 1/5, Loss: 0.3647\n",
      "   Epoch 2/5, Loss: 0.3557\n",
      "   Epoch 3/5, Loss: 0.3494\n",
      "   Epoch 4/5, Loss: 0.3432\n",
      "   Epoch 5/5, Loss: 0.3330\n",
      "   Epoch 1/5, Loss: 0.3008\n",
      "   Epoch 2/5, Loss: 0.2947\n",
      "   Epoch 3/5, Loss: 0.2925\n",
      "   Epoch 4/5, Loss: 0.2854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 02:18:43,744] Trial 9 finished with value: 0.443477475643158 and parameters: {'hidden_size': 127, 'num_layers': 2, 'dropout': 0.010014523491083116, 'lr': 0.0008823434347645746, 'time_step_in': 34, 'time_step_out': 4, 'stride': 6, 'num_lags': 1, 'lag_0': 11, 'num_windows': 1, 'window_0': 10}. Best is trial 3 with value: 0.27653692066669466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 5/5, Loss: 0.2821\n",
      "   Epoch 1/5, Loss: 0.8867\n",
      "   Epoch 2/5, Loss: 0.8772\n",
      "   Epoch 3/5, Loss: 0.8517\n",
      "   Epoch 4/5, Loss: 0.8495\n",
      "   Epoch 5/5, Loss: 0.8046\n",
      "   Epoch 1/5, Loss: 0.3552\n",
      "   Epoch 2/5, Loss: 0.3463\n",
      "   Epoch 3/5, Loss: 0.3230\n",
      "   Epoch 4/5, Loss: 0.3178\n",
      "   Epoch 5/5, Loss: 0.2989\n",
      "   Epoch 1/5, Loss: 0.2613\n",
      "   Epoch 2/5, Loss: 0.2531\n",
      "   Epoch 3/5, Loss: 0.2398\n",
      "   Epoch 4/5, Loss: 0.2264\n",
      "   Epoch 5/5, Loss: 0.2349\n",
      "   Epoch 1/5, Loss: 0.4053\n",
      "   Epoch 2/5, Loss: 0.3983\n",
      "   Epoch 3/5, Loss: 0.3904\n",
      "   Epoch 4/5, Loss: 0.3755\n",
      "   Epoch 5/5, Loss: 0.3716\n",
      "   Epoch 1/5, Loss: 0.2955\n",
      "   Epoch 2/5, Loss: 0.2834\n",
      "   Epoch 3/5, Loss: 0.2762\n",
      "   Epoch 4/5, Loss: 0.2711\n",
      "   Epoch 5/5, Loss: 0.2698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 02:20:42,484] Trial 10 finished with value: 0.3913621246814728 and parameters: {'hidden_size': 248, 'num_layers': 3, 'dropout': 0.17495171273333082, 'lr': 0.0007653760313794895, 'time_step_in': 47, 'time_step_out': 2, 'stride': 5, 'num_lags': 3, 'lag_0': 8, 'lag_1': 12, 'lag_2': 12, 'num_windows': 2, 'window_0': 6, 'window_1': 24}. Best is trial 3 with value: 0.27653692066669466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1/5, Loss: 0.6156\n",
      "   Epoch 2/5, Loss: 0.6016\n",
      "   Epoch 3/5, Loss: 0.6015\n",
      "   Epoch 4/5, Loss: 0.6106\n",
      "   Epoch 5/5, Loss: 0.5899\n",
      "   Epoch 1/5, Loss: 0.3157\n",
      "   Epoch 2/5, Loss: 0.3021\n",
      "   Epoch 3/5, Loss: 0.3015\n",
      "   Epoch 4/5, Loss: 0.2874\n",
      "   Epoch 5/5, Loss: 0.2905\n",
      "   Epoch 1/5, Loss: 0.2892\n",
      "   Epoch 2/5, Loss: 0.2896\n",
      "   Epoch 3/5, Loss: 0.2916\n",
      "   Early stopping at epoch 3\n",
      "   Epoch 1/5, Loss: 0.3460\n",
      "   Epoch 2/5, Loss: 0.3457\n",
      "   Epoch 3/5, Loss: 0.3422\n",
      "   Epoch 4/5, Loss: 0.3416\n",
      "   Epoch 5/5, Loss: 0.3397\n",
      "   Epoch 1/5, Loss: 0.2726\n",
      "   Epoch 2/5, Loss: 0.2676\n",
      "   Epoch 3/5, Loss: 0.2653\n",
      "   Epoch 4/5, Loss: 0.2644\n",
      "   Epoch 5/5, Loss: 0.2622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 02:22:27,202] Trial 11 finished with value: 0.3579388827085495 and parameters: {'hidden_size': 188, 'num_layers': 3, 'dropout': 0.4941576449366015, 'lr': 0.0029905615406039202, 'time_step_in': 25, 'time_step_out': 6, 'stride': 5, 'num_lags': 2, 'lag_0': 9, 'lag_1': 9, 'num_windows': 2, 'window_0': 18, 'window_1': 3}. Best is trial 3 with value: 0.27653692066669466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1/5, Loss: 0.8387\n",
      "   Epoch 2/5, Loss: 0.8201\n",
      "   Epoch 3/5, Loss: 0.8100\n",
      "   Epoch 4/5, Loss: 0.8071\n",
      "   Epoch 5/5, Loss: 0.8043\n",
      "   Epoch 1/5, Loss: 0.3516\n",
      "   Epoch 2/5, Loss: 0.3422\n",
      "   Epoch 3/5, Loss: 0.3284\n",
      "   Epoch 4/5, Loss: 0.3237\n",
      "   Epoch 5/5, Loss: 0.3152\n",
      "   Epoch 1/5, Loss: 0.2681\n",
      "   Epoch 2/5, Loss: 0.2647\n",
      "   Epoch 3/5, Loss: 0.2602\n",
      "   Epoch 4/5, Loss: 0.2597\n",
      "   Epoch 5/5, Loss: 0.2616\n",
      "   Epoch 1/5, Loss: 0.3690\n",
      "   Epoch 2/5, Loss: 0.3625\n",
      "   Epoch 3/5, Loss: 0.3625\n",
      "   Epoch 4/5, Loss: 0.3574\n",
      "   Epoch 5/5, Loss: 0.3478\n",
      "   Epoch 1/5, Loss: 0.2877\n",
      "   Epoch 2/5, Loss: 0.2819\n",
      "   Epoch 3/5, Loss: 0.2801\n",
      "   Epoch 4/5, Loss: 0.2759\n",
      "   Epoch 5/5, Loss: 0.2777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 02:24:33,314] Trial 12 finished with value: 0.45231848359107973 and parameters: {'hidden_size': 201, 'num_layers': 3, 'dropout': 0.2992387595556103, 'lr': 0.0024244627852470536, 'time_step_in': 41, 'time_step_out': 5, 'stride': 4, 'num_lags': 2, 'lag_0': 5, 'lag_1': 8, 'num_windows': 3, 'window_0': 9, 'window_1': 8, 'window_2': 3}. Best is trial 3 with value: 0.27653692066669466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1/5, Loss: 0.4717\n",
      "   Epoch 2/5, Loss: 0.4686\n",
      "   Epoch 3/5, Loss: 0.4667\n",
      "   Epoch 4/5, Loss: 0.4644\n",
      "   Epoch 5/5, Loss: 0.4601\n",
      "   Epoch 1/5, Loss: 0.2680\n",
      "   Epoch 2/5, Loss: 0.2620\n",
      "   Epoch 3/5, Loss: 0.2562\n",
      "   Epoch 4/5, Loss: 0.2552\n",
      "   Epoch 5/5, Loss: 0.2520\n",
      "   Epoch 1/5, Loss: 0.3078\n",
      "   Epoch 2/5, Loss: 0.2992\n",
      "   Epoch 3/5, Loss: 0.2925\n",
      "   Epoch 4/5, Loss: 0.2912\n",
      "   Epoch 5/5, Loss: 0.2789\n",
      "   Epoch 1/5, Loss: 0.2793\n",
      "   Epoch 2/5, Loss: 0.2757\n",
      "   Epoch 3/5, Loss: 0.2721\n",
      "   Epoch 4/5, Loss: 0.2681\n",
      "   Epoch 5/5, Loss: 0.2627\n",
      "   Epoch 1/5, Loss: 0.2335\n",
      "   Epoch 2/5, Loss: 0.2292\n",
      "   Epoch 3/5, Loss: 0.2276\n",
      "   Epoch 4/5, Loss: 0.2256\n",
      "   Epoch 5/5, Loss: 0.2243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 02:25:41,331] Trial 13 finished with value: 0.4294796854257584 and parameters: {'hidden_size': 162, 'num_layers': 2, 'dropout': 0.18386582499399293, 'lr': 0.0004548276598081751, 'time_step_in': 27, 'time_step_out': 3, 'stride': 6, 'num_lags': 3, 'lag_0': 9, 'lag_1': 5, 'lag_2': 12, 'num_windows': 1, 'window_0': 17}. Best is trial 3 with value: 0.27653692066669466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1/5, Loss: 0.8163\n",
      "   Epoch 2/5, Loss: 0.7900\n",
      "   Epoch 3/5, Loss: 0.7567\n",
      "   Epoch 4/5, Loss: 0.7386\n",
      "   Epoch 5/5, Loss: 0.7300\n",
      "   Epoch 1/5, Loss: 0.3386\n",
      "   Epoch 2/5, Loss: 0.3199\n",
      "   Epoch 3/5, Loss: 0.3104\n",
      "   Epoch 4/5, Loss: 0.3043\n",
      "   Epoch 5/5, Loss: 0.2979\n",
      "   Epoch 1/5, Loss: 0.2605\n",
      "   Epoch 2/5, Loss: 0.2549\n",
      "   Epoch 3/5, Loss: 0.2505\n",
      "   Epoch 4/5, Loss: 0.2478\n",
      "   Epoch 5/5, Loss: 0.2418\n",
      "   Epoch 1/5, Loss: 0.3718\n",
      "   Epoch 2/5, Loss: 0.3627\n",
      "   Epoch 3/5, Loss: 0.3594\n",
      "   Epoch 4/5, Loss: 0.3600\n",
      "   Epoch 5/5, Loss: 0.3601\n",
      "   Early stopping at epoch 5\n",
      "   Epoch 1/5, Loss: 0.2780\n",
      "   Epoch 2/5, Loss: 0.2716\n",
      "   Epoch 3/5, Loss: 0.2689\n",
      "   Epoch 4/5, Loss: 0.2647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 02:26:47,064] Trial 14 finished with value: 0.40571823716163635 and parameters: {'hidden_size': 107, 'num_layers': 2, 'dropout': 0.319985091847223, 'lr': 0.0024117348389916357, 'time_step_in': 42, 'time_step_out': 5, 'stride': 4, 'num_lags': 2, 'lag_0': 8, 'lag_1': 1, 'num_windows': 2, 'window_0': 8, 'window_1': 4}. Best is trial 3 with value: 0.27653692066669466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 5/5, Loss: 0.2660\n",
      "   Epoch 1/5, Loss: 0.6581\n",
      "   Epoch 2/5, Loss: 0.6231\n",
      "   Epoch 3/5, Loss: 0.6135\n",
      "   Epoch 4/5, Loss: 0.6175\n",
      "   Epoch 5/5, Loss: 0.6173\n",
      "   Early stopping at epoch 5\n",
      "   Epoch 1/5, Loss: 0.3164\n",
      "   Epoch 2/5, Loss: 0.3021\n",
      "   Epoch 3/5, Loss: 0.2979\n",
      "   Epoch 4/5, Loss: 0.2958\n",
      "   Epoch 5/5, Loss: 0.3013\n",
      "   Epoch 1/5, Loss: 0.2511\n",
      "   Epoch 2/5, Loss: 0.2487\n",
      "   Epoch 3/5, Loss: 0.2477\n",
      "   Epoch 4/5, Loss: 0.2495\n",
      "   Epoch 5/5, Loss: 0.2509\n",
      "   Early stopping at epoch 5\n",
      "   Epoch 1/5, Loss: 0.3228\n",
      "   Epoch 2/5, Loss: 0.3191\n",
      "   Epoch 3/5, Loss: 0.3183\n",
      "   Epoch 4/5, Loss: 0.3139\n",
      "   Epoch 5/5, Loss: 0.3122\n",
      "   Epoch 1/5, Loss: 0.2638\n",
      "   Epoch 2/5, Loss: 0.2576\n",
      "   Epoch 3/5, Loss: 0.2549\n",
      "   Epoch 4/5, Loss: 0.2516\n",
      "   Epoch 5/5, Loss: 0.2523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 02:28:54,095] Trial 15 finished with value: 0.37301172912120817 and parameters: {'hidden_size': 181, 'num_layers': 3, 'dropout': 0.11998621364501888, 'lr': 0.0047015069712108915, 'time_step_in': 29, 'time_step_out': 3, 'stride': 5, 'num_lags': 3, 'lag_0': 1, 'lag_1': 8, 'lag_2': 8, 'num_windows': 3, 'window_0': 20, 'window_1': 9, 'window_2': 3}. Best is trial 3 with value: 0.27653692066669466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1/5, Loss: 0.8151\n",
      "   Epoch 2/5, Loss: 0.7999\n",
      "   Epoch 3/5, Loss: 0.7927\n",
      "   Epoch 4/5, Loss: 0.7532\n",
      "   Epoch 5/5, Loss: 0.7542\n",
      "   Epoch 1/5, Loss: 0.3483\n",
      "   Epoch 2/5, Loss: 0.3253\n",
      "   Epoch 3/5, Loss: 0.3188\n",
      "   Epoch 4/5, Loss: 0.3108\n",
      "   Epoch 5/5, Loss: 0.3129\n",
      "   Epoch 1/5, Loss: 0.2669\n",
      "   Epoch 2/5, Loss: 0.2620\n",
      "   Epoch 3/5, Loss: 0.2521\n",
      "   Epoch 4/5, Loss: 0.2479\n",
      "   Epoch 5/5, Loss: 0.2430\n",
      "   Epoch 1/5, Loss: 0.3850\n",
      "   Epoch 2/5, Loss: 0.3772\n",
      "   Epoch 3/5, Loss: 0.3678\n",
      "   Epoch 4/5, Loss: 0.3693\n",
      "   Epoch 5/5, Loss: 0.3616\n",
      "   Epoch 1/5, Loss: 0.2991\n",
      "   Epoch 2/5, Loss: 0.2915\n",
      "   Epoch 3/5, Loss: 0.2878\n",
      "   Epoch 4/5, Loss: 0.2821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 02:29:56,626] Trial 16 finished with value: 0.32682636454701425 and parameters: {'hidden_size': 219, 'num_layers': 2, 'dropout': 0.004896055557927926, 'lr': 0.0015948380699362815, 'time_step_in': 40, 'time_step_out': 5, 'stride': 6, 'num_lags': 2, 'lag_0': 7, 'lag_1': 4, 'num_windows': 1, 'window_0': 15}. Best is trial 3 with value: 0.27653692066669466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 5/5, Loss: 0.2723\n",
      "   Epoch 1/5, Loss: 0.9099\n",
      "   Epoch 2/5, Loss: 0.8989\n",
      "   Epoch 3/5, Loss: 0.8795\n",
      "   Epoch 4/5, Loss: 0.8731\n",
      "   Epoch 5/5, Loss: 0.8127\n",
      "   Epoch 1/5, Loss: 0.3617\n",
      "   Epoch 2/5, Loss: 0.3482\n",
      "   Epoch 3/5, Loss: 0.3454\n",
      "   Epoch 4/5, Loss: 0.3282\n",
      "   Epoch 5/5, Loss: 0.3224\n",
      "   Epoch 1/5, Loss: 0.2643\n",
      "   Epoch 2/5, Loss: 0.2609\n",
      "   Epoch 3/5, Loss: 0.2563\n",
      "   Epoch 4/5, Loss: 0.2551\n",
      "   Epoch 5/5, Loss: 0.2493\n",
      "   Epoch 1/5, Loss: 0.3770\n",
      "   Epoch 2/5, Loss: 0.3671\n",
      "   Epoch 3/5, Loss: 0.3554\n",
      "   Epoch 4/5, Loss: 0.3513\n",
      "   Epoch 5/5, Loss: 0.3505\n",
      "   Epoch 1/5, Loss: 0.2830\n",
      "   Epoch 2/5, Loss: 0.2733\n",
      "   Epoch 3/5, Loss: 0.2657\n",
      "   Epoch 4/5, Loss: 0.2634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 02:31:07,575] Trial 17 finished with value: 0.371825635433197 and parameters: {'hidden_size': 219, 'num_layers': 2, 'dropout': 0.015521935600509122, 'lr': 0.0013375889610611625, 'time_step_in': 48, 'time_step_out': 5, 'stride': 6, 'num_lags': 2, 'lag_0': 4, 'lag_1': 4, 'num_windows': 1, 'window_0': 16}. Best is trial 3 with value: 0.27653692066669466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 5/5, Loss: 0.2582\n",
      "   Epoch 1/5, Loss: 0.7856\n",
      "   Epoch 2/5, Loss: 0.7756\n",
      "   Epoch 3/5, Loss: 0.7594\n",
      "   Epoch 4/5, Loss: 0.7429\n",
      "   Epoch 5/5, Loss: 0.7293\n",
      "   Epoch 1/5, Loss: 0.3494\n",
      "   Epoch 2/5, Loss: 0.3373\n",
      "   Epoch 3/5, Loss: 0.3330\n",
      "   Epoch 4/5, Loss: 0.3241\n",
      "   Epoch 5/5, Loss: 0.3293\n",
      "   Epoch 1/5, Loss: 0.2678\n",
      "   Epoch 2/5, Loss: 0.2656\n",
      "   Epoch 3/5, Loss: 0.2620\n",
      "   Epoch 4/5, Loss: 0.2579\n",
      "   Epoch 5/5, Loss: 0.2592\n",
      "   Epoch 1/5, Loss: 0.3789\n",
      "   Epoch 2/5, Loss: 0.3675\n",
      "   Epoch 3/5, Loss: 0.3620\n",
      "   Epoch 4/5, Loss: 0.3557\n",
      "   Epoch 5/5, Loss: 0.3519\n",
      "   Epoch 1/5, Loss: 0.2863\n",
      "   Epoch 2/5, Loss: 0.2762\n",
      "   Epoch 3/5, Loss: 0.2702\n",
      "   Epoch 4/5, Loss: 0.2664\n",
      "   Epoch 5/5, Loss: 0.2659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 02:33:18,104] Trial 18 finished with value: 0.34793316274881364 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.11534744364756988, 'lr': 0.0005871134904983957, 'time_step_in': 41, 'time_step_out': 3, 'stride': 4, 'num_lags': 3, 'lag_0': 6, 'lag_1': 3, 'lag_2': 2, 'num_windows': 1, 'window_0': 11}. Best is trial 3 with value: 0.27653692066669466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1/5, Loss: 0.9466\n",
      "   Epoch 2/5, Loss: 0.9288\n",
      "   Epoch 3/5, Loss: 0.9168\n",
      "   Epoch 4/5, Loss: 0.9128\n",
      "   Epoch 5/5, Loss: 0.8945\n",
      "   Epoch 1/5, Loss: 0.3846\n",
      "   Epoch 2/5, Loss: 0.3715\n",
      "   Epoch 3/5, Loss: 0.3646\n",
      "   Epoch 4/5, Loss: 0.3592\n",
      "   Epoch 5/5, Loss: 0.3549\n",
      "   Epoch 1/5, Loss: 0.2770\n",
      "   Epoch 2/5, Loss: 0.2732\n",
      "   Epoch 3/5, Loss: 0.2698\n",
      "   Epoch 4/5, Loss: 0.2525\n",
      "   Epoch 5/5, Loss: 0.2266\n",
      "   Epoch 1/5, Loss: 0.4475\n",
      "   Epoch 2/5, Loss: 0.4267\n",
      "   Epoch 3/5, Loss: 0.4006\n",
      "   Epoch 4/5, Loss: 0.3817\n",
      "   Epoch 5/5, Loss: 0.3567\n",
      "   Epoch 1/5, Loss: 0.2754\n",
      "   Epoch 2/5, Loss: 0.2656\n",
      "   Epoch 3/5, Loss: 0.2563\n",
      "   Epoch 4/5, Loss: 0.2370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 02:33:59,083] Trial 19 finished with value: 0.32652166187763215 and parameters: {'hidden_size': 40, 'num_layers': 3, 'dropout': 0.00034863480188733476, 'lr': 0.0011201326024500326, 'time_step_in': 44, 'time_step_out': 1, 'stride': 6, 'num_lags': 3, 'lag_0': 10, 'lag_1': 1, 'lag_2': 10, 'num_windows': 1, 'window_0': 14}. Best is trial 3 with value: 0.27653692066669466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 5/5, Loss: 0.2348\n",
      " Best parameters for 2019-04:\n",
      "  hidden_size: 153\n",
      "  num_layers: 3\n",
      "  dropout: 0.03325110439437351\n",
      "  lr: 0.000387997897226857\n",
      "  time_step_in: 43\n",
      "  time_step_out: 3\n",
      "  stride: 6\n",
      "  num_lags: 3\n",
      "  lag_0: 10\n",
      "  lag_1: 4\n",
      "  lag_2: 12\n",
      "  num_windows: 1\n",
      "  window_0: 10\n",
      " Best parameters saved to best_params_2019-04.json\n",
      "\n",
      " Final evaluation on 2019-04, fold_1 test set\n",
      "\n",
      "====== Training model for 2019-04, fold_1 with best parameters\n",
      "====== Training model on train set...\n",
      "   Epoch 1/10, Loss: 0.9124\n",
      "   Epoch 2/10, Loss: 0.9039\n",
      "   Epoch 3/10, Loss: 0.8981\n",
      "   Epoch 4/10, Loss: 0.8864\n",
      "   Epoch 5/10, Loss: 0.8623\n",
      "   Epoch 6/10, Loss: 0.8316\n",
      "   Epoch 7/10, Loss: 0.8880\n",
      "   Epoch 8/10, Loss: 0.8478\n",
      "   Epoch 9/10, Loss: 0.8301\n",
      "   Epoch 10/10, Loss: 0.8169\n",
      "====== Evaluating on validation set...\n",
      "  Val RMSE: 0.2077, Bias: 0.0890, R²: -0.2664, CSI: 0.0054\n",
      "====== Evaluating on test set...\n",
      "  Test RMSE: 1.2517, Bias: -0.1537, R²: -0.0233, CSI: 0.0555\n",
      " Model saved to model_2019-04_fold_1.pt\n",
      "\n",
      " Final evaluation on 2019-04, fold_2 test set\n",
      "\n",
      "====== Training model for 2019-04, fold_2 with best parameters\n",
      "====== Training model on train set...\n",
      "   Epoch 1/10, Loss: 0.3783\n",
      "   Epoch 2/10, Loss: 0.3600\n",
      "   Epoch 3/10, Loss: 0.3561\n",
      "   Epoch 4/10, Loss: 0.3424\n",
      "   Epoch 5/10, Loss: 0.3344\n",
      "   Epoch 6/10, Loss: 0.3239\n",
      "   Epoch 7/10, Loss: 0.3158\n",
      "   Epoch 8/10, Loss: 0.3688\n",
      "   Epoch 9/10, Loss: 0.3628\n",
      "   Epoch 10/10, Loss: 0.3538\n",
      "====== Evaluating on validation set...\n",
      "  Val RMSE: 0.3027, Bias: -0.0345, R²: -0.0293, CSI: 0.0000\n",
      "====== Evaluating on test set...\n",
      "  Test RMSE: 1.2513, Bias: -0.2065, R²: -0.0225, CSI: 0.1196\n",
      " Model saved to model_2019-04_fold_2.pt\n",
      "\n",
      " Final evaluation on 2019-04, fold_3 test set\n",
      "\n",
      "====== Training model for 2019-04, fold_3 with best parameters\n",
      "====== Training model on train set...\n",
      "   Epoch 1/10, Loss: 0.2733\n",
      "   Epoch 2/10, Loss: 0.2698\n",
      "   Epoch 3/10, Loss: 0.2668\n",
      "   Epoch 4/10, Loss: 0.2625\n",
      "   Epoch 5/10, Loss: 0.2657\n",
      "   Epoch 6/10, Loss: 0.2615\n",
      "   Epoch 7/10, Loss: 0.2463\n",
      "   Epoch 8/10, Loss: 0.2518\n",
      "   Epoch 9/10, Loss: 0.2438\n",
      "   Epoch 10/10, Loss: 0.2388\n",
      "====== Evaluating on validation set...\n",
      "  Val RMSE: 0.7427, Bias: -0.0024, R²: -0.0862, CSI: 0.1090\n",
      "====== Evaluating on test set...\n",
      "  Test RMSE: 1.2763, Bias: -0.0815, R²: -0.0639, CSI: 0.0825\n",
      " Model saved to model_2019-04_fold_3.pt\n",
      "\n",
      " Final evaluation on 2019-04, fold_4 test set\n",
      "\n",
      "====== Training model for 2019-04, fold_4 with best parameters\n",
      "====== Training model on train set...\n",
      "   Epoch 1/10, Loss: 0.4016\n",
      "   Epoch 2/10, Loss: 0.3918\n",
      "   Epoch 3/10, Loss: 0.3819\n",
      "   Epoch 4/10, Loss: 0.3737\n",
      "   Epoch 5/10, Loss: 0.3654\n",
      "   Epoch 6/10, Loss: 0.3565\n",
      "   Epoch 7/10, Loss: 0.3500\n",
      "   Epoch 8/10, Loss: 0.3558\n",
      "   Epoch 9/10, Loss: 0.3465\n",
      "   Epoch 10/10, Loss: 0.3338\n",
      "====== Evaluating on validation set...\n",
      "  Val RMSE: 0.0416, Bias: 0.0130, R²: -2.8245, CSI: 0.0000\n",
      "====== Evaluating on test set...\n",
      "  Test RMSE: 1.2458, Bias: -0.1290, R²: -0.0137, CSI: 0.1116\n",
      " Model saved to model_2019-04_fold_4.pt\n",
      "\n",
      " Final evaluation on 2019-04, fold_5 test set\n",
      "\n",
      "====== Training model for 2019-04, fold_5 with best parameters\n",
      "====== Training model on train set...\n",
      "   Epoch 1/10, Loss: 0.2883\n",
      "   Epoch 2/10, Loss: 0.2795\n",
      "   Epoch 3/10, Loss: 0.2725\n",
      "   Epoch 4/10, Loss: 0.2654\n",
      "   Epoch 5/10, Loss: 0.2616\n",
      "   Epoch 6/10, Loss: 0.2563\n",
      "   Epoch 7/10, Loss: 0.2487\n",
      "   Epoch 8/10, Loss: 0.2588\n",
      "   Epoch 9/10, Loss: 0.2545\n",
      "   Epoch 10/10, Loss: 0.2461\n",
      "====== Evaluating on validation set...\n",
      "  Val RMSE: 0.1466, Bias: 0.0464, R²: -0.0085, CSI: 0.6523\n",
      "====== Evaluating on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 02:37:04,606] A new study created in memory with name: 2019-10_study\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Test RMSE: 1.2381, Bias: -0.1335, R²: -0.0011, CSI: 0.0965\n",
      " Model saved to model_2019-04_fold_5.pt\n",
      "\n",
      " Mean test performance for 2019-04:\n",
      "  RMSE: 1.2526, Bias: -0.1408, R²: -0.0249, CSI: 0.0931\n",
      " Best fold test performance for 2019-04 (fold fold_5):\n",
      "  RMSE: 1.2381, Bias: -0.1335, R²: -0.0011, CSI: 0.0965\n",
      " Best model for 2019-04 saved to best_model_2019-04.pt\n",
      "\n",
      "###### Processing month: 2019-10\n",
      "   Epoch 1/5, Loss: 0.6655\n",
      "   Epoch 2/5, Loss: 0.6448\n",
      "   Epoch 3/5, Loss: 0.6304\n",
      "   Epoch 4/5, Loss: 0.6283\n",
      "   Epoch 5/5, Loss: 0.6079\n",
      "   Epoch 1/5, Loss: 0.6917\n",
      "   Epoch 2/5, Loss: 0.6613\n",
      "   Epoch 3/5, Loss: 0.6578\n",
      "   Epoch 4/5, Loss: 0.6470\n",
      "   Epoch 5/5, Loss: 0.6372\n",
      "   Epoch 1/5, Loss: 0.6993\n",
      "   Epoch 2/5, Loss: 0.6694\n",
      "   Epoch 3/5, Loss: 0.6562\n",
      "   Epoch 4/5, Loss: 0.6470\n",
      "   Epoch 5/5, Loss: 0.6410\n",
      "   Epoch 1/5, Loss: 0.7145\n",
      "   Epoch 2/5, Loss: 0.6903\n",
      "   Epoch 3/5, Loss: 0.6833\n",
      "   Epoch 4/5, Loss: 0.6742\n",
      "   Epoch 5/5, Loss: 0.6671\n",
      "   Epoch 1/5, Loss: 0.7222\n",
      "   Epoch 2/5, Loss: 0.6995\n",
      "   Epoch 3/5, Loss: 0.6879\n",
      "   Epoch 4/5, Loss: 0.6802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 02:38:22,545] Trial 0 finished with value: 0.5650564670562744 and parameters: {'hidden_size': 56, 'num_layers': 2, 'dropout': 0.31547755211880746, 'lr': 0.002220210621489526, 'time_step_in': 31, 'time_step_out': 6, 'stride': 2, 'num_lags': 1, 'lag_0': 11, 'num_windows': 1, 'window_0': 20}. Best is trial 0 with value: 0.5650564670562744.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 5/5, Loss: 0.6718\n",
      "   Epoch 1/5, Loss: 0.6400\n",
      "   Epoch 2/5, Loss: 0.6328\n",
      "   Epoch 3/5, Loss: 0.6257\n",
      "   Epoch 4/5, Loss: 0.6221\n",
      "   Epoch 5/5, Loss: 0.6201\n",
      "   Epoch 1/5, Loss: 0.7721\n",
      "   Epoch 2/5, Loss: 0.7189\n",
      "   Epoch 3/5, Loss: 0.7064\n",
      "   Epoch 4/5, Loss: 0.7020\n",
      "   Epoch 5/5, Loss: 0.6919\n",
      "   Epoch 1/5, Loss: 0.7611\n",
      "   Epoch 2/5, Loss: 0.7200\n",
      "   Epoch 3/5, Loss: 0.7096\n",
      "   Epoch 4/5, Loss: 0.6987\n",
      "   Epoch 5/5, Loss: 0.6853\n",
      "   Epoch 1/5, Loss: 0.7458\n",
      "   Epoch 2/5, Loss: 0.7208\n",
      "   Epoch 3/5, Loss: 0.7054\n",
      "   Epoch 4/5, Loss: 0.6936\n",
      "   Epoch 5/5, Loss: 0.6801\n",
      "   Epoch 1/5, Loss: 0.7625\n",
      "   Epoch 2/5, Loss: 0.7099\n",
      "   Epoch 3/5, Loss: 0.7005\n",
      "   Epoch 4/5, Loss: 0.6899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 02:39:03,731] Trial 1 finished with value: 0.6109803438186645 and parameters: {'hidden_size': 58, 'num_layers': 3, 'dropout': 0.46202524518694527, 'lr': 0.00039354679713878173, 'time_step_in': 39, 'time_step_out': 2, 'stride': 6, 'num_lags': 1, 'lag_0': 7, 'num_windows': 3, 'window_0': 9, 'window_1': 23, 'window_2': 7}. Best is trial 0 with value: 0.5650564670562744.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 5/5, Loss: 0.6836\n",
      "   Epoch 1/5, Loss: 0.6362\n",
      "   Epoch 2/5, Loss: 0.5994\n",
      "   Epoch 3/5, Loss: 0.5764\n",
      "   Epoch 4/5, Loss: 0.5758\n",
      "   Epoch 5/5, Loss: 0.5661\n",
      "   Epoch 1/5, Loss: 0.6424\n",
      "   Epoch 2/5, Loss: 0.6052\n",
      "   Epoch 3/5, Loss: 0.5997\n",
      "   Epoch 4/5, Loss: 0.5919\n",
      "   Epoch 5/5, Loss: 0.5924\n",
      "   Epoch 1/5, Loss: 0.6547\n",
      "   Epoch 2/5, Loss: 0.6218\n",
      "   Epoch 3/5, Loss: 0.6158\n",
      "   Epoch 4/5, Loss: 0.6083\n",
      "   Epoch 5/5, Loss: 0.6033\n",
      "   Epoch 1/5, Loss: 0.6698\n",
      "   Epoch 2/5, Loss: 0.6452\n",
      "   Epoch 3/5, Loss: 0.6389\n",
      "   Epoch 4/5, Loss: 0.6312\n",
      "   Epoch 5/5, Loss: 0.6288\n",
      "   Epoch 1/5, Loss: 0.6690\n",
      "   Epoch 2/5, Loss: 0.6464\n",
      "   Epoch 3/5, Loss: 0.6406\n",
      "   Epoch 4/5, Loss: 0.6357\n",
      "   Epoch 5/5, Loss: 0.6317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 02:43:19,238] Trial 2 finished with value: 0.5346689105033875 and parameters: {'hidden_size': 213, 'num_layers': 3, 'dropout': 0.4489976529976379, 'lr': 0.0006299998432530625, 'time_step_in': 25, 'time_step_out': 2, 'stride': 1, 'num_lags': 2, 'lag_0': 11, 'lag_1': 6, 'num_windows': 3, 'window_0': 7, 'window_1': 8, 'window_2': 17}. Best is trial 2 with value: 0.5346689105033875.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1/5, Loss: 0.6913\n",
      "   Epoch 2/5, Loss: 0.6634\n",
      "   Epoch 3/5, Loss: 0.6568\n",
      "   Epoch 4/5, Loss: 0.6536\n",
      "   Epoch 5/5, Loss: 0.6514\n",
      "   Epoch 1/5, Loss: 0.7425\n",
      "   Epoch 2/5, Loss: 0.6921\n",
      "   Epoch 3/5, Loss: 0.6834\n",
      "   Epoch 4/5, Loss: 0.6768\n",
      "   Epoch 5/5, Loss: 0.6687\n",
      "   Epoch 1/5, Loss: 0.7285\n",
      "   Epoch 2/5, Loss: 0.6961\n",
      "   Epoch 3/5, Loss: 0.6857\n",
      "   Epoch 4/5, Loss: 0.6775\n",
      "   Epoch 5/5, Loss: 0.6706\n",
      "   Epoch 1/5, Loss: 0.7325\n",
      "   Epoch 2/5, Loss: 0.7089\n",
      "   Epoch 3/5, Loss: 0.6988\n",
      "   Epoch 4/5, Loss: 0.6907\n",
      "   Epoch 5/5, Loss: 0.6859\n",
      "   Epoch 1/5, Loss: 0.7520\n",
      "   Epoch 2/5, Loss: 0.7174\n",
      "   Epoch 3/5, Loss: 0.7064\n",
      "   Epoch 4/5, Loss: 0.6993\n",
      "   Epoch 5/5, Loss: 0.6927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 02:44:46,759] Trial 3 finished with value: 0.6438467383384705 and parameters: {'hidden_size': 103, 'num_layers': 2, 'dropout': 0.3050662291462312, 'lr': 0.00011808706530505704, 'time_step_in': 34, 'time_step_out': 6, 'stride': 2, 'num_lags': 1, 'lag_0': 3, 'num_windows': 1, 'window_0': 9}. Best is trial 2 with value: 0.5346689105033875.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1/5, Loss: 0.6672\n",
      "   Epoch 2/5, Loss: 0.6386\n",
      "   Epoch 3/5, Loss: 0.6248\n",
      "   Epoch 4/5, Loss: 0.6158\n",
      "   Epoch 5/5, Loss: 0.6091\n",
      "   Epoch 1/5, Loss: 0.6938\n",
      "   Epoch 2/5, Loss: 0.6536\n",
      "   Epoch 3/5, Loss: 0.6426\n",
      "   Epoch 4/5, Loss: 0.6344\n",
      "   Epoch 5/5, Loss: 0.6279\n",
      "   Epoch 1/5, Loss: 0.6936\n",
      "   Epoch 2/5, Loss: 0.6563\n",
      "   Epoch 3/5, Loss: 0.6438\n",
      "   Epoch 4/5, Loss: 0.6357\n",
      "   Epoch 5/5, Loss: 0.6303\n",
      "   Epoch 1/5, Loss: 0.7022\n",
      "   Epoch 2/5, Loss: 0.6782\n",
      "   Epoch 3/5, Loss: 0.6653\n",
      "   Epoch 4/5, Loss: 0.6583\n",
      "   Epoch 5/5, Loss: 0.6534\n",
      "   Epoch 1/5, Loss: 0.7053\n",
      "   Epoch 2/5, Loss: 0.6765\n",
      "   Epoch 3/5, Loss: 0.6672\n",
      "   Epoch 4/5, Loss: 0.6616\n",
      "   Epoch 5/5, Loss: 0.6562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 02:46:24,612] Trial 4 finished with value: 0.5881626963615417 and parameters: {'hidden_size': 51, 'num_layers': 2, 'dropout': 0.3142876428133021, 'lr': 0.00022877553032663603, 'time_step_in': 13, 'time_step_out': 6, 'stride': 1, 'num_lags': 1, 'lag_0': 3, 'num_windows': 1, 'window_0': 3}. Best is trial 2 with value: 0.5346689105033875.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1/5, Loss: 0.6229\n",
      "   Epoch 2/5, Loss: 0.6002\n",
      "   Epoch 3/5, Loss: 0.5912\n",
      "   Epoch 4/5, Loss: 0.5858\n",
      "   Epoch 5/5, Loss: 0.5821\n",
      "   Epoch 1/5, Loss: 0.6361\n",
      "   Epoch 2/5, Loss: 0.6110\n",
      "   Epoch 3/5, Loss: 0.6034\n",
      "   Epoch 4/5, Loss: 0.6003\n",
      "   Epoch 5/5, Loss: 0.5970\n",
      "   Epoch 1/5, Loss: 0.6500\n",
      "   Epoch 2/5, Loss: 0.6277\n",
      "   Epoch 3/5, Loss: 0.6219\n",
      "   Epoch 4/5, Loss: 0.6152\n",
      "   Epoch 5/5, Loss: 0.6089\n",
      "   Epoch 1/5, Loss: 0.6794\n",
      "   Epoch 2/5, Loss: 0.6650\n",
      "   Epoch 3/5, Loss: 0.6582\n",
      "   Epoch 4/5, Loss: 0.6483\n",
      "   Epoch 5/5, Loss: 0.6453\n",
      "   Epoch 1/5, Loss: 0.6735\n",
      "   Epoch 2/5, Loss: 0.6561\n",
      "   Epoch 3/5, Loss: 0.6517\n",
      "   Epoch 4/5, Loss: 0.6456\n",
      "   Epoch 5/5, Loss: 0.6438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 02:47:30,092] Trial 5 finished with value: 0.5673715531826019 and parameters: {'hidden_size': 161, 'num_layers': 1, 'dropout': 0.05645090094200489, 'lr': 0.0040780882538660294, 'time_step_in': 20, 'time_step_out': 4, 'stride': 3, 'num_lags': 2, 'lag_0': 8, 'lag_1': 5, 'num_windows': 2, 'window_0': 6, 'window_1': 18}. Best is trial 2 with value: 0.5346689105033875.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1/5, Loss: 0.6583\n",
      "   Epoch 2/5, Loss: 0.6372\n",
      "   Epoch 3/5, Loss: 0.6353\n",
      "   Epoch 4/5, Loss: 0.6322\n",
      "   Epoch 5/5, Loss: 0.6162\n",
      "   Epoch 1/5, Loss: 0.7009\n",
      "   Epoch 2/5, Loss: 0.6728\n",
      "   Epoch 3/5, Loss: 0.6658\n",
      "   Epoch 4/5, Loss: 0.6585\n",
      "   Epoch 5/5, Loss: 0.6537\n",
      "   Epoch 1/5, Loss: 0.7097\n",
      "   Epoch 2/5, Loss: 0.6921\n",
      "   Epoch 3/5, Loss: 0.6876\n",
      "   Epoch 4/5, Loss: 0.6771\n",
      "   Epoch 5/5, Loss: 0.6666\n",
      "   Epoch 1/5, Loss: 0.7293\n",
      "   Epoch 2/5, Loss: 0.7156\n",
      "   Epoch 3/5, Loss: 0.7072\n",
      "   Epoch 4/5, Loss: 0.6998\n",
      "   Epoch 5/5, Loss: 0.6945\n",
      "   Epoch 1/5, Loss: 0.7261\n",
      "   Epoch 2/5, Loss: 0.7052\n",
      "   Epoch 3/5, Loss: 0.6972\n",
      "   Epoch 4/5, Loss: 0.6899\n",
      "   Epoch 5/5, Loss: 0.6834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 02:49:26,525] Trial 6 finished with value: 0.6185609221458435 and parameters: {'hidden_size': 163, 'num_layers': 3, 'dropout': 0.009948555140825377, 'lr': 0.00236303566006988, 'time_step_in': 29, 'time_step_out': 6, 'stride': 4, 'num_lags': 1, 'lag_0': 1, 'num_windows': 1, 'window_0': 22}. Best is trial 2 with value: 0.5346689105033875.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1/5, Loss: 0.6356\n",
      "   Epoch 2/5, Loss: 0.6120\n",
      "   Epoch 3/5, Loss: 0.6054\n",
      "   Epoch 4/5, Loss: 0.6017\n",
      "   Epoch 5/5, Loss: 0.5910\n",
      "   Epoch 1/5, Loss: 0.6623\n",
      "   Epoch 2/5, Loss: 0.6303\n",
      "   Epoch 3/5, Loss: 0.6226\n",
      "   Epoch 4/5, Loss: 0.6103\n",
      "   Epoch 5/5, Loss: 0.6022\n",
      "   Epoch 1/5, Loss: 0.6729\n",
      "   Epoch 2/5, Loss: 0.6493\n",
      "   Epoch 3/5, Loss: 0.6424\n",
      "   Epoch 4/5, Loss: 0.6290\n",
      "   Epoch 5/5, Loss: 0.6191\n",
      "   Epoch 1/5, Loss: 0.7020\n",
      "   Epoch 2/5, Loss: 0.6807\n",
      "   Epoch 3/5, Loss: 0.6706\n",
      "   Epoch 4/5, Loss: 0.6592\n",
      "   Epoch 5/5, Loss: 0.6516\n",
      "   Epoch 1/5, Loss: 0.7143\n",
      "   Epoch 2/5, Loss: 0.6854\n",
      "   Epoch 3/5, Loss: 0.6705\n",
      "   Epoch 4/5, Loss: 0.6627\n",
      "   Epoch 5/5, Loss: 0.6563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 02:51:39,426] Trial 7 finished with value: 0.5609170198440552 and parameters: {'hidden_size': 153, 'num_layers': 2, 'dropout': 0.401733205375796, 'lr': 0.0006222571967514484, 'time_step_in': 40, 'time_step_out': 2, 'stride': 3, 'num_lags': 3, 'lag_0': 9, 'lag_1': 2, 'lag_2': 10, 'num_windows': 2, 'window_0': 19, 'window_1': 17}. Best is trial 2 with value: 0.5346689105033875.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1/5, Loss: 0.6342\n",
      "   Epoch 2/5, Loss: 0.6119\n",
      "   Epoch 3/5, Loss: 0.6046\n",
      "   Epoch 4/5, Loss: 0.5971\n",
      "   Epoch 5/5, Loss: 0.5926\n",
      "   Epoch 1/5, Loss: 0.6469\n",
      "   Epoch 2/5, Loss: 0.6319\n",
      "   Epoch 3/5, Loss: 0.6260\n",
      "   Epoch 4/5, Loss: 0.6171\n",
      "   Epoch 5/5, Loss: 0.6151\n",
      "   Epoch 1/5, Loss: 0.6608\n",
      "   Epoch 2/5, Loss: 0.6402\n",
      "   Epoch 3/5, Loss: 0.6335\n",
      "   Epoch 4/5, Loss: 0.6257\n",
      "   Epoch 5/5, Loss: 0.6256\n",
      "   Epoch 1/5, Loss: 0.6799\n",
      "   Epoch 2/5, Loss: 0.6605\n",
      "   Epoch 3/5, Loss: 0.6548\n",
      "   Epoch 4/5, Loss: 0.6481\n",
      "   Epoch 5/5, Loss: 0.6394\n",
      "   Epoch 1/5, Loss: 0.6769\n",
      "   Epoch 2/5, Loss: 0.6601\n",
      "   Epoch 3/5, Loss: 0.6539\n",
      "   Epoch 4/5, Loss: 0.6474\n",
      "   Epoch 5/5, Loss: 0.6432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 02:52:43,133] Trial 8 finished with value: 0.5853910982608795 and parameters: {'hidden_size': 152, 'num_layers': 1, 'dropout': 0.11022360670819892, 'lr': 0.0041659917066115704, 'time_step_in': 12, 'time_step_out': 5, 'stride': 2, 'num_lags': 1, 'lag_0': 3, 'num_windows': 2, 'window_0': 11, 'window_1': 11}. Best is trial 2 with value: 0.5346689105033875.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1/5, Loss: 0.6548\n",
      "   Epoch 2/5, Loss: 0.6303\n",
      "   Epoch 3/5, Loss: 0.6302\n",
      "   Epoch 4/5, Loss: 0.6098\n",
      "   Epoch 5/5, Loss: 0.6133\n",
      "   Epoch 1/5, Loss: 0.6857\n",
      "   Epoch 2/5, Loss: 0.6539\n",
      "   Epoch 3/5, Loss: 0.6454\n",
      "   Epoch 4/5, Loss: 0.6416\n",
      "   Epoch 5/5, Loss: 0.6354\n",
      "   Epoch 1/5, Loss: 0.6930\n",
      "   Epoch 2/5, Loss: 0.6664\n",
      "   Epoch 3/5, Loss: 0.6638\n",
      "   Epoch 4/5, Loss: 0.6549\n",
      "   Epoch 5/5, Loss: 0.6462\n",
      "   Epoch 1/5, Loss: 0.7176\n",
      "   Epoch 2/5, Loss: 0.6922\n",
      "   Epoch 3/5, Loss: 0.6847\n",
      "   Epoch 4/5, Loss: 0.6804\n",
      "   Epoch 5/5, Loss: 0.6746\n",
      "   Epoch 1/5, Loss: 0.7144\n",
      "   Epoch 2/5, Loss: 0.6946\n",
      "   Epoch 3/5, Loss: 0.6872\n",
      "   Epoch 4/5, Loss: 0.6816\n",
      "   Epoch 5/5, Loss: 0.6779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 02:53:33,288] Trial 9 finished with value: 0.5886213123798371 and parameters: {'hidden_size': 181, 'num_layers': 1, 'dropout': 0.3061735315926337, 'lr': 0.0033631375446890343, 'time_step_in': 25, 'time_step_out': 5, 'stride': 5, 'num_lags': 1, 'lag_0': 11, 'num_windows': 2, 'window_0': 21, 'window_1': 21}. Best is trial 2 with value: 0.5346689105033875.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1/5, Loss: 0.6027\n",
      "   Epoch 2/5, Loss: 0.5460\n",
      "   Epoch 3/5, Loss: 0.5351\n",
      "   Epoch 4/5, Loss: 0.5324\n",
      "   Epoch 5/5, Loss: 0.5317\n",
      "   Epoch 1/5, Loss: 0.5914\n",
      "   Epoch 2/5, Loss: 0.5719\n",
      "   Epoch 3/5, Loss: 0.5636\n",
      "   Epoch 4/5, Loss: 0.5572\n",
      "   Epoch 5/5, Loss: 0.5536\n",
      "   Epoch 1/5, Loss: 0.6143\n",
      "   Epoch 2/5, Loss: 0.5873\n",
      "   Epoch 3/5, Loss: 0.5795\n",
      "   Epoch 4/5, Loss: 0.5754\n",
      "   Epoch 5/5, Loss: 0.5701\n",
      "   Epoch 1/5, Loss: 0.6322\n",
      "   Epoch 2/5, Loss: 0.6140\n",
      "   Epoch 3/5, Loss: 0.6037\n",
      "   Epoch 4/5, Loss: 0.6005\n",
      "   Epoch 5/5, Loss: 0.6013\n",
      "   Epoch 1/5, Loss: 0.6324\n",
      "   Epoch 2/5, Loss: 0.6098\n",
      "   Epoch 3/5, Loss: 0.6029\n",
      "   Epoch 4/5, Loss: 0.6001\n",
      "   Epoch 5/5, Loss: 0.5947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 02:57:36,801] Trial 10 finished with value: 0.49208855628967285 and parameters: {'hidden_size': 251, 'num_layers': 3, 'dropout': 0.18775094957003446, 'lr': 0.0016362411563676776, 'time_step_in': 21, 'time_step_out': 1, 'stride': 1, 'num_lags': 3, 'lag_0': 12, 'lag_1': 11, 'lag_2': 1, 'num_windows': 3, 'window_0': 15, 'window_1': 4, 'window_2': 22}. Best is trial 10 with value: 0.49208855628967285.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1/5, Loss: 0.5996\n",
      "   Epoch 2/5, Loss: 0.5438\n",
      "   Epoch 3/5, Loss: 0.5279\n",
      "   Epoch 4/5, Loss: 0.5211\n",
      "   Epoch 5/5, Loss: 0.5178\n",
      "   Epoch 1/5, Loss: 0.6010\n",
      "   Epoch 2/5, Loss: 0.5567\n",
      "   Epoch 3/5, Loss: 0.5517\n",
      "   Epoch 4/5, Loss: 0.5533\n",
      "   Epoch 5/5, Loss: 0.5440\n",
      "   Epoch 1/5, Loss: 0.6071\n",
      "   Epoch 2/5, Loss: 0.5782\n",
      "   Epoch 3/5, Loss: 0.5700\n",
      "   Epoch 4/5, Loss: 0.5702\n",
      "   Epoch 5/5, Loss: 0.5660\n",
      "   Epoch 1/5, Loss: 0.6285\n",
      "   Epoch 2/5, Loss: 0.6034\n",
      "   Epoch 3/5, Loss: 0.5998\n",
      "   Epoch 4/5, Loss: 0.5957\n",
      "   Epoch 5/5, Loss: 0.5920\n",
      "   Epoch 1/5, Loss: 0.6239\n",
      "   Epoch 2/5, Loss: 0.6020\n",
      "   Epoch 3/5, Loss: 0.5987\n",
      "   Epoch 4/5, Loss: 0.5932\n",
      "   Epoch 5/5, Loss: 0.5907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 03:01:40,647] Trial 11 finished with value: 0.4670801043510437 and parameters: {'hidden_size': 250, 'num_layers': 3, 'dropout': 0.16845544012518635, 'lr': 0.001149199659089396, 'time_step_in': 21, 'time_step_out': 1, 'stride': 1, 'num_lags': 3, 'lag_0': 12, 'lag_1': 12, 'lag_2': 1, 'num_windows': 3, 'window_0': 15, 'window_1': 3, 'window_2': 23}. Best is trial 11 with value: 0.4670801043510437.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1/5, Loss: 0.5973\n",
      "   Epoch 2/5, Loss: 0.5467\n",
      "   Epoch 3/5, Loss: 0.5329\n",
      "   Epoch 4/5, Loss: 0.5274\n",
      "   Epoch 5/5, Loss: 0.5275\n",
      "   Epoch 1/5, Loss: 0.6022\n",
      "   Epoch 2/5, Loss: 0.5681\n",
      "   Epoch 3/5, Loss: 0.5621\n",
      "   Epoch 4/5, Loss: 0.5565\n",
      "   Epoch 5/5, Loss: 0.5565\n",
      "   Epoch 1/5, Loss: 0.6139\n",
      "   Epoch 2/5, Loss: 0.5844\n",
      "   Epoch 3/5, Loss: 0.5764\n",
      "   Epoch 4/5, Loss: 0.5716\n",
      "   Epoch 5/5, Loss: 0.5690\n",
      "   Epoch 1/5, Loss: 0.6399\n",
      "   Epoch 2/5, Loss: 0.6121\n",
      "   Epoch 3/5, Loss: 0.6059\n",
      "   Epoch 4/5, Loss: 0.6013\n",
      "   Epoch 5/5, Loss: 0.5977\n",
      "   Epoch 1/5, Loss: 0.6321\n",
      "   Epoch 2/5, Loss: 0.6080\n",
      "   Epoch 3/5, Loss: 0.6006\n",
      "   Epoch 4/5, Loss: 0.5991\n",
      "   Epoch 5/5, Loss: 0.5928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 03:05:26,959] Trial 12 finished with value: 0.4757362186908722 and parameters: {'hidden_size': 248, 'num_layers': 3, 'dropout': 0.16723983746596827, 'lr': 0.0013574983990502247, 'time_step_in': 19, 'time_step_out': 1, 'stride': 1, 'num_lags': 3, 'lag_0': 12, 'lag_1': 12, 'lag_2': 1, 'num_windows': 3, 'window_0': 15, 'window_1': 4, 'window_2': 24}. Best is trial 11 with value: 0.4670801043510437.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1/5, Loss: 0.7588\n",
      "   Epoch 2/5, Loss: 0.6657\n",
      "   Epoch 3/5, Loss: 0.6794\n",
      "   Epoch 4/5, Loss: 0.6671\n",
      "   Early stopping at epoch 4\n",
      "   Epoch 1/5, Loss: 0.7757\n",
      "   Epoch 2/5, Loss: 0.7366\n",
      "   Epoch 3/5, Loss: 0.7337\n",
      "   Epoch 4/5, Loss: 0.7060\n",
      "   Epoch 5/5, Loss: 0.6790\n",
      "   Epoch 1/5, Loss: 0.7614\n",
      "   Epoch 2/5, Loss: 0.7344\n",
      "   Epoch 3/5, Loss: 0.7344\n",
      "   Epoch 4/5, Loss: 0.7343\n",
      "   Epoch 5/5, Loss: 0.7349\n",
      "   Epoch 1/5, Loss: 0.7707\n",
      "   Epoch 2/5, Loss: 0.7595\n",
      "   Epoch 3/5, Loss: 0.7553\n",
      "   Epoch 4/5, Loss: 0.7569\n",
      "   Epoch 5/5, Loss: 0.7572\n",
      "   Early stopping at epoch 5\n",
      "   Epoch 1/5, Loss: 0.8470\n",
      "   Epoch 2/5, Loss: 0.8399\n",
      "   Epoch 3/5, Loss: 0.8444\n",
      "   Epoch 4/5, Loss: 0.8442\n",
      "   Early stopping at epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 03:12:16,324] Trial 13 finished with value: 0.7735422134399415 and parameters: {'hidden_size': 252, 'num_layers': 3, 'dropout': 0.17799741368128355, 'lr': 0.009943664189161898, 'time_step_in': 48, 'time_step_out': 1, 'stride': 1, 'num_lags': 3, 'lag_0': 9, 'lag_1': 12, 'lag_2': 1, 'num_windows': 3, 'window_0': 15, 'window_1': 3, 'window_2': 24}. Best is trial 11 with value: 0.4670801043510437.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1/5, Loss: 0.6543\n",
      "   Epoch 2/5, Loss: 0.6063\n",
      "   Epoch 3/5, Loss: 0.5937\n",
      "   Epoch 4/5, Loss: 0.5892\n",
      "   Epoch 5/5, Loss: 0.5787\n",
      "   Epoch 1/5, Loss: 0.6656\n",
      "   Epoch 2/5, Loss: 0.6232\n",
      "   Epoch 3/5, Loss: 0.6182\n",
      "   Epoch 4/5, Loss: 0.6096\n",
      "   Epoch 5/5, Loss: 0.6051\n",
      "   Epoch 1/5, Loss: 0.6621\n",
      "   Epoch 2/5, Loss: 0.6306\n",
      "   Epoch 3/5, Loss: 0.6197\n",
      "   Epoch 4/5, Loss: 0.6178\n",
      "   Epoch 5/5, Loss: 0.6129\n",
      "   Epoch 1/5, Loss: 0.6771\n",
      "   Epoch 2/5, Loss: 0.6578\n",
      "   Epoch 3/5, Loss: 0.6485\n",
      "   Epoch 4/5, Loss: 0.6416\n",
      "   Epoch 5/5, Loss: 0.6383\n",
      "   Epoch 1/5, Loss: 0.6723\n",
      "   Epoch 2/5, Loss: 0.6509\n",
      "   Epoch 3/5, Loss: 0.6459\n",
      "   Epoch 4/5, Loss: 0.6412\n",
      "   Epoch 5/5, Loss: 0.6365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 03:14:04,953] Trial 14 finished with value: 0.5714959084987641 and parameters: {'hidden_size': 210, 'num_layers': 3, 'dropout': 0.2049858395477972, 'lr': 0.0011058465537242747, 'time_step_in': 18, 'time_step_out': 3, 'stride': 2, 'num_lags': 2, 'lag_0': 12, 'lag_1': 10, 'num_windows': 3, 'window_0': 17, 'window_1': 7, 'window_2': 24}. Best is trial 11 with value: 0.4670801043510437.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1/5, Loss: 0.5894\n",
      "   Epoch 2/5, Loss: 0.5469\n",
      "   Epoch 3/5, Loss: 0.5361\n",
      "   Epoch 4/5, Loss: 0.5251\n",
      "   Epoch 5/5, Loss: 0.5337\n",
      "   Epoch 1/5, Loss: 0.6782\n",
      "   Epoch 2/5, Loss: 0.6184\n",
      "   Epoch 3/5, Loss: 0.6052\n",
      "   Epoch 4/5, Loss: 0.5928\n",
      "   Epoch 5/5, Loss: 0.5814\n",
      "   Epoch 1/5, Loss: 0.6788\n",
      "   Epoch 2/5, Loss: 0.6091\n",
      "   Epoch 3/5, Loss: 0.6074\n",
      "   Epoch 4/5, Loss: 0.5890\n",
      "   Epoch 5/5, Loss: 0.5781\n",
      "   Epoch 1/5, Loss: 0.6656\n",
      "   Epoch 2/5, Loss: 0.6257\n",
      "   Epoch 3/5, Loss: 0.6091\n",
      "   Epoch 4/5, Loss: 0.6236\n",
      "   Epoch 5/5, Loss: 0.6093\n",
      "   Early stopping at epoch 5\n",
      "   Epoch 1/5, Loss: 0.6318\n",
      "   Epoch 2/5, Loss: 0.5937\n",
      "   Epoch 3/5, Loss: 0.5874\n",
      "   Epoch 4/5, Loss: 0.5795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 03:14:57,787] Trial 15 finished with value: 0.5165428757667542 and parameters: {'hidden_size': 218, 'num_layers': 2, 'dropout': 0.12488250203007786, 'lr': 0.0011171909230062492, 'time_step_in': 18, 'time_step_out': 1, 'stride': 4, 'num_lags': 3, 'lag_0': 5, 'lag_1': 9, 'lag_2': 4, 'num_windows': 3, 'window_0': 13, 'window_1': 7, 'window_2': 16}. Best is trial 11 with value: 0.4670801043510437.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 5/5, Loss: 0.5756\n",
      "   Epoch 1/5, Loss: 0.6614\n",
      "   Epoch 2/5, Loss: 0.6354\n",
      "   Epoch 3/5, Loss: 0.6177\n",
      "   Epoch 4/5, Loss: 0.6025\n",
      "   Epoch 5/5, Loss: 0.5910\n",
      "   Epoch 1/5, Loss: 0.6872\n",
      "   Epoch 2/5, Loss: 0.6487\n",
      "   Epoch 3/5, Loss: 0.6329\n",
      "   Epoch 4/5, Loss: 0.6208\n",
      "   Epoch 5/5, Loss: 0.6167\n",
      "   Epoch 1/5, Loss: 0.6918\n",
      "   Epoch 2/5, Loss: 0.6553\n",
      "   Epoch 3/5, Loss: 0.6395\n",
      "   Epoch 4/5, Loss: 0.6285\n",
      "   Epoch 5/5, Loss: 0.6239\n",
      "   Epoch 1/5, Loss: 0.7065\n",
      "   Epoch 2/5, Loss: 0.6743\n",
      "   Epoch 3/5, Loss: 0.6579\n",
      "   Epoch 4/5, Loss: 0.6519\n",
      "   Epoch 5/5, Loss: 0.6484\n",
      "   Epoch 1/5, Loss: 0.7089\n",
      "   Epoch 2/5, Loss: 0.6715\n",
      "   Epoch 3/5, Loss: 0.6608\n",
      "   Epoch 4/5, Loss: 0.6525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 03:15:55,683] Trial 16 finished with value: 0.5793953776359558 and parameters: {'hidden_size': 104, 'num_layers': 3, 'dropout': 0.24641913953642994, 'lr': 0.0005777824491537315, 'time_step_in': 15, 'time_step_out': 3, 'stride': 3, 'num_lags': 3, 'lag_0': 10, 'lag_1': 8, 'lag_2': 5, 'num_windows': 3, 'window_0': 17, 'window_1': 12, 'window_2': 19}. Best is trial 11 with value: 0.4670801043510437.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 5/5, Loss: 0.6462\n",
      "   Epoch 1/5, Loss: 0.7005\n",
      "   Epoch 2/5, Loss: 0.6824\n",
      "   Epoch 3/5, Loss: 0.6957\n",
      "   Epoch 4/5, Loss: 0.6839\n",
      "   Early stopping at epoch 4\n",
      "   Epoch 1/5, Loss: 0.7595\n",
      "   Epoch 2/5, Loss: 0.7440\n",
      "   Epoch 3/5, Loss: 0.7480\n",
      "   Epoch 4/5, Loss: 0.7473\n",
      "   Early stopping at epoch 4\n",
      "   Epoch 1/5, Loss: 0.6596\n",
      "   Epoch 2/5, Loss: 0.6387\n",
      "   Epoch 3/5, Loss: 0.6410\n",
      "   Epoch 4/5, Loss: 0.6455\n",
      "   Early stopping at epoch 4\n",
      "   Epoch 1/5, Loss: 0.7376\n",
      "   Epoch 2/5, Loss: 0.7154\n",
      "   Epoch 3/5, Loss: 0.7026\n",
      "   Epoch 4/5, Loss: 0.6961\n",
      "   Epoch 5/5, Loss: 0.7046\n",
      "   Epoch 1/5, Loss: 0.7214\n",
      "   Epoch 2/5, Loss: 0.6715\n",
      "   Epoch 3/5, Loss: 0.6682\n",
      "   Epoch 4/5, Loss: 0.6669\n",
      "   Epoch 5/5, Loss: 0.6680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 03:19:54,010] Trial 17 finished with value: 0.6652457594871521 and parameters: {'hidden_size': 231, 'num_layers': 3, 'dropout': 0.11985651551694755, 'lr': 0.009760259050958177, 'time_step_in': 24, 'time_step_out': 2, 'stride': 1, 'num_lags': 2, 'lag_0': 6, 'lag_1': 12, 'num_windows': 2, 'window_0': 24, 'window_1': 4}. Best is trial 11 with value: 0.4670801043510437.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1/5, Loss: 0.6661\n",
      "   Epoch 2/5, Loss: 0.6450\n",
      "   Epoch 3/5, Loss: 0.6256\n",
      "   Epoch 4/5, Loss: 0.6159\n",
      "   Epoch 5/5, Loss: 0.6149\n",
      "   Epoch 1/5, Loss: 0.6842\n",
      "   Epoch 2/5, Loss: 0.6345\n",
      "   Epoch 3/5, Loss: 0.6222\n",
      "   Epoch 4/5, Loss: 0.6001\n",
      "   Epoch 5/5, Loss: 0.5773\n",
      "   Epoch 1/5, Loss: 0.6648\n",
      "   Epoch 2/5, Loss: 0.6212\n",
      "   Epoch 3/5, Loss: 0.5847\n",
      "   Epoch 4/5, Loss: 0.5757\n",
      "   Epoch 5/5, Loss: 0.5715\n",
      "   Epoch 1/5, Loss: 0.6671\n",
      "   Epoch 2/5, Loss: 0.6139\n",
      "   Epoch 3/5, Loss: 0.5953\n",
      "   Epoch 4/5, Loss: 0.5895\n",
      "   Epoch 5/5, Loss: 0.5824\n",
      "   Epoch 1/5, Loss: 0.6643\n",
      "   Epoch 2/5, Loss: 0.6082\n",
      "   Epoch 3/5, Loss: 0.5926\n",
      "   Epoch 4/5, Loss: 0.5852\n",
      "   Epoch 5/5, Loss: 0.5811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 03:24:07,987] Trial 18 finished with value: 0.5147504568099975 and parameters: {'hidden_size': 188, 'num_layers': 3, 'dropout': 0.2439287410932335, 'lr': 0.00032293899622518887, 'time_step_in': 28, 'time_step_out': 1, 'stride': 2, 'num_lags': 3, 'lag_0': 9, 'lag_1': 8, 'lag_2': 1, 'num_windows': 3, 'window_0': 13, 'window_1': 8, 'window_2': 11}. Best is trial 11 with value: 0.4670801043510437.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1/5, Loss: 0.6277\n",
      "   Epoch 2/5, Loss: 0.6077\n",
      "   Epoch 3/5, Loss: 0.6015\n",
      "   Epoch 4/5, Loss: 0.5944\n",
      "   Epoch 5/5, Loss: 0.5994\n",
      "   Epoch 1/5, Loss: 0.6357\n",
      "   Epoch 2/5, Loss: 0.6016\n",
      "   Epoch 3/5, Loss: 0.5893\n",
      "   Epoch 4/5, Loss: 0.5804\n",
      "   Epoch 5/5, Loss: 0.5663\n",
      "   Epoch 1/5, Loss: 0.6459\n",
      "   Epoch 2/5, Loss: 0.6130\n",
      "   Epoch 3/5, Loss: 0.6066\n",
      "   Epoch 4/5, Loss: 0.5941\n",
      "   Epoch 5/5, Loss: 0.5888\n",
      "   Epoch 1/5, Loss: 0.6715\n",
      "   Epoch 2/5, Loss: 0.6453\n",
      "   Epoch 3/5, Loss: 0.6369\n",
      "   Epoch 4/5, Loss: 0.6267\n",
      "   Epoch 5/5, Loss: 0.6255\n",
      "   Epoch 1/5, Loss: 0.6915\n",
      "   Epoch 2/5, Loss: 0.6588\n",
      "   Epoch 3/5, Loss: 0.6473\n",
      "   Epoch 4/5, Loss: 0.6393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 03:24:42,647] Trial 19 finished with value: 0.574175763130188 and parameters: {'hidden_size': 121, 'num_layers': 2, 'dropout': 0.06541720388267308, 'lr': 0.0015386505692789971, 'time_step_in': 16, 'time_step_out': 3, 'stride': 6, 'num_lags': 3, 'lag_0': 12, 'lag_1': 4, 'lag_2': 9, 'num_windows': 3, 'window_0': 17, 'window_1': 15, 'window_2': 20}. Best is trial 11 with value: 0.4670801043510437.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 5/5, Loss: 0.6366\n",
      " Best parameters for 2019-10:\n",
      "  hidden_size: 250\n",
      "  num_layers: 3\n",
      "  dropout: 0.16845544012518635\n",
      "  lr: 0.001149199659089396\n",
      "  time_step_in: 21\n",
      "  time_step_out: 1\n",
      "  stride: 1\n",
      "  num_lags: 3\n",
      "  lag_0: 12\n",
      "  lag_1: 12\n",
      "  lag_2: 1\n",
      "  num_windows: 3\n",
      "  window_0: 15\n",
      "  window_1: 3\n",
      "  window_2: 23\n",
      " Best parameters saved to best_params_2019-10.json\n",
      "\n",
      " Final evaluation on 2019-10, fold_1 test set\n",
      "\n",
      "====== Training model for 2019-10, fold_1 with best parameters\n",
      "====== Training model on train set...\n",
      "   Epoch 1/15, Loss: 0.5830\n",
      "   Epoch 2/15, Loss: 0.5405\n",
      "   Epoch 3/15, Loss: 0.5293\n",
      "   Epoch 4/15, Loss: 0.5298\n",
      "   Epoch 5/15, Loss: 0.5193\n",
      "   Epoch 6/15, Loss: 0.5140\n",
      "   Epoch 7/15, Loss: 0.5109\n",
      "   Epoch 8/15, Loss: 0.5116\n",
      "   Epoch 9/15, Loss: 0.5085\n",
      "   Epoch 10/15, Loss: 0.5058\n",
      "   Epoch 11/15, Loss: 0.5076\n",
      "   Epoch 12/15, Loss: 0.5007\n",
      "   Epoch 13/15, Loss: 0.5031\n",
      "   Epoch 14/15, Loss: 0.4941\n",
      "   Epoch 15/15, Loss: 0.4902\n",
      "====== Evaluating on validation set...\n",
      "  Val RMSE: 0.5669, Bias: 0.0214, R²: 0.4397, CSI: 0.5614\n",
      "====== Evaluating on test set...\n",
      "  Test RMSE: 0.3831, Bias: 0.0153, R²: 0.7523, CSI: 0.6471\n",
      " Model saved to model_2019-10_fold_1.pt\n",
      "\n",
      " Final evaluation on 2019-10, fold_2 test set\n",
      "\n",
      "====== Training model for 2019-10, fold_2 with best parameters\n",
      "====== Training model on train set...\n",
      "   Epoch 1/15, Loss: 0.5912\n",
      "   Epoch 2/15, Loss: 0.5578\n",
      "   Epoch 3/15, Loss: 0.5584\n",
      "   Epoch 4/15, Loss: 0.5501\n",
      "   Epoch 5/15, Loss: 0.5471\n",
      "   Epoch 6/15, Loss: 0.5452\n",
      "   Epoch 7/15, Loss: 0.5394\n",
      "   Epoch 8/15, Loss: 0.5380\n",
      "   Epoch 9/15, Loss: 0.5324\n",
      "   Epoch 10/15, Loss: 0.5360\n",
      "   Epoch 11/15, Loss: 0.5296\n",
      "   Epoch 12/15, Loss: 0.5237\n",
      "   Epoch 13/15, Loss: 0.5166\n",
      "   Epoch 14/15, Loss: 0.5184\n",
      "   Epoch 15/15, Loss: 0.5118\n",
      "====== Evaluating on validation set...\n",
      "  Val RMSE: 0.5056, Bias: -0.0429, R²: 0.5299, CSI: 0.6786\n",
      "====== Evaluating on test set...\n",
      "  Test RMSE: 0.5022, Bias: -0.0175, R²: 0.7315, CSI: 0.7348\n",
      " Model saved to model_2019-10_fold_2.pt\n",
      "\n",
      " Final evaluation on 2019-10, fold_3 test set\n",
      "\n",
      "====== Training model for 2019-10, fold_3 with best parameters\n",
      "====== Training model on train set...\n",
      "   Epoch 1/15, Loss: 0.6002\n",
      "   Epoch 2/15, Loss: 0.5780\n",
      "   Epoch 3/15, Loss: 0.5733\n",
      "   Epoch 4/15, Loss: 0.5681\n",
      "   Epoch 5/15, Loss: 0.5643\n",
      "   Epoch 6/15, Loss: 0.5637\n",
      "   Epoch 7/15, Loss: 0.5614\n",
      "   Epoch 8/15, Loss: 0.5531\n",
      "   Epoch 9/15, Loss: 0.5541\n",
      "   Epoch 10/15, Loss: 0.5490\n",
      "   Epoch 11/15, Loss: 0.5442\n",
      "   Epoch 12/15, Loss: 0.5388\n",
      "   Epoch 13/15, Loss: 0.5344\n",
      "   Epoch 14/15, Loss: 0.5266\n",
      "   Epoch 15/15, Loss: 0.5216\n",
      "====== Evaluating on validation set...\n",
      "  Val RMSE: 0.4832, Bias: -0.0542, R²: 0.5773, CSI: 0.6665\n",
      "====== Evaluating on test set...\n",
      "  Test RMSE: 0.6246, Bias: -0.0863, R²: 0.6593, CSI: 0.7661\n",
      " Model saved to model_2019-10_fold_3.pt\n",
      "\n",
      " Final evaluation on 2019-10, fold_4 test set\n",
      "\n",
      "====== Training model for 2019-10, fold_4 with best parameters\n",
      "====== Training model on train set...\n",
      "   Epoch 1/15, Loss: 0.6274\n",
      "   Epoch 2/15, Loss: 0.6054\n",
      "   Epoch 3/15, Loss: 0.5994\n",
      "   Epoch 4/15, Loss: 0.5964\n",
      "   Epoch 5/15, Loss: 0.5927\n",
      "   Epoch 6/15, Loss: 0.5871\n",
      "   Epoch 7/15, Loss: 0.5835\n",
      "   Epoch 8/15, Loss: 0.5846\n",
      "   Epoch 9/15, Loss: 0.5789\n",
      "   Epoch 10/15, Loss: 0.5724\n",
      "   Epoch 11/15, Loss: 0.5674\n",
      "   Epoch 12/15, Loss: 0.5632\n",
      "   Epoch 13/15, Loss: 0.5583\n",
      "   Epoch 14/15, Loss: 0.5482\n",
      "   Epoch 15/15, Loss: 0.5440\n",
      "====== Evaluating on validation set...\n",
      "  Val RMSE: 0.3991, Bias: -0.0307, R²: 0.6015, CSI: 0.6912\n",
      "====== Evaluating on test set...\n",
      "  Test RMSE: 0.6623, Bias: -0.0584, R²: 0.6168, CSI: 0.7937\n",
      " Model saved to model_2019-10_fold_4.pt\n",
      "\n",
      " Final evaluation on 2019-10, fold_5 test set\n",
      "\n",
      "====== Training model for 2019-10, fold_5 with best parameters\n",
      "====== Training model on train set...\n",
      "   Epoch 1/15, Loss: 0.6240\n",
      "   Epoch 2/15, Loss: 0.6024\n",
      "   Epoch 3/15, Loss: 0.5973\n",
      "   Epoch 4/15, Loss: 0.5945\n",
      "   Epoch 5/15, Loss: 0.5905\n",
      "   Epoch 6/15, Loss: 0.5857\n",
      "   Epoch 7/15, Loss: 0.5850\n",
      "   Epoch 8/15, Loss: 0.5781\n",
      "   Epoch 9/15, Loss: 0.5763\n",
      "   Epoch 10/15, Loss: 0.5730\n",
      "   Epoch 11/15, Loss: 0.5692\n",
      "   Epoch 12/15, Loss: 0.5643\n",
      "   Epoch 13/15, Loss: 0.5560\n",
      "   Epoch 14/15, Loss: 0.5516\n",
      "   Epoch 15/15, Loss: 0.5587\n",
      "====== Evaluating on validation set...\n",
      "  Val RMSE: 0.4122, Bias: -0.0107, R²: 0.6933, CSI: 0.6722\n",
      "====== Evaluating on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 03:34:49,504] A new study created in memory with name: 2020-04_study\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Test RMSE: 0.6446, Bias: -0.0280, R²: 0.6886, CSI: 0.7284\n",
      " Model saved to model_2019-10_fold_5.pt\n",
      "\n",
      " Mean test performance for 2019-10:\n",
      "  RMSE: 0.5634, Bias: -0.0350, R²: 0.6897, CSI: 0.7340\n",
      " Best fold test performance for 2019-10 (fold fold_1):\n",
      "  RMSE: 0.3831, Bias: 0.0153, R²: 0.7523, CSI: 0.6471\n",
      " Best model for 2019-10 saved to best_model_2019-10.pt\n",
      "\n",
      "###### Processing month: 2020-04\n",
      "   Epoch 1/5, Loss: 0.2459\n",
      "   Epoch 2/5, Loss: 0.2337\n",
      "   Epoch 3/5, Loss: 0.2256\n",
      "   Epoch 4/5, Loss: 0.2222\n",
      "   Epoch 5/5, Loss: 0.2153\n",
      "   Epoch 1/5, Loss: 0.2746\n",
      "   Epoch 2/5, Loss: 0.2503\n",
      "   Epoch 3/5, Loss: 0.2435\n",
      "   Epoch 4/5, Loss: 0.2379\n",
      "   Epoch 5/5, Loss: 0.2378\n",
      "   Epoch 1/5, Loss: 0.2880\n",
      "   Epoch 2/5, Loss: 0.2721\n",
      "   Epoch 3/5, Loss: 0.2672\n",
      "   Epoch 4/5, Loss: 0.2646\n",
      "   Epoch 5/5, Loss: 0.2598\n",
      "   Epoch 1/5, Loss: 0.2543\n",
      "   Epoch 2/5, Loss: 0.2389\n",
      "   Epoch 3/5, Loss: 0.2322\n",
      "   Epoch 4/5, Loss: 0.2279\n",
      "   Epoch 5/5, Loss: 0.2234\n",
      "   Epoch 1/5, Loss: 0.2108\n",
      "   Epoch 2/5, Loss: 0.1982\n",
      "   Epoch 3/5, Loss: 0.1943\n",
      "   Epoch 4/5, Loss: 0.1918\n",
      "   Epoch 5/5, Loss: 0.1901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 03:37:35,099] Trial 0 finished with value: 0.6140594497323036 and parameters: {'hidden_size': 67, 'num_layers': 3, 'dropout': 0.08247942473288222, 'lr': 0.0012143251181931233, 'time_step_in': 12, 'time_step_out': 1, 'stride': 1, 'num_lags': 2, 'lag_0': 7, 'lag_1': 9, 'num_windows': 2, 'window_0': 20, 'window_1': 24}. Best is trial 0 with value: 0.6140594497323036.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1/5, Loss: 0.3128\n",
      "   Epoch 2/5, Loss: 0.3076\n",
      "   Epoch 3/5, Loss: 0.2992\n",
      "   Epoch 4/5, Loss: 0.2880\n",
      "   Epoch 5/5, Loss: 0.2928\n",
      "   Epoch 1/5, Loss: 0.3248\n",
      "   Epoch 2/5, Loss: 0.3030\n",
      "   Epoch 3/5, Loss: 0.2985\n",
      "   Epoch 4/5, Loss: 0.3009\n",
      "   Epoch 5/5, Loss: 0.2871\n",
      "   Epoch 1/5, Loss: 0.3342\n",
      "   Epoch 2/5, Loss: 0.3195\n",
      "   Epoch 3/5, Loss: 0.3120\n",
      "   Epoch 4/5, Loss: 0.3070\n",
      "   Epoch 5/5, Loss: 0.3023\n",
      "   Epoch 1/5, Loss: 0.2976\n",
      "   Epoch 2/5, Loss: 0.2724\n",
      "   Epoch 3/5, Loss: 0.2636\n",
      "   Epoch 4/5, Loss: 0.2554\n",
      "   Epoch 5/5, Loss: 0.2490\n",
      "   Epoch 1/5, Loss: 0.2356\n",
      "   Epoch 2/5, Loss: 0.2247\n",
      "   Epoch 3/5, Loss: 0.2193\n",
      "   Epoch 4/5, Loss: 0.2157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 03:38:38,577] Trial 1 finished with value: 0.6486224472522736 and parameters: {'hidden_size': 123, 'num_layers': 2, 'dropout': 0.4015945159479697, 'lr': 0.0006979993023010035, 'time_step_in': 30, 'time_step_out': 4, 'stride': 4, 'num_lags': 3, 'lag_0': 10, 'lag_1': 7, 'lag_2': 4, 'num_windows': 3, 'window_0': 17, 'window_1': 21, 'window_2': 4}. Best is trial 0 with value: 0.6140594497323036.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 5/5, Loss: 0.2141\n",
      "   Epoch 1/5, Loss: 0.3532\n",
      "   Epoch 2/5, Loss: 0.3418\n",
      "   Epoch 3/5, Loss: 0.3291\n",
      "   Epoch 4/5, Loss: 0.3140\n",
      "   Epoch 5/5, Loss: 0.3024\n",
      "   Epoch 1/5, Loss: 0.3447\n",
      "   Epoch 2/5, Loss: 0.3160\n",
      "   Epoch 3/5, Loss: 0.2986\n",
      "   Epoch 4/5, Loss: 0.2873\n",
      "   Epoch 5/5, Loss: 0.2783\n",
      "   Epoch 1/5, Loss: 0.3458\n",
      "   Epoch 2/5, Loss: 0.3315\n",
      "   Epoch 3/5, Loss: 0.3206\n",
      "   Epoch 4/5, Loss: 0.3149\n",
      "   Epoch 5/5, Loss: 0.3114\n",
      "   Epoch 1/5, Loss: 0.3074\n",
      "   Epoch 2/5, Loss: 0.2816\n",
      "   Epoch 3/5, Loss: 0.2659\n",
      "   Epoch 4/5, Loss: 0.2585\n",
      "   Epoch 5/5, Loss: 0.2512\n",
      "   Epoch 1/5, Loss: 0.2395\n",
      "   Epoch 2/5, Loss: 0.2260\n",
      "   Epoch 3/5, Loss: 0.2202\n",
      "   Epoch 4/5, Loss: 0.2178\n",
      "   Epoch 5/5, Loss: 0.2146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 03:44:18,198] Trial 2 finished with value: 0.8357196837663651 and parameters: {'hidden_size': 189, 'num_layers': 3, 'dropout': 0.32712204027829006, 'lr': 0.00032800710787981186, 'time_step_in': 37, 'time_step_out': 6, 'stride': 2, 'num_lags': 1, 'lag_0': 3, 'num_windows': 1, 'window_0': 5}. Best is trial 0 with value: 0.6140594497323036.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1/5, Loss: 0.3589\n",
      "   Epoch 2/5, Loss: 0.3519\n",
      "   Epoch 3/5, Loss: 0.3443\n",
      "   Epoch 4/5, Loss: 0.3403\n",
      "   Epoch 5/5, Loss: 0.3260\n",
      "   Epoch 1/5, Loss: 0.3639\n",
      "   Epoch 2/5, Loss: 0.3496\n",
      "   Epoch 3/5, Loss: 0.3350\n",
      "   Epoch 4/5, Loss: 0.3277\n",
      "   Epoch 5/5, Loss: 0.3195\n",
      "   Epoch 1/5, Loss: 0.3507\n",
      "   Epoch 2/5, Loss: 0.3402\n",
      "   Epoch 3/5, Loss: 0.3295\n",
      "   Epoch 4/5, Loss: 0.3269\n",
      "   Epoch 5/5, Loss: 0.3213\n",
      "   Epoch 1/5, Loss: 0.3237\n",
      "   Epoch 2/5, Loss: 0.2970\n",
      "   Epoch 3/5, Loss: 0.2850\n",
      "   Epoch 4/5, Loss: 0.2785\n",
      "   Epoch 5/5, Loss: 0.2721\n",
      "   Epoch 1/5, Loss: 0.2512\n",
      "   Epoch 2/5, Loss: 0.2396\n",
      "   Epoch 3/5, Loss: 0.2357\n",
      "   Epoch 4/5, Loss: 0.2313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 03:45:05,220] Trial 3 finished with value: 0.8104930520057678 and parameters: {'hidden_size': 198, 'num_layers': 2, 'dropout': 0.42413110934439585, 'lr': 0.0005927915206053074, 'time_step_in': 17, 'time_step_out': 3, 'stride': 5, 'num_lags': 2, 'lag_0': 12, 'lag_1': 11, 'num_windows': 2, 'window_0': 22, 'window_1': 18}. Best is trial 0 with value: 0.6140594497323036.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 5/5, Loss: 0.2280\n",
      "   Epoch 1/5, Loss: 0.3359\n",
      "   Epoch 2/5, Loss: 0.3168\n",
      "   Epoch 3/5, Loss: 0.3013\n",
      "   Epoch 4/5, Loss: 0.2808\n",
      "   Epoch 5/5, Loss: 0.2776\n",
      "   Epoch 1/5, Loss: 0.3197\n",
      "   Epoch 2/5, Loss: 0.2987\n",
      "   Epoch 3/5, Loss: 0.2854\n",
      "   Epoch 4/5, Loss: 0.2741\n",
      "   Epoch 5/5, Loss: 0.2621\n",
      "   Epoch 1/5, Loss: 0.3295\n",
      "   Epoch 2/5, Loss: 0.3193\n",
      "   Epoch 3/5, Loss: 0.3127\n",
      "   Epoch 4/5, Loss: 0.3015\n",
      "   Epoch 5/5, Loss: 0.2910\n",
      "   Epoch 1/5, Loss: 0.2842\n",
      "   Epoch 2/5, Loss: 0.2606\n",
      "   Epoch 3/5, Loss: 0.2478\n",
      "   Epoch 4/5, Loss: 0.2401\n",
      "   Epoch 5/5, Loss: 0.2319\n",
      "   Epoch 1/5, Loss: 0.2278\n",
      "   Epoch 2/5, Loss: 0.2171\n",
      "   Epoch 3/5, Loss: 0.2101\n",
      "   Epoch 4/5, Loss: 0.2058\n",
      "   Epoch 5/5, Loss: 0.1996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 03:53:34,055] Trial 4 finished with value: 0.741805961728096 and parameters: {'hidden_size': 140, 'num_layers': 3, 'dropout': 0.10986487403938161, 'lr': 0.0011744226397735961, 'time_step_in': 38, 'time_step_out': 3, 'stride': 1, 'num_lags': 1, 'lag_0': 3, 'num_windows': 3, 'window_0': 14, 'window_1': 21, 'window_2': 19}. Best is trial 0 with value: 0.6140594497323036.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1/5, Loss: 0.0688\n",
      "   Epoch 2/5, Loss: 0.0622\n",
      "   Epoch 3/5, Loss: 0.0605\n",
      "   Epoch 4/5, Loss: 0.0593\n",
      "   Epoch 5/5, Loss: 0.0581\n",
      "   Epoch 1/5, Loss: 0.1572\n",
      "   Epoch 2/5, Loss: 0.1469\n",
      "   Epoch 3/5, Loss: 0.1429\n",
      "   Epoch 4/5, Loss: 0.1400\n",
      "   Epoch 5/5, Loss: 0.1363\n",
      "   Epoch 1/5, Loss: 0.2482\n",
      "   Epoch 2/5, Loss: 0.2406\n",
      "   Epoch 3/5, Loss: 0.2361\n",
      "   Epoch 4/5, Loss: 0.2320\n",
      "   Epoch 5/5, Loss: 0.2301\n",
      "   Epoch 1/5, Loss: 0.2382\n",
      "   Epoch 2/5, Loss: 0.2208\n",
      "   Epoch 3/5, Loss: 0.2123\n",
      "   Epoch 4/5, Loss: 0.2039\n",
      "   Epoch 5/5, Loss: 0.1959\n",
      "   Epoch 1/5, Loss: 0.2100\n",
      "   Epoch 2/5, Loss: 0.2028\n",
      "   Epoch 3/5, Loss: 0.1990\n",
      "   Epoch 4/5, Loss: 0.1977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 03:54:06,213] Trial 5 finished with value: 0.5604017861187458 and parameters: {'hidden_size': 62, 'num_layers': 1, 'dropout': 0.23388992481904686, 'lr': 0.0021208954668125637, 'time_step_in': 15, 'time_step_out': 2, 'stride': 6, 'num_lags': 1, 'lag_0': 7, 'num_windows': 2, 'window_0': 10, 'window_1': 24}. Best is trial 5 with value: 0.5604017861187458.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 5/5, Loss: 0.1942\n",
      "   Epoch 1/5, Loss: 0.3843\n",
      "   Epoch 2/5, Loss: 0.3761\n",
      "   Epoch 3/5, Loss: 0.3700\n",
      "   Epoch 4/5, Loss: 0.3613\n",
      "   Epoch 5/5, Loss: 0.3496\n",
      "   Epoch 1/5, Loss: 0.3622\n",
      "   Epoch 2/5, Loss: 0.3337\n",
      "   Epoch 3/5, Loss: 0.3164\n",
      "   Epoch 4/5, Loss: 0.3047\n",
      "   Epoch 5/5, Loss: 0.2910\n",
      "   Epoch 1/5, Loss: 0.3576\n",
      "   Epoch 2/5, Loss: 0.3434\n",
      "   Epoch 3/5, Loss: 0.3357\n",
      "   Epoch 4/5, Loss: 0.3233\n",
      "   Epoch 5/5, Loss: 0.3132\n",
      "   Epoch 1/5, Loss: 0.3174\n",
      "   Epoch 2/5, Loss: 0.2890\n",
      "   Epoch 3/5, Loss: 0.2743\n",
      "   Epoch 4/5, Loss: 0.2663\n",
      "   Epoch 5/5, Loss: 0.2622\n",
      "   Epoch 1/5, Loss: 0.2457\n",
      "   Epoch 2/5, Loss: 0.2324\n",
      "   Epoch 3/5, Loss: 0.2275\n",
      "   Epoch 4/5, Loss: 0.2237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 03:55:56,681] Trial 6 finished with value: 0.7081992834806442 and parameters: {'hidden_size': 39, 'num_layers': 3, 'dropout': 0.48923495187385246, 'lr': 0.0005441263592050816, 'time_step_in': 42, 'time_step_out': 6, 'stride': 2, 'num_lags': 2, 'lag_0': 3, 'lag_1': 4, 'num_windows': 3, 'window_0': 22, 'window_1': 19, 'window_2': 17}. Best is trial 5 with value: 0.5604017861187458.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 5/5, Loss: 0.2181\n",
      "   Epoch 1/5, Loss: 0.2112\n",
      "   Epoch 2/5, Loss: 0.1879\n",
      "   Epoch 3/5, Loss: 0.1858\n",
      "   Epoch 4/5, Loss: 0.1820\n",
      "   Epoch 5/5, Loss: 0.1782\n",
      "   Epoch 1/5, Loss: 0.3133\n",
      "   Epoch 2/5, Loss: 0.2933\n",
      "   Epoch 3/5, Loss: 0.2878\n",
      "   Epoch 4/5, Loss: 0.2748\n",
      "   Epoch 5/5, Loss: 0.2753\n",
      "   Epoch 1/5, Loss: 0.3141\n",
      "   Epoch 2/5, Loss: 0.2998\n",
      "   Epoch 3/5, Loss: 0.2972\n",
      "   Epoch 4/5, Loss: 0.2940\n",
      "   Epoch 5/5, Loss: 0.2886\n",
      "   Epoch 1/5, Loss: 0.2933\n",
      "   Epoch 2/5, Loss: 0.2727\n",
      "   Epoch 3/5, Loss: 0.2634\n",
      "   Epoch 4/5, Loss: 0.2557\n",
      "   Epoch 5/5, Loss: 0.2485\n",
      "   Epoch 1/5, Loss: 0.2196\n",
      "   Epoch 2/5, Loss: 0.2099\n",
      "   Epoch 3/5, Loss: 0.2072\n",
      "   Epoch 4/5, Loss: 0.2018\n",
      "   Epoch 5/5, Loss: 0.1999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 03:57:22,511] Trial 7 finished with value: 0.6114205494523048 and parameters: {'hidden_size': 241, 'num_layers': 2, 'dropout': 0.1413404008688373, 'lr': 0.0018421971853541657, 'time_step_in': 39, 'time_step_out': 2, 'stride': 5, 'num_lags': 3, 'lag_0': 5, 'lag_1': 1, 'lag_2': 4, 'num_windows': 2, 'window_0': 8, 'window_1': 13}. Best is trial 5 with value: 0.5604017861187458.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1/5, Loss: 0.6875\n",
      "   Epoch 2/5, Loss: 0.5172\n",
      "   Epoch 3/5, Loss: 0.5149\n",
      "   Epoch 4/5, Loss: 0.5164\n",
      "   Epoch 5/5, Loss: 0.5151\n",
      "   Early stopping at epoch 5\n",
      "   Epoch 1/5, Loss: 0.4536\n",
      "   Epoch 2/5, Loss: 0.3924\n",
      "   Epoch 3/5, Loss: 0.3922\n",
      "   Epoch 4/5, Loss: 0.3863\n",
      "   Epoch 5/5, Loss: 0.3924\n",
      "   Epoch 1/5, Loss: 0.4114\n",
      "   Epoch 2/5, Loss: 0.3858\n",
      "   Epoch 3/5, Loss: 0.3875\n",
      "   Epoch 4/5, Loss: 0.3868\n",
      "   Early stopping at epoch 4\n",
      "   Epoch 1/5, Loss: 0.3696\n",
      "   Epoch 2/5, Loss: 0.3585\n",
      "   Epoch 3/5, Loss: 0.3552\n",
      "   Epoch 4/5, Loss: 0.3555\n",
      "   Epoch 5/5, Loss: 0.3562\n",
      "   Early stopping at epoch 5\n",
      "   Epoch 1/5, Loss: 0.3080\n",
      "   Epoch 2/5, Loss: 0.2856\n",
      "   Epoch 3/5, Loss: 0.2829\n",
      "   Epoch 4/5, Loss: 0.2830\n",
      "   Epoch 5/5, Loss: 0.2823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 03:59:10,282] Trial 8 finished with value: 0.674920505285263 and parameters: {'hidden_size': 250, 'num_layers': 3, 'dropout': 0.04874598097027932, 'lr': 0.009237047819114896, 'time_step_in': 37, 'time_step_out': 2, 'stride': 5, 'num_lags': 1, 'lag_0': 3, 'num_windows': 3, 'window_0': 13, 'window_1': 13, 'window_2': 12}. Best is trial 5 with value: 0.5604017861187458.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1/5, Loss: 0.1806\n",
      "   Epoch 2/5, Loss: 0.1714\n",
      "   Epoch 3/5, Loss: 0.1680\n",
      "   Epoch 4/5, Loss: 0.1676\n",
      "   Epoch 5/5, Loss: 0.1680\n",
      "   Epoch 1/5, Loss: 0.3051\n",
      "   Epoch 2/5, Loss: 0.2758\n",
      "   Epoch 3/5, Loss: 0.2580\n",
      "   Epoch 4/5, Loss: 0.2577\n",
      "   Epoch 5/5, Loss: 0.2410\n",
      "   Epoch 1/5, Loss: 0.2900\n",
      "   Epoch 2/5, Loss: 0.2687\n",
      "   Epoch 3/5, Loss: 0.2635\n",
      "   Epoch 4/5, Loss: 0.2553\n",
      "   Epoch 5/5, Loss: 0.2518\n",
      "   Epoch 1/5, Loss: 0.2517\n",
      "   Epoch 2/5, Loss: 0.2405\n",
      "   Epoch 3/5, Loss: 0.2333\n",
      "   Epoch 4/5, Loss: 0.2235\n",
      "   Epoch 5/5, Loss: 0.2194\n",
      "   Epoch 1/5, Loss: 0.2068\n",
      "   Epoch 2/5, Loss: 0.1929\n",
      "   Epoch 3/5, Loss: 0.1892\n",
      "   Epoch 4/5, Loss: 0.1856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 03:59:59,268] Trial 9 finished with value: 0.7885393142700196 and parameters: {'hidden_size': 208, 'num_layers': 1, 'dropout': 0.44413616640961245, 'lr': 0.007867713262471685, 'time_step_in': 28, 'time_step_out': 1, 'stride': 4, 'num_lags': 1, 'lag_0': 7, 'num_windows': 1, 'window_0': 18}. Best is trial 5 with value: 0.5604017861187458.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 5/5, Loss: 0.1789\n",
      "   Epoch 1/5, Loss: 0.1451\n",
      "   Epoch 2/5, Loss: 0.1403\n",
      "   Epoch 3/5, Loss: 0.1388\n",
      "   Epoch 4/5, Loss: 0.1383\n",
      "   Epoch 5/5, Loss: 0.1367\n",
      "   Epoch 1/5, Loss: 0.2618\n",
      "   Epoch 2/5, Loss: 0.2454\n",
      "   Epoch 3/5, Loss: 0.2489\n",
      "   Epoch 4/5, Loss: 0.2369\n",
      "   Epoch 5/5, Loss: 0.2337\n",
      "   Epoch 1/5, Loss: 0.2885\n",
      "   Epoch 2/5, Loss: 0.2842\n",
      "   Epoch 3/5, Loss: 0.2817\n",
      "   Epoch 4/5, Loss: 0.2780\n",
      "   Epoch 5/5, Loss: 0.2762\n",
      "   Epoch 1/5, Loss: 0.2597\n",
      "   Epoch 2/5, Loss: 0.2395\n",
      "   Epoch 3/5, Loss: 0.2281\n",
      "   Epoch 4/5, Loss: 0.2244\n",
      "   Epoch 5/5, Loss: 0.2209\n",
      "   Epoch 1/5, Loss: 0.2174\n",
      "   Epoch 2/5, Loss: 0.2102\n",
      "   Epoch 3/5, Loss: 0.2055\n",
      "   Epoch 4/5, Loss: 0.2015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 04:00:33,108] Trial 10 finished with value: 0.8910842418670655 and parameters: {'hidden_size': 96, 'num_layers': 1, 'dropout': 0.22339505452922817, 'lr': 0.003175218953049216, 'time_step_in': 21, 'time_step_out': 4, 'stride': 6, 'num_lags': 2, 'lag_0': 9, 'lag_1': 12, 'num_windows': 2, 'window_0': 9, 'window_1': 4}. Best is trial 5 with value: 0.5604017861187458.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 5/5, Loss: 0.1990\n",
      "   Epoch 1/5, Loss: 0.7410\n",
      "   Epoch 2/5, Loss: 0.7134\n",
      "   Epoch 3/5, Loss: 0.6997\n",
      "   Epoch 4/5, Loss: 0.6852\n",
      "   Epoch 5/5, Loss: 0.6483\n",
      "   Epoch 1/5, Loss: 0.5342\n",
      "   Epoch 2/5, Loss: 0.4981\n",
      "   Epoch 3/5, Loss: 0.4810\n",
      "   Epoch 4/5, Loss: 0.4723\n",
      "   Epoch 5/5, Loss: 0.4676\n",
      "   Epoch 1/5, Loss: 0.4354\n",
      "   Epoch 2/5, Loss: 0.4226\n",
      "   Epoch 3/5, Loss: 0.4059\n",
      "   Epoch 4/5, Loss: 0.4021\n",
      "   Epoch 5/5, Loss: 0.3951\n",
      "   Epoch 1/5, Loss: 0.3767\n",
      "   Epoch 2/5, Loss: 0.3562\n",
      "   Epoch 3/5, Loss: 0.3450\n",
      "   Epoch 4/5, Loss: 0.3333\n",
      "   Epoch 5/5, Loss: 0.3256\n",
      "   Epoch 1/5, Loss: 0.2797\n",
      "   Epoch 2/5, Loss: 0.2681\n",
      "   Epoch 3/5, Loss: 0.2576\n",
      "   Epoch 4/5, Loss: 0.2528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 04:01:25,042] Trial 11 finished with value: 0.6746506243944168 and parameters: {'hidden_size': 250, 'num_layers': 1, 'dropout': 0.2020753250553183, 'lr': 0.0032737831158461163, 'time_step_in': 48, 'time_step_out': 2, 'stride': 6, 'num_lags': 3, 'lag_0': 5, 'lag_1': 1, 'lag_2': 9, 'num_windows': 2, 'window_0': 3, 'window_1': 11}. Best is trial 5 with value: 0.5604017861187458.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 5/5, Loss: 0.2559\n",
      "   Epoch 1/5, Loss: 0.1886\n",
      "   Epoch 2/5, Loss: 0.1855\n",
      "   Epoch 3/5, Loss: 0.1839\n",
      "   Epoch 4/5, Loss: 0.1822\n",
      "   Epoch 5/5, Loss: 0.1814\n",
      "   Epoch 1/5, Loss: 0.2441\n",
      "   Epoch 2/5, Loss: 0.2358\n",
      "   Epoch 3/5, Loss: 0.2299\n",
      "   Epoch 4/5, Loss: 0.2261\n",
      "   Epoch 5/5, Loss: 0.2212\n",
      "   Epoch 1/5, Loss: 0.3087\n",
      "   Epoch 2/5, Loss: 0.3005\n",
      "   Epoch 3/5, Loss: 0.2972\n",
      "   Epoch 4/5, Loss: 0.2938\n",
      "   Epoch 5/5, Loss: 0.2899\n",
      "   Epoch 1/5, Loss: 0.2755\n",
      "   Epoch 2/5, Loss: 0.2621\n",
      "   Epoch 3/5, Loss: 0.2544\n",
      "   Epoch 4/5, Loss: 0.2486\n",
      "   Epoch 5/5, Loss: 0.2432\n",
      "   Epoch 1/5, Loss: 0.2341\n",
      "   Epoch 2/5, Loss: 0.2240\n",
      "   Epoch 3/5, Loss: 0.2201\n",
      "   Epoch 4/5, Loss: 0.2182\n",
      "   Epoch 5/5, Loss: 0.2155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 04:02:46,483] Trial 12 finished with value: 0.588531781733036 and parameters: {'hidden_size': 162, 'num_layers': 2, 'dropout': 0.15409878155226184, 'lr': 0.00011627029298020157, 'time_step_in': 26, 'time_step_out': 2, 'stride': 5, 'num_lags': 3, 'lag_0': 5, 'lag_1': 1, 'lag_2': 1, 'num_windows': 2, 'window_0': 8, 'window_1': 8}. Best is trial 5 with value: 0.5604017861187458.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1/5, Loss: 0.5283\n",
      "   Epoch 2/5, Loss: 0.5202\n",
      "   Epoch 3/5, Loss: 0.5183\n",
      "   Epoch 4/5, Loss: 0.5160\n",
      "   Epoch 5/5, Loss: 0.5110\n",
      "   Epoch 1/5, Loss: 0.5220\n",
      "   Epoch 2/5, Loss: 0.5158\n",
      "   Epoch 3/5, Loss: 0.4995\n",
      "   Epoch 4/5, Loss: 0.4713\n",
      "   Epoch 5/5, Loss: 0.4594\n",
      "   Epoch 1/5, Loss: 0.4427\n",
      "   Epoch 2/5, Loss: 0.4351\n",
      "   Epoch 3/5, Loss: 0.4286\n",
      "   Epoch 4/5, Loss: 0.4166\n",
      "   Epoch 5/5, Loss: 0.4075\n",
      "   Epoch 1/5, Loss: 0.3883\n",
      "   Epoch 2/5, Loss: 0.3748\n",
      "   Epoch 3/5, Loss: 0.3578\n",
      "   Epoch 4/5, Loss: 0.3484\n",
      "   Epoch 5/5, Loss: 0.3384\n",
      "   Epoch 1/5, Loss: 0.2941\n",
      "   Epoch 2/5, Loss: 0.2790\n",
      "   Epoch 3/5, Loss: 0.2697\n",
      "   Epoch 4/5, Loss: 0.2625\n",
      "   Epoch 5/5, Loss: 0.2557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 04:03:50,643] Trial 13 finished with value: 0.6149514555931092 and parameters: {'hidden_size': 166, 'num_layers': 2, 'dropout': 0.31779413958261404, 'lr': 0.00011480270004148706, 'time_step_in': 24, 'time_step_out': 2, 'stride': 6, 'num_lags': 3, 'lag_0': 6, 'lag_1': 4, 'lag_2': 2, 'num_windows': 1, 'window_0': 10}. Best is trial 5 with value: 0.5604017861187458.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1/5, Loss: 0.0996\n",
      "   Epoch 2/5, Loss: 0.0908\n",
      "   Epoch 3/5, Loss: 0.0890\n",
      "   Epoch 4/5, Loss: 0.0873\n",
      "   Epoch 5/5, Loss: 0.0863\n",
      "   Epoch 1/5, Loss: 0.2272\n",
      "   Epoch 2/5, Loss: 0.2150\n",
      "   Epoch 3/5, Loss: 0.2080\n",
      "   Epoch 4/5, Loss: 0.2028\n",
      "   Epoch 5/5, Loss: 0.1994\n",
      "   Epoch 1/5, Loss: 0.2708\n",
      "   Epoch 2/5, Loss: 0.2568\n",
      "   Epoch 3/5, Loss: 0.2493\n",
      "   Epoch 4/5, Loss: 0.2439\n",
      "   Epoch 5/5, Loss: 0.2413\n",
      "   Epoch 1/5, Loss: 0.2507\n",
      "   Epoch 2/5, Loss: 0.2348\n",
      "   Epoch 3/5, Loss: 0.2267\n",
      "   Epoch 4/5, Loss: 0.2217\n",
      "   Epoch 5/5, Loss: 0.2169\n",
      "   Epoch 1/5, Loss: 0.1863\n",
      "   Epoch 2/5, Loss: 0.1754\n",
      "   Epoch 3/5, Loss: 0.1710\n",
      "   Epoch 4/5, Loss: 0.1683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 04:04:27,740] Trial 14 finished with value: 0.5810898393392563 and parameters: {'hidden_size': 105, 'num_layers': 1, 'dropout': 0.16940087867203957, 'lr': 0.00010084937675095396, 'time_step_in': 15, 'time_step_out': 1, 'stride': 5, 'num_lags': 2, 'lag_0': 1, 'lag_1': 4, 'num_windows': 2, 'window_0': 12, 'window_1': 7}. Best is trial 5 with value: 0.5604017861187458.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 5/5, Loss: 0.1663\n",
      "   Epoch 1/5, Loss: 0.1453\n",
      "   Epoch 2/5, Loss: 0.1412\n",
      "   Epoch 3/5, Loss: 0.1393\n",
      "   Epoch 4/5, Loss: 0.1380\n",
      "   Epoch 5/5, Loss: 0.1368\n",
      "   Epoch 1/5, Loss: 0.2772\n",
      "   Epoch 2/5, Loss: 0.2645\n",
      "   Epoch 3/5, Loss: 0.2567\n",
      "   Epoch 4/5, Loss: 0.2516\n",
      "   Epoch 5/5, Loss: 0.2462\n",
      "   Epoch 1/5, Loss: 0.2905\n",
      "   Epoch 2/5, Loss: 0.2810\n",
      "   Epoch 3/5, Loss: 0.2776\n",
      "   Epoch 4/5, Loss: 0.2744\n",
      "   Epoch 5/5, Loss: 0.2715\n",
      "   Epoch 1/5, Loss: 0.2472\n",
      "   Epoch 2/5, Loss: 0.2353\n",
      "   Epoch 3/5, Loss: 0.2309\n",
      "   Epoch 4/5, Loss: 0.2270\n",
      "   Epoch 5/5, Loss: 0.2231\n",
      "   Epoch 1/5, Loss: 0.2159\n",
      "   Epoch 2/5, Loss: 0.2082\n",
      "   Epoch 3/5, Loss: 0.2055\n",
      "   Epoch 4/5, Loss: 0.2032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 04:05:14,799] Trial 15 finished with value: 0.7155505537986755 and parameters: {'hidden_size': 84, 'num_layers': 1, 'dropout': 0.2905590094505598, 'lr': 0.00021484498217675044, 'time_step_in': 12, 'time_step_out': 1, 'stride': 3, 'num_lags': 1, 'lag_0': 1, 'num_windows': 1, 'window_0': 13}. Best is trial 5 with value: 0.5604017861187458.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 5/5, Loss: 0.2005\n",
      "   Epoch 1/5, Loss: 0.1592\n",
      "   Epoch 2/5, Loss: 0.1515\n",
      "   Epoch 3/5, Loss: 0.1502\n",
      "   Epoch 4/5, Loss: 0.1487\n",
      "   Epoch 5/5, Loss: 0.1484\n",
      "   Epoch 1/5, Loss: 0.2539\n",
      "   Epoch 2/5, Loss: 0.2299\n",
      "   Epoch 3/5, Loss: 0.2228\n",
      "   Epoch 4/5, Loss: 0.2180\n",
      "   Epoch 5/5, Loss: 0.2124\n",
      "   Epoch 1/5, Loss: 0.2571\n",
      "   Epoch 2/5, Loss: 0.2430\n",
      "   Epoch 3/5, Loss: 0.2376\n",
      "   Epoch 4/5, Loss: 0.2351\n",
      "   Epoch 5/5, Loss: 0.2353\n",
      "   Epoch 1/5, Loss: 0.2126\n",
      "   Epoch 2/5, Loss: 0.1943\n",
      "   Epoch 3/5, Loss: 0.1904\n",
      "   Epoch 4/5, Loss: 0.1856\n",
      "   Epoch 5/5, Loss: 0.1828\n",
      "   Epoch 1/5, Loss: 0.1818\n",
      "   Epoch 2/5, Loss: 0.1756\n",
      "   Epoch 3/5, Loss: 0.1703\n",
      "   Epoch 4/5, Loss: 0.1692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 04:05:48,356] Trial 16 finished with value: 0.5320963561534882 and parameters: {'hidden_size': 47, 'num_layers': 1, 'dropout': 0.19309511962864553, 'lr': 0.003951613886456789, 'time_step_in': 17, 'time_step_out': 1, 'stride': 6, 'num_lags': 2, 'lag_0': 1, 'lag_1': 5, 'num_windows': 2, 'window_0': 11, 'window_1': 3}. Best is trial 16 with value: 0.5320963561534882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 5/5, Loss: 0.1658\n",
      "   Epoch 1/5, Loss: 0.1559\n",
      "   Epoch 2/5, Loss: 0.1488\n",
      "   Epoch 3/5, Loss: 0.1426\n",
      "   Epoch 4/5, Loss: 0.1374\n",
      "   Epoch 5/5, Loss: 0.1345\n",
      "   Epoch 1/5, Loss: 0.1912\n",
      "   Epoch 2/5, Loss: 0.1791\n",
      "   Epoch 3/5, Loss: 0.1736\n",
      "   Epoch 4/5, Loss: 0.1701\n",
      "   Epoch 5/5, Loss: 0.1703\n",
      "   Epoch 1/5, Loss: 0.2649\n",
      "   Epoch 2/5, Loss: 0.2543\n",
      "   Epoch 3/5, Loss: 0.2513\n",
      "   Epoch 4/5, Loss: 0.2426\n",
      "   Epoch 5/5, Loss: 0.2434\n",
      "   Epoch 1/5, Loss: 0.2511\n",
      "   Epoch 2/5, Loss: 0.2258\n",
      "   Epoch 3/5, Loss: 0.2199\n",
      "   Epoch 4/5, Loss: 0.2115\n",
      "   Epoch 5/5, Loss: 0.2039\n",
      "   Epoch 1/5, Loss: 0.2123\n",
      "   Epoch 2/5, Loss: 0.2032\n",
      "   Epoch 3/5, Loss: 0.1978\n",
      "   Epoch 4/5, Loss: 0.1975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 04:06:18,920] Trial 17 finished with value: 0.5900735840201378 and parameters: {'hidden_size': 35, 'num_layers': 1, 'dropout': 7.892716176627346e-05, 'lr': 0.005116955339298123, 'time_step_in': 20, 'time_step_out': 3, 'stride': 6, 'num_lags': 2, 'lag_0': 10, 'lag_1': 7, 'num_windows': 1, 'window_0': 16}. Best is trial 16 with value: 0.5320963561534882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 5/5, Loss: 0.1947\n",
      "   Epoch 1/5, Loss: 0.2720\n",
      "   Epoch 2/5, Loss: 0.2638\n",
      "   Epoch 3/5, Loss: 0.2603\n",
      "   Epoch 4/5, Loss: 0.2594\n",
      "   Epoch 5/5, Loss: 0.2564\n",
      "   Epoch 1/5, Loss: 0.3068\n",
      "   Epoch 2/5, Loss: 0.2900\n",
      "   Epoch 3/5, Loss: 0.2789\n",
      "   Epoch 4/5, Loss: 0.2733\n",
      "   Epoch 5/5, Loss: 0.2682\n",
      "   Epoch 1/5, Loss: 0.3224\n",
      "   Epoch 2/5, Loss: 0.3131\n",
      "   Epoch 3/5, Loss: 0.3092\n",
      "   Epoch 4/5, Loss: 0.3054\n",
      "   Epoch 5/5, Loss: 0.3028\n",
      "   Epoch 1/5, Loss: 0.2854\n",
      "   Epoch 2/5, Loss: 0.2673\n",
      "   Epoch 3/5, Loss: 0.2581\n",
      "   Epoch 4/5, Loss: 0.2514\n",
      "   Epoch 5/5, Loss: 0.2441\n",
      "   Epoch 1/5, Loss: 0.2307\n",
      "   Epoch 2/5, Loss: 0.2220\n",
      "   Epoch 3/5, Loss: 0.2168\n",
      "   Epoch 4/5, Loss: 0.2124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 04:07:06,050] Trial 18 finished with value: 0.5791297808289528 and parameters: {'hidden_size': 62, 'num_layers': 1, 'dropout': 0.26649172983071134, 'lr': 0.0023953194603563337, 'time_step_in': 19, 'time_step_out': 4, 'stride': 4, 'num_lags': 1, 'lag_0': 8, 'num_windows': 3, 'window_0': 6, 'window_1': 16, 'window_2': 24}. Best is trial 16 with value: 0.5320963561534882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 5/5, Loss: 0.2115\n",
      "   Epoch 1/5, Loss: 0.3410\n",
      "   Epoch 2/5, Loss: 0.3325\n",
      "   Epoch 3/5, Loss: 0.3261\n",
      "   Epoch 4/5, Loss: 0.3216\n",
      "   Epoch 5/5, Loss: 0.3139\n",
      "   Epoch 1/5, Loss: 0.3222\n",
      "   Epoch 2/5, Loss: 0.3115\n",
      "   Epoch 3/5, Loss: 0.3047\n",
      "   Epoch 4/5, Loss: 0.3008\n",
      "   Epoch 5/5, Loss: 0.3054\n",
      "   Epoch 1/5, Loss: 0.3337\n",
      "   Epoch 2/5, Loss: 0.3273\n",
      "   Epoch 3/5, Loss: 0.3238\n",
      "   Epoch 4/5, Loss: 0.3211\n",
      "   Epoch 5/5, Loss: 0.3159\n",
      "   Epoch 1/5, Loss: 0.3018\n",
      "   Epoch 2/5, Loss: 0.2875\n",
      "   Epoch 3/5, Loss: 0.2713\n",
      "   Epoch 4/5, Loss: 0.2625\n",
      "   Epoch 5/5, Loss: 0.2540\n",
      "   Epoch 1/5, Loss: 0.2344\n",
      "   Epoch 2/5, Loss: 0.2278\n",
      "   Epoch 3/5, Loss: 0.2247\n",
      "   Epoch 4/5, Loss: 0.2218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 04:08:06,906] Trial 19 finished with value: 0.6016939610242844 and parameters: {'hidden_size': 65, 'num_layers': 1, 'dropout': 0.23832469164620387, 'lr': 0.005678646797161847, 'time_step_in': 31, 'time_step_out': 5, 'stride': 3, 'num_lags': 1, 'lag_0': 11, 'num_windows': 2, 'window_0': 10, 'window_1': 3}. Best is trial 16 with value: 0.5320963561534882.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 5/5, Loss: 0.2188\n",
      " Best parameters for 2020-04:\n",
      "  hidden_size: 47\n",
      "  num_layers: 1\n",
      "  dropout: 0.19309511962864553\n",
      "  lr: 0.003951613886456789\n",
      "  time_step_in: 17\n",
      "  time_step_out: 1\n",
      "  stride: 6\n",
      "  num_lags: 2\n",
      "  lag_0: 1\n",
      "  lag_1: 5\n",
      "  num_windows: 2\n",
      "  window_0: 11\n",
      "  window_1: 3\n",
      " Best parameters saved to best_params_2020-04.json\n",
      "\n",
      " Final evaluation on 2020-04, fold_1 test set\n",
      "\n",
      "====== Training model for 2020-04, fold_1 with best parameters\n",
      "====== Training model on train set...\n",
      "   Epoch 1/10, Loss: 0.1566\n",
      "   Epoch 2/10, Loss: 0.1528\n",
      "   Epoch 3/10, Loss: 0.1498\n",
      "   Epoch 4/10, Loss: 0.1485\n",
      "   Epoch 5/10, Loss: 0.1474\n",
      "   Epoch 6/10, Loss: 0.1468\n",
      "   Epoch 7/10, Loss: 0.1459\n",
      "   Epoch 8/10, Loss: 0.1465\n",
      "   Epoch 9/10, Loss: 0.1438\n",
      "   Epoch 10/10, Loss: 0.1449\n",
      "====== Evaluating on validation set...\n",
      "  Val RMSE: 0.6020, Bias: -0.0572, R²: 0.0977, CSI: 0.6580\n",
      "====== Evaluating on test set...\n",
      "  Test RMSE: 0.2879, Bias: 0.0255, R²: 0.0594, CSI: 0.2054\n",
      " Model saved to model_2020-04_fold_1.pt\n",
      "\n",
      " Final evaluation on 2020-04, fold_2 test set\n",
      "\n",
      "====== Training model for 2020-04, fold_2 with best parameters\n",
      "====== Training model on train set...\n",
      "   Epoch 1/10, Loss: 0.2454\n",
      "   Epoch 2/10, Loss: 0.2256\n",
      "   Epoch 3/10, Loss: 0.2184\n",
      "   Epoch 4/10, Loss: 0.2195\n",
      "   Epoch 5/10, Loss: 0.2132\n",
      "   Epoch 6/10, Loss: 0.2077\n",
      "   Epoch 7/10, Loss: 0.2083\n",
      "   Epoch 8/10, Loss: 0.2038\n",
      "   Epoch 9/10, Loss: 0.1987\n",
      "   Epoch 10/10, Loss: 0.1940\n",
      "====== Evaluating on validation set...\n",
      "  Val RMSE: 0.5872, Bias: -0.0460, R²: 0.2990, CSI: 0.5341\n",
      "====== Evaluating on test set...\n",
      "  Test RMSE: 0.3098, Bias: 0.0442, R²: -0.0891, CSI: 0.0703\n",
      " Model saved to model_2020-04_fold_2.pt\n",
      "\n",
      " Final evaluation on 2020-04, fold_3 test set\n",
      "\n",
      "====== Training model for 2020-04, fold_3 with best parameters\n",
      "====== Training model on train set...\n",
      "   Epoch 1/10, Loss: 0.2540\n",
      "   Epoch 2/10, Loss: 0.2414\n",
      "   Epoch 3/10, Loss: 0.2376\n",
      "   Epoch 4/10, Loss: 0.2338\n",
      "   Epoch 5/10, Loss: 0.2317\n",
      "   Epoch 6/10, Loss: 0.2274\n",
      "   Epoch 7/10, Loss: 0.2261\n",
      "   Epoch 8/10, Loss: 0.2250\n",
      "   Epoch 9/10, Loss: 0.2213\n",
      "   Epoch 10/10, Loss: 0.2184\n",
      "====== Evaluating on validation set...\n",
      "  Val RMSE: 0.0674, Bias: -0.0007, R²: 0.0459, CSI: 0.1375\n",
      "====== Evaluating on test set...\n",
      "  Test RMSE: 0.2894, Bias: 0.0274, R²: 0.0499, CSI: 0.2100\n",
      " Model saved to model_2020-04_fold_3.pt\n",
      "\n",
      " Final evaluation on 2020-04, fold_4 test set\n",
      "\n",
      "====== Training model for 2020-04, fold_4 with best parameters\n",
      "====== Training model on train set...\n",
      "   Epoch 1/10, Loss: 0.2112\n",
      "   Epoch 2/10, Loss: 0.1943\n",
      "   Epoch 3/10, Loss: 0.1882\n",
      "   Epoch 4/10, Loss: 0.1853\n",
      "   Epoch 5/10, Loss: 0.1814\n",
      "   Epoch 6/10, Loss: 0.1789\n",
      "   Epoch 7/10, Loss: 0.1803\n",
      "   Epoch 8/10, Loss: 0.1754\n",
      "   Epoch 9/10, Loss: 0.1731\n",
      "   Epoch 10/10, Loss: 0.1707\n",
      "====== Evaluating on validation set...\n",
      "  Val RMSE: 0.4185, Bias: -0.0315, R²: 0.0557, CSI: 0.3916\n",
      "====== Evaluating on test set...\n",
      "  Test RMSE: 0.2858, Bias: 0.0262, R²: 0.0736, CSI: 0.1650\n",
      " Model saved to model_2020-04_fold_4.pt\n",
      "\n",
      " Final evaluation on 2020-04, fold_5 test set\n",
      "\n",
      "====== Training model for 2020-04, fold_5 with best parameters\n",
      "====== Training model on train set...\n",
      "   Epoch 1/10, Loss: 0.1833\n",
      "   Epoch 2/10, Loss: 0.1751\n",
      "   Epoch 3/10, Loss: 0.1718\n",
      "   Epoch 4/10, Loss: 0.1683\n",
      "   Epoch 5/10, Loss: 0.1672\n",
      "   Epoch 6/10, Loss: 0.1675\n",
      "   Epoch 7/10, Loss: 0.1642\n",
      "   Epoch 8/10, Loss: 0.1624\n",
      "   Epoch 9/10, Loss: 0.1582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 04:08:54,902] A new study created in memory with name: 2020-10_study\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 10/10, Loss: 0.1580\n",
      "====== Evaluating on validation set...\n",
      "  Val RMSE: 0.9868, Bias: -0.1526, R²: 0.1367, CSI: 0.6714\n",
      "====== Evaluating on test set...\n",
      "  Test RMSE: 0.2887, Bias: 0.0385, R²: 0.0547, CSI: 0.1033\n",
      " Model saved to model_2020-04_fold_5.pt\n",
      "\n",
      " Mean test performance for 2020-04:\n",
      "  RMSE: 0.2923, Bias: 0.0324, R²: 0.0297, CSI: 0.1508\n",
      " Best fold test performance for 2020-04 (fold fold_4):\n",
      "  RMSE: 0.2858, Bias: 0.0262, R²: 0.0736, CSI: 0.1650\n",
      " Best model for 2020-04 saved to best_model_2020-04.pt\n",
      "\n",
      "###### Processing month: 2020-10\n",
      "   Epoch 1/5, Loss: 2.4152\n",
      "   Epoch 2/5, Loss: 1.8269\n",
      "   Epoch 3/5, Loss: 1.6498\n",
      "   Epoch 4/5, Loss: 1.5441\n",
      "   Epoch 5/5, Loss: 1.4743\n",
      "   Epoch 1/5, Loss: 1.7554\n",
      "   Epoch 2/5, Loss: 1.3621\n",
      "   Epoch 3/5, Loss: 1.2353\n",
      "   Epoch 4/5, Loss: 1.1401\n",
      "   Epoch 5/5, Loss: 1.0882\n",
      "   Epoch 1/5, Loss: 1.6518\n",
      "   Epoch 2/5, Loss: 1.2470\n",
      "   Epoch 3/5, Loss: 1.1128\n",
      "   Epoch 4/5, Loss: 1.0447\n",
      "   Epoch 5/5, Loss: 1.0015\n",
      "   Epoch 1/5, Loss: 1.5601\n",
      "   Epoch 2/5, Loss: 1.1543\n",
      "   Epoch 3/5, Loss: 1.0409\n",
      "   Epoch 4/5, Loss: 0.9966\n",
      "   Epoch 5/5, Loss: 0.9591\n",
      "   Epoch 1/5, Loss: 1.5164\n",
      "   Epoch 2/5, Loss: 1.1142\n",
      "   Epoch 3/5, Loss: 1.0254\n",
      "   Epoch 4/5, Loss: 0.9754\n",
      "   Epoch 5/5, Loss: 0.9511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 04:17:54,574] Trial 0 finished with value: 1.0021047711372375 and parameters: {'hidden_size': 188, 'num_layers': 2, 'dropout': 0.1990680107401797, 'lr': 0.000127233756628581, 'time_step_in': 47, 'time_step_out': 1, 'stride': 1, 'num_lags': 2, 'lag_0': 9, 'lag_1': 3, 'num_windows': 2, 'window_0': 12, 'window_1': 21}. Best is trial 0 with value: 1.0021047711372375.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1/5, Loss: 2.8832\n",
      "   Epoch 2/5, Loss: 2.1438\n",
      "   Epoch 3/5, Loss: 1.8998\n",
      "   Epoch 4/5, Loss: 1.7416\n",
      "   Epoch 5/5, Loss: 1.6714\n",
      "   Epoch 1/5, Loss: 2.1541\n",
      "   Epoch 2/5, Loss: 1.6169\n",
      "   Epoch 3/5, Loss: 1.4827\n",
      "   Epoch 4/5, Loss: 1.4005\n",
      "   Epoch 5/5, Loss: 1.3703\n",
      "   Epoch 1/5, Loss: 1.9882\n",
      "   Epoch 2/5, Loss: 1.5079\n",
      "   Epoch 3/5, Loss: 1.4276\n",
      "   Epoch 4/5, Loss: 1.3759\n",
      "   Epoch 5/5, Loss: 1.3248\n",
      "   Epoch 1/5, Loss: 1.8949\n",
      "   Epoch 2/5, Loss: 1.4628\n",
      "   Epoch 3/5, Loss: 1.3864\n",
      "   Epoch 4/5, Loss: 1.3240\n",
      "   Epoch 5/5, Loss: 1.2764\n",
      "   Epoch 1/5, Loss: 1.8555\n",
      "   Epoch 2/5, Loss: 1.4388\n",
      "   Epoch 3/5, Loss: 1.3523\n",
      "   Epoch 4/5, Loss: 1.2894\n",
      "   Epoch 5/5, Loss: 1.2478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 04:21:11,451] Trial 1 finished with value: 1.315560793876648 and parameters: {'hidden_size': 189, 'num_layers': 3, 'dropout': 0.4105682885781912, 'lr': 0.00022640742094724077, 'time_step_in': 33, 'time_step_out': 4, 'stride': 3, 'num_lags': 3, 'lag_0': 3, 'lag_1': 10, 'lag_2': 9, 'num_windows': 2, 'window_0': 5, 'window_1': 17}. Best is trial 0 with value: 1.0021047711372375.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1/5, Loss: 2.3690\n",
      "   Epoch 2/5, Loss: 1.8356\n",
      "   Epoch 3/5, Loss: 1.7441\n",
      "   Epoch 4/5, Loss: 1.7042\n",
      "   Epoch 5/5, Loss: 1.5986\n",
      "   Epoch 1/5, Loss: 1.7778\n",
      "   Epoch 2/5, Loss: 1.4842\n",
      "   Epoch 3/5, Loss: 1.3850\n",
      "   Epoch 4/5, Loss: 1.2725\n",
      "   Epoch 5/5, Loss: 1.2554\n",
      "   Epoch 1/5, Loss: 1.6864\n",
      "   Epoch 2/5, Loss: 1.4075\n",
      "   Epoch 3/5, Loss: 1.3034\n",
      "   Epoch 4/5, Loss: 1.2654\n",
      "   Epoch 5/5, Loss: 1.1988\n",
      "   Epoch 1/5, Loss: 1.6162\n",
      "   Epoch 2/5, Loss: 1.3466\n",
      "   Epoch 3/5, Loss: 1.2794\n",
      "   Epoch 4/5, Loss: 1.2353\n",
      "   Epoch 5/5, Loss: 1.1961\n",
      "   Epoch 1/5, Loss: 1.6349\n",
      "   Epoch 2/5, Loss: 1.3620\n",
      "   Epoch 3/5, Loss: 1.2428\n",
      "   Epoch 4/5, Loss: 1.1817\n",
      "   Epoch 5/5, Loss: 1.1436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 04:22:42,798] Trial 2 finished with value: 1.196418786048889 and parameters: {'hidden_size': 182, 'num_layers': 1, 'dropout': 0.2953511800468232, 'lr': 0.001253637754860127, 'time_step_in': 43, 'time_step_out': 3, 'stride': 4, 'num_lags': 2, 'lag_0': 4, 'lag_1': 11, 'num_windows': 3, 'window_0': 14, 'window_1': 10, 'window_2': 23}. Best is trial 0 with value: 1.0021047711372375.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1/5, Loss: 2.5532\n",
      "   Epoch 2/5, Loss: 1.9852\n",
      "   Epoch 3/5, Loss: 1.9073\n",
      "   Epoch 4/5, Loss: 1.7100\n",
      "   Epoch 5/5, Loss: 1.7088\n",
      "   Epoch 1/5, Loss: 1.9359\n",
      "   Epoch 2/5, Loss: 1.5941\n",
      "   Epoch 3/5, Loss: 1.5011\n",
      "   Epoch 4/5, Loss: 1.4933\n",
      "   Epoch 5/5, Loss: 1.4252\n",
      "   Epoch 1/5, Loss: 1.8662\n",
      "   Epoch 2/5, Loss: 1.5432\n",
      "   Epoch 3/5, Loss: 1.4813\n",
      "   Epoch 4/5, Loss: 1.4312\n",
      "   Epoch 5/5, Loss: 1.3820\n",
      "   Epoch 1/5, Loss: 1.8263\n",
      "   Epoch 2/5, Loss: 1.5348\n",
      "   Epoch 3/5, Loss: 1.4503\n",
      "   Epoch 4/5, Loss: 1.4187\n",
      "   Epoch 5/5, Loss: 1.3919\n",
      "   Epoch 1/5, Loss: 1.7294\n",
      "   Epoch 2/5, Loss: 1.5143\n",
      "   Epoch 3/5, Loss: 1.4416\n",
      "   Epoch 4/5, Loss: 1.3727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 04:23:24,838] Trial 3 finished with value: 1.2962304592132567 and parameters: {'hidden_size': 71, 'num_layers': 3, 'dropout': 0.0489230733744796, 'lr': 0.0056504900582748105, 'time_step_in': 38, 'time_step_out': 4, 'stride': 5, 'num_lags': 3, 'lag_0': 5, 'lag_1': 5, 'lag_2': 10, 'num_windows': 1, 'window_0': 17}. Best is trial 0 with value: 1.0021047711372375.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 5/5, Loss: 1.3765\n",
      "   Epoch 1/5, Loss: 2.6277\n",
      "   Epoch 2/5, Loss: 1.5797\n",
      "   Epoch 3/5, Loss: 1.4385\n",
      "   Epoch 4/5, Loss: 1.2780\n",
      "   Epoch 5/5, Loss: 1.2146\n",
      "   Epoch 1/5, Loss: 1.7888\n",
      "   Epoch 2/5, Loss: 1.2451\n",
      "   Epoch 3/5, Loss: 1.1670\n",
      "   Epoch 4/5, Loss: 1.1549\n",
      "   Epoch 5/5, Loss: 1.1152\n",
      "   Epoch 1/5, Loss: 1.5533\n",
      "   Epoch 2/5, Loss: 1.2238\n",
      "   Epoch 3/5, Loss: 1.1398\n",
      "   Epoch 4/5, Loss: 1.1084\n",
      "   Epoch 5/5, Loss: 1.1253\n",
      "   Epoch 1/5, Loss: 1.5109\n",
      "   Epoch 2/5, Loss: 1.1769\n",
      "   Epoch 3/5, Loss: 1.1286\n",
      "   Epoch 4/5, Loss: 1.1120\n",
      "   Epoch 5/5, Loss: 1.0705\n",
      "   Epoch 1/5, Loss: 1.4308\n",
      "   Epoch 2/5, Loss: 1.1747\n",
      "   Epoch 3/5, Loss: 1.1128\n",
      "   Epoch 4/5, Loss: 1.1240\n",
      "   Epoch 5/5, Loss: 1.0743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 04:24:54,336] Trial 4 finished with value: 1.0353346109390258 and parameters: {'hidden_size': 222, 'num_layers': 3, 'dropout': 0.08194826444669034, 'lr': 0.007256014141035618, 'time_step_in': 40, 'time_step_out': 1, 'stride': 5, 'num_lags': 1, 'lag_0': 5, 'num_windows': 3, 'window_0': 14, 'window_1': 12, 'window_2': 8}. Best is trial 0 with value: 1.0021047711372375.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1/5, Loss: 2.6149\n",
      "   Epoch 2/5, Loss: 1.8251\n",
      "   Epoch 3/5, Loss: 1.7911\n",
      "   Epoch 4/5, Loss: 1.6551\n",
      "   Epoch 5/5, Loss: 1.6914\n",
      "   Epoch 1/5, Loss: 1.8993\n",
      "   Epoch 2/5, Loss: 1.5229\n",
      "   Epoch 3/5, Loss: 1.4770\n",
      "   Epoch 4/5, Loss: 1.5414\n",
      "   Epoch 5/5, Loss: 1.4913\n",
      "   Early stopping at epoch 5\n",
      "   Epoch 1/5, Loss: 1.7605\n",
      "   Epoch 2/5, Loss: 1.4801\n",
      "   Epoch 3/5, Loss: 1.4485\n",
      "   Epoch 4/5, Loss: 1.4397\n",
      "   Epoch 5/5, Loss: 1.4202\n",
      "   Epoch 1/5, Loss: 1.7267\n",
      "   Epoch 2/5, Loss: 1.4763\n",
      "   Epoch 3/5, Loss: 1.4608\n",
      "   Epoch 4/5, Loss: 1.4219\n",
      "   Epoch 5/5, Loss: 1.3812\n",
      "   Epoch 1/5, Loss: 1.7066\n",
      "   Epoch 2/5, Loss: 1.5094\n",
      "   Epoch 3/5, Loss: 1.4485\n",
      "   Epoch 4/5, Loss: 1.4248\n",
      "   Epoch 5/5, Loss: 1.3826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 04:26:48,886] Trial 5 finished with value: 1.26138676404953 and parameters: {'hidden_size': 213, 'num_layers': 3, 'dropout': 0.4796811692267192, 'lr': 0.005160042869315811, 'time_step_in': 45, 'time_step_out': 5, 'stride': 4, 'num_lags': 2, 'lag_0': 9, 'lag_1': 6, 'num_windows': 3, 'window_0': 23, 'window_1': 3, 'window_2': 24}. Best is trial 0 with value: 1.0021047711372375.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1/5, Loss: 2.8050\n",
      "   Epoch 2/5, Loss: 2.0889\n",
      "   Epoch 3/5, Loss: 1.7736\n",
      "   Epoch 4/5, Loss: 1.6382\n",
      "   Epoch 5/5, Loss: 1.5282\n",
      "   Epoch 1/5, Loss: 2.1189\n",
      "   Epoch 2/5, Loss: 1.4738\n",
      "   Epoch 3/5, Loss: 1.3388\n",
      "   Epoch 4/5, Loss: 1.2854\n",
      "   Epoch 5/5, Loss: 1.2520\n",
      "   Epoch 1/5, Loss: 1.9186\n",
      "   Epoch 2/5, Loss: 1.3722\n",
      "   Epoch 3/5, Loss: 1.3035\n",
      "   Epoch 4/5, Loss: 1.2559\n",
      "   Epoch 5/5, Loss: 1.2110\n",
      "   Epoch 1/5, Loss: 1.7615\n",
      "   Epoch 2/5, Loss: 1.3370\n",
      "   Epoch 3/5, Loss: 1.2736\n",
      "   Epoch 4/5, Loss: 1.2355\n",
      "   Epoch 5/5, Loss: 1.1883\n",
      "   Epoch 1/5, Loss: 1.7423\n",
      "   Epoch 2/5, Loss: 1.3306\n",
      "   Epoch 3/5, Loss: 1.2776\n",
      "   Epoch 4/5, Loss: 1.2246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 04:27:53,743] Trial 6 finished with value: 1.2759917020797729 and parameters: {'hidden_size': 94, 'num_layers': 3, 'dropout': 0.08085459755166102, 'lr': 0.0004342232551656716, 'time_step_in': 32, 'time_step_out': 4, 'stride': 3, 'num_lags': 2, 'lag_0': 9, 'lag_1': 10, 'num_windows': 2, 'window_0': 4, 'window_1': 9}. Best is trial 0 with value: 1.0021047711372375.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 5/5, Loss: 1.1823\n",
      "   Epoch 1/5, Loss: 2.2053\n",
      "   Epoch 2/5, Loss: 1.7178\n",
      "   Epoch 3/5, Loss: 1.5622\n",
      "   Epoch 4/5, Loss: 1.5684\n",
      "   Epoch 5/5, Loss: 1.5163\n",
      "   Epoch 1/5, Loss: 1.6723\n",
      "   Epoch 2/5, Loss: 1.4081\n",
      "   Epoch 3/5, Loss: 1.3506\n",
      "   Epoch 4/5, Loss: 1.2884\n",
      "   Epoch 5/5, Loss: 1.2445\n",
      "   Epoch 1/5, Loss: 1.5997\n",
      "   Epoch 2/5, Loss: 1.3535\n",
      "   Epoch 3/5, Loss: 1.2857\n",
      "   Epoch 4/5, Loss: 1.2427\n",
      "   Epoch 5/5, Loss: 1.2011\n",
      "   Epoch 1/5, Loss: 1.5708\n",
      "   Epoch 2/5, Loss: 1.3259\n",
      "   Epoch 3/5, Loss: 1.2804\n",
      "   Epoch 4/5, Loss: 1.2301\n",
      "   Epoch 5/5, Loss: 1.1925\n",
      "   Epoch 1/5, Loss: 1.5864\n",
      "   Epoch 2/5, Loss: 1.2901\n",
      "   Epoch 3/5, Loss: 1.2245\n",
      "   Epoch 4/5, Loss: 1.1771\n",
      "   Epoch 5/5, Loss: 1.1571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 04:29:27,363] Trial 7 finished with value: 1.0914056420326232 and parameters: {'hidden_size': 95, 'num_layers': 3, 'dropout': 0.4709166445273569, 'lr': 0.0059848803697350305, 'time_step_in': 39, 'time_step_out': 1, 'stride': 2, 'num_lags': 1, 'lag_0': 4, 'num_windows': 1, 'window_0': 23}. Best is trial 0 with value: 1.0021047711372375.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1/5, Loss: 2.3862\n",
      "   Epoch 2/5, Loss: 1.6967\n",
      "   Epoch 3/5, Loss: 1.6023\n",
      "   Epoch 4/5, Loss: 1.5574\n",
      "   Epoch 5/5, Loss: 1.5184\n",
      "   Epoch 1/5, Loss: 1.7802\n",
      "   Epoch 2/5, Loss: 1.4608\n",
      "   Epoch 3/5, Loss: 1.4017\n",
      "   Epoch 4/5, Loss: 1.3553\n",
      "   Epoch 5/5, Loss: 1.3132\n",
      "   Epoch 1/5, Loss: 1.7111\n",
      "   Epoch 2/5, Loss: 1.4259\n",
      "   Epoch 3/5, Loss: 1.3544\n",
      "   Epoch 4/5, Loss: 1.3008\n",
      "   Epoch 5/5, Loss: 1.2641\n",
      "   Epoch 1/5, Loss: 1.6490\n",
      "   Epoch 2/5, Loss: 1.3964\n",
      "   Epoch 3/5, Loss: 1.3159\n",
      "   Epoch 4/5, Loss: 1.2553\n",
      "   Epoch 5/5, Loss: 1.2120\n",
      "   Epoch 1/5, Loss: 1.6313\n",
      "   Epoch 2/5, Loss: 1.3724\n",
      "   Epoch 3/5, Loss: 1.2833\n",
      "   Epoch 4/5, Loss: 1.2375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 04:30:31,421] Trial 8 finished with value: 1.2898480653762818 and parameters: {'hidden_size': 117, 'num_layers': 1, 'dropout': 0.2054806764568176, 'lr': 0.0004520851497052328, 'time_step_in': 22, 'time_step_out': 2, 'stride': 2, 'num_lags': 2, 'lag_0': 11, 'lag_1': 2, 'num_windows': 1, 'window_0': 22}. Best is trial 0 with value: 1.0021047711372375.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 5/5, Loss: 1.1809\n",
      "   Epoch 1/5, Loss: 3.2418\n",
      "   Epoch 2/5, Loss: 2.4449\n",
      "   Epoch 3/5, Loss: 2.1980\n",
      "   Epoch 4/5, Loss: 2.0661\n",
      "   Epoch 5/5, Loss: 1.9796\n",
      "   Epoch 1/5, Loss: 2.3233\n",
      "   Epoch 2/5, Loss: 1.7722\n",
      "   Epoch 3/5, Loss: 1.6449\n",
      "   Epoch 4/5, Loss: 1.5802\n",
      "   Epoch 5/5, Loss: 1.5637\n",
      "   Epoch 1/5, Loss: 2.1962\n",
      "   Epoch 2/5, Loss: 1.7016\n",
      "   Epoch 3/5, Loss: 1.6117\n",
      "   Epoch 4/5, Loss: 1.5783\n",
      "   Epoch 5/5, Loss: 1.5340\n",
      "   Epoch 1/5, Loss: 2.1000\n",
      "   Epoch 2/5, Loss: 1.6668\n",
      "   Epoch 3/5, Loss: 1.6022\n",
      "   Epoch 4/5, Loss: 1.5542\n",
      "   Epoch 5/5, Loss: 1.4837\n",
      "   Epoch 1/5, Loss: 2.0713\n",
      "   Epoch 2/5, Loss: 1.7050\n",
      "   Epoch 3/5, Loss: 1.6389\n",
      "   Epoch 4/5, Loss: 1.6112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 04:31:44,749] Trial 9 finished with value: 1.308059322834015 and parameters: {'hidden_size': 204, 'num_layers': 2, 'dropout': 0.017613114409996078, 'lr': 0.0002488571610912915, 'time_step_in': 45, 'time_step_out': 6, 'stride': 5, 'num_lags': 2, 'lag_0': 4, 'lag_1': 1, 'num_windows': 2, 'window_0': 22, 'window_1': 17}. Best is trial 0 with value: 1.0021047711372375.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 5/5, Loss: 1.5081\n",
      "   Epoch 1/5, Loss: 1.5131\n",
      "   Epoch 2/5, Loss: 1.3753\n",
      "   Epoch 3/5, Loss: 1.2940\n",
      "   Epoch 4/5, Loss: 1.2467\n",
      "   Epoch 5/5, Loss: 1.1996\n",
      "   Epoch 1/5, Loss: 1.3704\n",
      "   Epoch 2/5, Loss: 1.2044\n",
      "   Epoch 3/5, Loss: 1.1464\n",
      "   Epoch 4/5, Loss: 1.1097\n",
      "   Epoch 5/5, Loss: 1.0806\n",
      "   Epoch 1/5, Loss: 1.3519\n",
      "   Epoch 2/5, Loss: 1.2059\n",
      "   Epoch 3/5, Loss: 1.1266\n",
      "   Epoch 4/5, Loss: 1.0900\n",
      "   Epoch 5/5, Loss: 1.0625\n",
      "   Epoch 1/5, Loss: 1.3205\n",
      "   Epoch 2/5, Loss: 1.1573\n",
      "   Epoch 3/5, Loss: 1.1036\n",
      "   Epoch 4/5, Loss: 1.0661\n",
      "   Epoch 5/5, Loss: 1.0265\n",
      "   Epoch 1/5, Loss: 1.2999\n",
      "   Epoch 2/5, Loss: 1.1252\n",
      "   Epoch 3/5, Loss: 1.0719\n",
      "   Epoch 4/5, Loss: 1.0305\n",
      "   Epoch 5/5, Loss: 0.9930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 04:34:18,404] Trial 10 finished with value: 1.2031443238258361 and parameters: {'hidden_size': 252, 'num_layers': 2, 'dropout': 0.19853025829251952, 'lr': 0.0011769001212426527, 'time_step_in': 14, 'time_step_out': 2, 'stride': 1, 'num_lags': 3, 'lag_0': 1, 'lag_1': 4, 'lag_2': 1, 'num_windows': 2, 'window_0': 10, 'window_1': 23}. Best is trial 0 with value: 1.0021047711372375.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1/5, Loss: 3.6312\n",
      "   Epoch 2/5, Loss: 2.9530\n",
      "   Epoch 3/5, Loss: 2.3978\n",
      "   Epoch 4/5, Loss: 2.1536\n",
      "   Epoch 5/5, Loss: 1.9701\n",
      "   Epoch 1/5, Loss: 2.5966\n",
      "   Epoch 2/5, Loss: 1.7974\n",
      "   Epoch 3/5, Loss: 1.5045\n",
      "   Epoch 4/5, Loss: 1.3616\n",
      "   Epoch 5/5, Loss: 1.2804\n",
      "   Epoch 1/5, Loss: 2.3442\n",
      "   Epoch 2/5, Loss: 1.5626\n",
      "   Epoch 3/5, Loss: 1.3421\n",
      "   Epoch 4/5, Loss: 1.2523\n",
      "   Epoch 5/5, Loss: 1.2108\n",
      "   Epoch 1/5, Loss: 2.2375\n",
      "   Epoch 2/5, Loss: 1.4502\n",
      "   Epoch 3/5, Loss: 1.2928\n",
      "   Epoch 4/5, Loss: 1.2280\n",
      "   Epoch 5/5, Loss: 1.1861\n",
      "   Epoch 1/5, Loss: 2.1333\n",
      "   Epoch 2/5, Loss: 1.3798\n",
      "   Epoch 3/5, Loss: 1.2548\n",
      "   Epoch 4/5, Loss: 1.2016\n",
      "   Epoch 5/5, Loss: 1.1399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 04:35:43,670] Trial 11 finished with value: 1.0669320344924926 and parameters: {'hidden_size': 150, 'num_layers': 2, 'dropout': 0.14553829763948076, 'lr': 0.00010126824175478817, 'time_step_in': 46, 'time_step_out': 1, 'stride': 6, 'num_lags': 1, 'lag_0': 7, 'num_windows': 3, 'window_0': 10, 'window_1': 23, 'window_2': 3}. Best is trial 0 with value: 1.0021047711372375.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1/5, Loss: 1.5876\n",
      "   Epoch 2/5, Loss: 1.3744\n",
      "   Epoch 3/5, Loss: 1.3135\n",
      "   Epoch 4/5, Loss: 1.2562\n",
      "   Epoch 5/5, Loss: 1.2536\n",
      "   Epoch 1/5, Loss: 1.3339\n",
      "   Epoch 2/5, Loss: 1.1765\n",
      "   Epoch 3/5, Loss: 1.1194\n",
      "   Epoch 4/5, Loss: 1.0855\n",
      "   Epoch 5/5, Loss: 1.0592\n",
      "   Epoch 1/5, Loss: 1.2766\n",
      "   Epoch 2/5, Loss: 1.1482\n",
      "   Epoch 3/5, Loss: 1.1005\n",
      "   Epoch 4/5, Loss: 1.0722\n",
      "   Epoch 5/5, Loss: 1.0390\n",
      "   Epoch 1/5, Loss: 1.2815\n",
      "   Epoch 2/5, Loss: 1.1298\n",
      "   Epoch 3/5, Loss: 1.0756\n",
      "   Epoch 4/5, Loss: 1.0392\n",
      "   Epoch 5/5, Loss: 1.0093\n",
      "   Epoch 1/5, Loss: 1.2492\n",
      "   Epoch 2/5, Loss: 1.1057\n",
      "   Epoch 3/5, Loss: 1.0497\n",
      "   Epoch 4/5, Loss: 1.0121\n",
      "   Epoch 5/5, Loss: 0.9755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 04:40:53,990] Trial 12 finished with value: 1.1301091074943543 and parameters: {'hidden_size': 243, 'num_layers': 2, 'dropout': 0.3029376909011109, 'lr': 0.0020106868490555618, 'time_step_in': 38, 'time_step_out': 2, 'stride': 1, 'num_lags': 1, 'lag_0': 7, 'num_windows': 3, 'window_0': 16, 'window_1': 15, 'window_2': 8}. Best is trial 0 with value: 1.0021047711372375.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1/5, Loss: 2.1150\n",
      "   Epoch 2/5, Loss: 1.5936\n",
      "   Epoch 3/5, Loss: 1.4980\n",
      "   Epoch 4/5, Loss: 1.4139\n",
      "   Epoch 5/5, Loss: 1.3334\n",
      "   Epoch 1/5, Loss: 1.5276\n",
      "   Epoch 2/5, Loss: 1.2736\n",
      "   Epoch 3/5, Loss: 1.2056\n",
      "   Epoch 4/5, Loss: 1.1358\n",
      "   Epoch 5/5, Loss: 1.0846\n",
      "   Epoch 1/5, Loss: 1.4029\n",
      "   Epoch 2/5, Loss: 1.1940\n",
      "   Epoch 3/5, Loss: 1.0765\n",
      "   Epoch 4/5, Loss: 1.0354\n",
      "   Epoch 5/5, Loss: 1.0082\n",
      "   Epoch 1/5, Loss: 1.4347\n",
      "   Epoch 2/5, Loss: 1.1823\n",
      "   Epoch 3/5, Loss: 1.0946\n",
      "   Epoch 4/5, Loss: 1.0363\n",
      "   Epoch 5/5, Loss: 1.0522\n",
      "   Epoch 1/5, Loss: 1.3499\n",
      "   Epoch 2/5, Loss: 1.0933\n",
      "   Epoch 3/5, Loss: 1.0507\n",
      "   Epoch 4/5, Loss: 1.0293\n",
      "   Epoch 5/5, Loss: 1.0117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 04:41:51,493] Trial 13 finished with value: 1.1502674579620362 and parameters: {'hidden_size': 157, 'num_layers': 2, 'dropout': 0.12494707524696584, 'lr': 0.0025752547616558876, 'time_step_in': 26, 'time_step_out': 1, 'stride': 6, 'num_lags': 1, 'lag_0': 11, 'num_windows': 2, 'window_0': 10, 'window_1': 12}. Best is trial 0 with value: 1.0021047711372375.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1/5, Loss: 3.4905\n",
      "   Epoch 2/5, Loss: 2.9235\n",
      "   Epoch 3/5, Loss: 2.5302\n",
      "   Epoch 4/5, Loss: 2.3917\n",
      "   Epoch 5/5, Loss: 2.2986\n",
      "   Epoch 1/5, Loss: 2.6065\n",
      "   Epoch 2/5, Loss: 2.0715\n",
      "   Epoch 3/5, Loss: 1.8632\n",
      "   Epoch 4/5, Loss: 1.7215\n",
      "   Epoch 5/5, Loss: 1.6491\n",
      "   Epoch 1/5, Loss: 2.4317\n",
      "   Epoch 2/5, Loss: 1.8791\n",
      "   Epoch 3/5, Loss: 1.6820\n",
      "   Epoch 4/5, Loss: 1.5768\n",
      "   Epoch 5/5, Loss: 1.5068\n",
      "   Epoch 1/5, Loss: 2.3893\n",
      "   Epoch 2/5, Loss: 1.8691\n",
      "   Epoch 3/5, Loss: 1.6721\n",
      "   Epoch 4/5, Loss: 1.5734\n",
      "   Epoch 5/5, Loss: 1.5013\n",
      "   Epoch 1/5, Loss: 2.3548\n",
      "   Epoch 2/5, Loss: 1.7797\n",
      "   Epoch 3/5, Loss: 1.6098\n",
      "   Epoch 4/5, Loss: 1.5173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 04:42:51,934] Trial 14 finished with value: 1.2848883628845216 and parameters: {'hidden_size': 227, 'num_layers': 1, 'dropout': 0.26971022890265156, 'lr': 0.00010611950688890145, 'time_step_in': 48, 'time_step_out': 3, 'stride': 5, 'num_lags': 1, 'lag_0': 9, 'num_windows': 3, 'window_0': 18, 'window_1': 19, 'window_2': 13}. Best is trial 0 with value: 1.0021047711372375.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 5/5, Loss: 1.4409\n",
      "   Epoch 1/5, Loss: 1.7798\n",
      "   Epoch 2/5, Loss: 1.3340\n",
      "   Epoch 3/5, Loss: 1.2331\n",
      "   Epoch 4/5, Loss: 1.2512\n",
      "   Epoch 5/5, Loss: 1.2248\n",
      "   Epoch 1/5, Loss: 1.2879\n",
      "   Epoch 2/5, Loss: 1.1231\n",
      "   Epoch 3/5, Loss: 1.0948\n",
      "   Epoch 4/5, Loss: 1.0636\n",
      "   Epoch 5/5, Loss: 1.0850\n",
      "   Epoch 1/5, Loss: 1.3084\n",
      "   Epoch 2/5, Loss: 1.1147\n",
      "   Epoch 3/5, Loss: 1.0732\n",
      "   Epoch 4/5, Loss: 1.0569\n",
      "   Epoch 5/5, Loss: 1.0673\n",
      "   Epoch 1/5, Loss: 1.2228\n",
      "   Epoch 2/5, Loss: 1.0791\n",
      "   Epoch 3/5, Loss: 1.0606\n",
      "   Epoch 4/5, Loss: 1.0397\n",
      "   Epoch 5/5, Loss: 1.0250\n",
      "   Epoch 1/5, Loss: 1.2028\n",
      "   Epoch 2/5, Loss: 1.1001\n",
      "   Epoch 3/5, Loss: 1.0759\n",
      "   Epoch 4/5, Loss: 1.0602\n",
      "   Epoch 5/5, Loss: 1.0332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 04:46:46,047] Trial 15 finished with value: 1.0821003437042236 and parameters: {'hidden_size': 171, 'num_layers': 2, 'dropout': 0.12259107467629095, 'lr': 0.009777679892888505, 'time_step_in': 40, 'time_step_out': 1, 'stride': 2, 'num_lags': 2, 'lag_0': 6, 'lag_1': 3, 'num_windows': 2, 'window_0': 12, 'window_1': 7}. Best is trial 0 with value: 1.0021047711372375.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1/5, Loss: 2.5623\n",
      "   Epoch 2/5, Loss: 1.8353\n",
      "   Epoch 3/5, Loss: 1.6239\n",
      "   Epoch 4/5, Loss: 1.5397\n",
      "   Epoch 5/5, Loss: 1.4722\n",
      "   Epoch 1/5, Loss: 1.8470\n",
      "   Epoch 2/5, Loss: 1.3482\n",
      "   Epoch 3/5, Loss: 1.2515\n",
      "   Epoch 4/5, Loss: 1.1956\n",
      "   Epoch 5/5, Loss: 1.1699\n",
      "   Epoch 1/5, Loss: 1.6859\n",
      "   Epoch 2/5, Loss: 1.2777\n",
      "   Epoch 3/5, Loss: 1.1986\n",
      "   Epoch 4/5, Loss: 1.1670\n",
      "   Epoch 5/5, Loss: 1.1172\n",
      "   Epoch 1/5, Loss: 1.6373\n",
      "   Epoch 2/5, Loss: 1.2412\n",
      "   Epoch 3/5, Loss: 1.1695\n",
      "   Epoch 4/5, Loss: 1.1287\n",
      "   Epoch 5/5, Loss: 1.1131\n",
      "   Epoch 1/5, Loss: 1.5627\n",
      "   Epoch 2/5, Loss: 1.2069\n",
      "   Epoch 3/5, Loss: 1.1425\n",
      "   Epoch 4/5, Loss: 1.1113\n",
      "   Epoch 5/5, Loss: 1.0823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 04:48:14,697] Trial 16 finished with value: 1.1586897015571593 and parameters: {'hidden_size': 131, 'num_layers': 2, 'dropout': 0.2018956872002267, 'lr': 0.0006097246635313868, 'time_step_in': 33, 'time_step_out': 2, 'stride': 4, 'num_lags': 1, 'lag_0': 12, 'num_windows': 2, 'window_0': 7, 'window_1': 20}. Best is trial 0 with value: 1.0021047711372375.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1/5, Loss: 2.1298\n",
      "   Epoch 2/5, Loss: 1.7605\n",
      "   Epoch 3/5, Loss: 1.6346\n",
      "   Epoch 4/5, Loss: 1.5339\n",
      "   Epoch 5/5, Loss: 1.5427\n",
      "   Epoch 1/5, Loss: 1.7663\n",
      "   Epoch 2/5, Loss: 1.4551\n",
      "   Epoch 3/5, Loss: 1.4145\n",
      "   Epoch 4/5, Loss: 1.3622\n",
      "   Epoch 5/5, Loss: 1.3381\n",
      "   Epoch 1/5, Loss: 1.6362\n",
      "   Epoch 2/5, Loss: 1.4330\n",
      "   Epoch 3/5, Loss: 1.3641\n",
      "   Epoch 4/5, Loss: 1.3264\n",
      "   Epoch 5/5, Loss: 1.3069\n",
      "   Epoch 1/5, Loss: 1.6700\n",
      "   Epoch 2/5, Loss: 1.4147\n",
      "   Epoch 3/5, Loss: 1.3399\n",
      "   Epoch 4/5, Loss: 1.3117\n",
      "   Epoch 5/5, Loss: 1.2729\n",
      "   Epoch 1/5, Loss: 1.6188\n",
      "   Epoch 2/5, Loss: 1.3610\n",
      "   Epoch 3/5, Loss: 1.2986\n",
      "   Epoch 4/5, Loss: 1.2683\n",
      "   Epoch 5/5, Loss: 1.2468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 04:50:03,713] Trial 17 finished with value: 1.2945745229721068 and parameters: {'hidden_size': 220, 'num_layers': 3, 'dropout': 0.3755317700904188, 'lr': 0.0027649683989845655, 'time_step_in': 27, 'time_step_out': 3, 'stride': 3, 'num_lags': 3, 'lag_0': 8, 'lag_1': 8, 'lag_2': 3, 'num_windows': 3, 'window_0': 19, 'window_1': 12, 'window_2': 14}. Best is trial 0 with value: 1.0021047711372375.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 1/5, Loss: 2.9530\n",
      "   Epoch 2/5, Loss: 2.2015\n",
      "   Epoch 3/5, Loss: 1.9519\n",
      "   Epoch 4/5, Loss: 1.8157\n",
      "   Epoch 5/5, Loss: 1.7569\n",
      "   Epoch 1/5, Loss: 2.2854\n",
      "   Epoch 2/5, Loss: 1.6468\n",
      "   Epoch 3/5, Loss: 1.4717\n",
      "   Epoch 4/5, Loss: 1.4051\n",
      "   Epoch 5/5, Loss: 1.3835\n",
      "   Epoch 1/5, Loss: 2.0538\n",
      "   Epoch 2/5, Loss: 1.5334\n",
      "   Epoch 3/5, Loss: 1.4433\n",
      "   Epoch 4/5, Loss: 1.4004\n",
      "   Epoch 5/5, Loss: 1.3767\n",
      "   Epoch 1/5, Loss: 1.9882\n",
      "   Epoch 2/5, Loss: 1.4430\n",
      "   Epoch 3/5, Loss: 1.3708\n",
      "   Epoch 4/5, Loss: 1.3391\n",
      "   Epoch 5/5, Loss: 1.3068\n",
      "   Epoch 1/5, Loss: 1.8931\n",
      "   Epoch 2/5, Loss: 1.4611\n",
      "   Epoch 3/5, Loss: 1.4049\n",
      "   Epoch 4/5, Loss: 1.3580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 04:50:49,249] Trial 18 finished with value: 1.2259411096572876 and parameters: {'hidden_size': 195, 'num_layers': 1, 'dropout': 0.07307578138697404, 'lr': 0.00016603306916094203, 'time_step_in': 42, 'time_step_out': 1, 'stride': 5, 'num_lags': 1, 'lag_0': 2, 'num_windows': 1, 'window_0': 14}. Best is trial 0 with value: 1.0021047711372375.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 5/5, Loss: 1.3047\n",
      "   Epoch 1/5, Loss: 2.3160\n",
      "   Epoch 2/5, Loss: 1.5738\n",
      "   Epoch 3/5, Loss: 1.4592\n",
      "   Epoch 4/5, Loss: 1.4538\n",
      "   Epoch 5/5, Loss: 1.4303\n",
      "   Epoch 1/5, Loss: 1.8362\n",
      "   Epoch 2/5, Loss: 1.2737\n",
      "   Epoch 3/5, Loss: 1.2168\n",
      "   Epoch 4/5, Loss: 1.2048\n",
      "   Epoch 5/5, Loss: 1.1974\n",
      "   Epoch 1/5, Loss: 1.4001\n",
      "   Epoch 2/5, Loss: 1.2439\n",
      "   Epoch 3/5, Loss: 1.1767\n",
      "   Epoch 4/5, Loss: 1.1743\n",
      "   Epoch 5/5, Loss: 1.1479\n",
      "   Epoch 1/5, Loss: 1.4081\n",
      "   Epoch 2/5, Loss: 1.2205\n",
      "   Epoch 3/5, Loss: 1.1977\n",
      "   Epoch 4/5, Loss: 1.1682\n",
      "   Epoch 5/5, Loss: 1.1519\n",
      "   Epoch 1/5, Loss: 1.3565\n",
      "   Epoch 2/5, Loss: 1.2221\n",
      "   Epoch 3/5, Loss: 1.1687\n",
      "   Epoch 4/5, Loss: 1.1472\n",
      "   Epoch 5/5, Loss: 1.1155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-07 04:55:33,808] Trial 19 finished with value: 1.233364462852478 and parameters: {'hidden_size': 239, 'num_layers': 2, 'dropout': 0.1702338301459344, 'lr': 0.009966592825219731, 'time_step_in': 35, 'time_step_out': 2, 'stride': 1, 'num_lags': 2, 'lag_0': 6, 'lag_1': 8, 'num_windows': 2, 'window_0': 12, 'window_1': 14}. Best is trial 0 with value: 1.0021047711372375.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Best parameters for 2020-10:\n",
      "  hidden_size: 188\n",
      "  num_layers: 2\n",
      "  dropout: 0.1990680107401797\n",
      "  lr: 0.000127233756628581\n",
      "  time_step_in: 47\n",
      "  time_step_out: 1\n",
      "  stride: 1\n",
      "  num_lags: 2\n",
      "  lag_0: 9\n",
      "  lag_1: 3\n",
      "  num_windows: 2\n",
      "  window_0: 12\n",
      "  window_1: 21\n",
      " Best parameters saved to best_params_2020-10.json\n",
      "\n",
      " Final evaluation on 2020-10, fold_1 test set\n",
      "\n",
      "====== Training model for 2020-10, fold_1 with best parameters\n",
      "====== Training model on train set...\n",
      "   Epoch 1/15, Loss: 2.4192\n",
      "   Epoch 2/15, Loss: 1.8416\n",
      "   Epoch 3/15, Loss: 1.6727\n",
      "   Epoch 4/15, Loss: 1.5761\n",
      "   Epoch 5/15, Loss: 1.4827\n",
      "   Epoch 6/15, Loss: 1.4129\n",
      "   Epoch 7/15, Loss: 1.3334\n",
      "   Epoch 8/15, Loss: 1.2935\n",
      "   Epoch 9/15, Loss: 1.2597\n",
      "   Epoch 10/15, Loss: 1.2072\n",
      "   Epoch 11/15, Loss: 1.1953\n",
      "   Epoch 12/15, Loss: 1.1568\n",
      "   Epoch 13/15, Loss: 1.1304\n",
      "   Epoch 14/15, Loss: 1.1076\n",
      "   Epoch 15/15, Loss: 1.0877\n",
      "====== Evaluating on validation set...\n",
      "  Val RMSE: 0.9009, Bias: -0.0838, R²: 0.6362, CSI: 0.6032\n",
      "====== Evaluating on test set...\n",
      "  Test RMSE: 1.2032, Bias: -0.0884, R²: 0.6789, CSI: 0.6829\n",
      " Model saved to model_2020-10_fold_1.pt\n",
      "\n",
      " Final evaluation on 2020-10, fold_2 test set\n",
      "\n",
      "====== Training model for 2020-10, fold_2 with best parameters\n",
      "====== Training model on train set...\n",
      "   Epoch 1/15, Loss: 1.7493\n",
      "   Epoch 2/15, Loss: 1.3776\n",
      "   Epoch 3/15, Loss: 1.2362\n",
      "   Epoch 4/15, Loss: 1.1380\n",
      "   Epoch 5/15, Loss: 1.0795\n",
      "   Epoch 6/15, Loss: 1.0388\n",
      "   Epoch 7/15, Loss: 1.0041\n",
      "   Epoch 8/15, Loss: 1.0016\n",
      "   Epoch 9/15, Loss: 0.9752\n",
      "   Epoch 10/15, Loss: 0.9528\n",
      "   Epoch 11/15, Loss: 0.9461\n",
      "   Epoch 12/15, Loss: 0.9356\n",
      "   Epoch 13/15, Loss: 0.9303\n",
      "   Epoch 14/15, Loss: 0.9122\n",
      "   Epoch 15/15, Loss: 0.9097\n",
      "====== Evaluating on validation set...\n",
      "  Val RMSE: 1.0573, Bias: 0.0278, R²: 0.6812, CSI: 0.5875\n",
      "====== Evaluating on test set...\n",
      "  Test RMSE: 0.9781, Bias: -0.0149, R²: 0.7067, CSI: 0.6332\n",
      " Model saved to model_2020-10_fold_2.pt\n",
      "\n",
      " Final evaluation on 2020-10, fold_3 test set\n",
      "\n",
      "====== Training model for 2020-10, fold_3 with best parameters\n",
      "====== Training model on train set...\n",
      "   Epoch 1/15, Loss: 1.6188\n",
      "   Epoch 2/15, Loss: 1.2281\n",
      "   Epoch 3/15, Loss: 1.0897\n",
      "   Epoch 4/15, Loss: 1.0373\n",
      "   Epoch 5/15, Loss: 1.0015\n",
      "   Epoch 6/15, Loss: 0.9804\n",
      "   Epoch 7/15, Loss: 0.9560\n",
      "   Epoch 8/15, Loss: 0.9435\n",
      "   Epoch 9/15, Loss: 0.9378\n",
      "   Epoch 10/15, Loss: 0.9252\n",
      "   Epoch 11/15, Loss: 0.9131\n",
      "   Epoch 12/15, Loss: 0.9065\n",
      "   Epoch 13/15, Loss: 0.9004\n",
      "   Epoch 14/15, Loss: 0.8998\n",
      "   Epoch 15/15, Loss: 0.8868\n",
      "====== Evaluating on validation set...\n",
      "  Val RMSE: 1.2025, Bias: 0.0168, R²: 0.6820, CSI: 0.6720\n",
      "====== Evaluating on test set...\n",
      "  Test RMSE: 0.6792, Bias: -0.0196, R²: 0.6608, CSI: 0.6260\n",
      " Model saved to model_2020-10_fold_3.pt\n",
      "\n",
      " Final evaluation on 2020-10, fold_4 test set\n",
      "\n",
      "====== Training model for 2020-10, fold_4 with best parameters\n",
      "====== Training model on train set...\n",
      "   Epoch 1/15, Loss: 1.5915\n",
      "   Epoch 2/15, Loss: 1.1805\n",
      "   Epoch 3/15, Loss: 1.0642\n",
      "   Epoch 4/15, Loss: 1.0093\n",
      "   Epoch 5/15, Loss: 0.9710\n",
      "   Epoch 6/15, Loss: 0.9519\n",
      "   Epoch 7/15, Loss: 0.9383\n",
      "   Epoch 8/15, Loss: 0.9243\n",
      "   Epoch 9/15, Loss: 0.9127\n",
      "   Epoch 10/15, Loss: 0.9022\n",
      "   Epoch 11/15, Loss: 0.8907\n",
      "   Epoch 12/15, Loss: 0.8876\n",
      "   Epoch 13/15, Loss: 0.8829\n",
      "   Epoch 14/15, Loss: 0.8742\n",
      "   Epoch 15/15, Loss: 0.8649\n",
      "====== Evaluating on validation set...\n",
      "  Val RMSE: 0.9756, Bias: -0.0634, R²: 0.7046, CSI: 0.6120\n",
      "====== Evaluating on test set...\n",
      "  Test RMSE: 0.5643, Bias: -0.0112, R²: 0.5891, CSI: 0.5704\n",
      " Model saved to model_2020-10_fold_4.pt\n",
      "\n",
      " Final evaluation on 2020-10, fold_5 test set\n",
      "\n",
      "====== Training model for 2020-10, fold_5 with best parameters\n",
      "====== Training model on train set...\n",
      "   Epoch 1/15, Loss: 1.5293\n",
      "   Epoch 2/15, Loss: 1.1029\n",
      "   Epoch 3/15, Loss: 1.0204\n",
      "   Epoch 4/15, Loss: 0.9692\n",
      "   Epoch 5/15, Loss: 0.9468\n",
      "   Epoch 6/15, Loss: 0.9341\n",
      "   Epoch 7/15, Loss: 0.9182\n",
      "   Epoch 8/15, Loss: 0.9117\n",
      "   Epoch 9/15, Loss: 0.8999\n",
      "   Epoch 10/15, Loss: 0.8889\n",
      "   Epoch 11/15, Loss: 0.8805\n",
      "   Epoch 12/15, Loss: 0.8724\n",
      "   Epoch 13/15, Loss: 0.8639\n",
      "   Epoch 14/15, Loss: 0.8583\n",
      "   Epoch 15/15, Loss: 0.8492\n",
      "====== Evaluating on validation set...\n",
      "  Val RMSE: 0.7899, Bias: -0.0487, R²: 0.6651, CSI: 0.5959\n",
      "====== Evaluating on test set...\n",
      "  Test RMSE: 0.4721, Bias: 0.0076, R²: 0.5364, CSI: 0.5760\n",
      " Model saved to model_2020-10_fold_5.pt\n",
      "\n",
      " Mean test performance for 2020-10:\n",
      "  RMSE: 0.7794, Bias: -0.0253, R²: 0.6344, CSI: 0.6177\n",
      " Best fold test performance for 2020-10 (fold fold_5):\n",
      "  RMSE: 0.4721, Bias: 0.0076, R²: 0.5364, CSI: 0.5760\n",
      " Best model for 2020-10 saved to best_model_2020-10.pt\n",
      "\n",
      " Overall mean performance across all months:\n",
      "  RMSE: 0.5948, Bias: -0.0211, R²: 0.3403, CSI: 0.3711\n",
      "\n",
      " Results by Month:\n",
      "     month best_fold  best_test_rmse  best_test_bias  best_test_r  \\\n",
      "0  2019-04    fold_5          1.2381         -0.1335      -0.0011   \n",
      "1  2019-10    fold_1          0.3831          0.0153       0.7523   \n",
      "2  2020-04    fold_4          0.2858          0.0262       0.0736   \n",
      "3  2020-10    fold_5          0.4721          0.0076       0.5364   \n",
      "\n",
      "   best_test_csi  mean_test_rmse  mean_test_bias  mean_test_r  mean_test_csi  \n",
      "0         0.0965          1.2526         -0.1408      -0.0249         0.0931  \n",
      "1         0.6471          0.5634         -0.0350       0.6897         0.7340  \n",
      "2         0.1650          0.2923          0.0324       0.0297         0.1508  \n",
      "3         0.5760          0.7794         -0.0253       0.6344         0.6177  \n",
      " Results saved to lstm_month_results.csv and lstm_all_fold_results.csv\n"
     ]
    }
   ],
   "source": [
    "# Execute optimization\n",
    "if __name__ == \"__main__\":\n",
    "    run_optuna_optimization()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7085647,
     "sourceId": 11327529,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7091976,
     "sourceId": 11340032,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7117290,
     "sourceId": 11369580,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6984394,
     "isSourceIdPinned": true,
     "sourceId": 11378857,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7173004,
     "sourceId": 11448922,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 11586.703928,
   "end_time": "2025-05-07T05:18:04.155882",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-07T02:04:57.451954",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
