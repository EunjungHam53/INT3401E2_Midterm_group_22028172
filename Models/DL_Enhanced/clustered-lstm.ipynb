{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "886cae42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T17:16:43.447245Z",
     "iopub.status.busy": "2025-05-06T17:16:43.446892Z",
     "iopub.status.idle": "2025-05-06T17:16:49.278973Z",
     "shell.execute_reply": "2025-05-06T17:16:49.277850Z"
    },
    "papermill": {
     "duration": 5.838132,
     "end_time": "2025-05-06T17:16:49.280789",
     "exception": false,
     "start_time": "2025-05-06T17:16:43.442657",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import json\n",
    "import optuna\n",
    "from functools import partial\n",
    "from joblib import Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39fd6b83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T17:16:49.287170Z",
     "iopub.status.busy": "2025-05-06T17:16:49.286785Z",
     "iopub.status.idle": "2025-05-06T17:16:49.291803Z",
     "shell.execute_reply": "2025-05-06T17:16:49.290875Z"
    },
    "papermill": {
     "duration": 0.009244,
     "end_time": "2025-05-06T17:16:49.293042",
     "exception": false,
     "start_time": "2025-05-06T17:16:49.283798",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_clustering_info():\n",
    "    \"\"\"Load clustering information from CSV file\"\"\"\n",
    "    cluster_file = \"/kaggle/input/ai-data4clustering-dict/fuzzy_clusters.csv\"\n",
    "    try:\n",
    "        clusters_df = pd.read_csv(cluster_file)\n",
    "        print(f\" Loaded clustering info: {clusters_df.shape[0]} rows\")\n",
    "        # Check if required columns exist\n",
    "        required_cols = ['ROW', 'COL', 'CLUSTER']\n",
    "        if not all(col in clusters_df.columns for col in required_cols):\n",
    "            print(f\"[ERRORS] Clustering file missing required columns: {required_cols}\")\n",
    "            return None\n",
    "        return clusters_df\n",
    "    except Exception as e:\n",
    "        print(f\"[ERRORS] Error loading clustering file: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e480e5c",
   "metadata": {
    "_cell_guid": "0d428d71-24a7-41ca-b8ef-91a62c6351bb",
    "_uuid": "777f311e-aaab-4cbf-8427-94523806e0a8",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-05-06T17:16:49.298897Z",
     "iopub.status.busy": "2025-05-06T17:16:49.298623Z",
     "iopub.status.idle": "2025-05-06T17:16:49.391296Z",
     "shell.execute_reply": "2025-05-06T17:16:49.390595Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.097627,
     "end_time": "2025-05-06T17:16:49.392945",
     "exception": false,
     "start_time": "2025-05-06T17:16:49.295318",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Setup memory cache\n",
    "cache_dir = './joblib_cache'\n",
    "memory = Memory(cache_dir, verbose=0)\n",
    "\n",
    "class Config:\n",
    "    TARGET = 'AWS'\n",
    "    USE_LAG_FEATURES = True\n",
    "    USE_ROLLING_STATISTICS = True\n",
    "\n",
    "# Paths\n",
    "base_path = \"/kaggle/input/ai-dataimputedataset-k-fold\"\n",
    "months = [\"2019-04\", \"2019-10\", \"2020-04\", \"2020-10\"]\n",
    "folds = [f\"fold_{i}\" for i in range(1, 6)]\n",
    "\n",
    "# Define selected features\n",
    "selected_features = [\n",
    "    'TCW', 'TCLW', 'R250', 'R500', 'R850', 'U850', 'V850', 'EWSS', 'KX', 'CAPE', 'SSHF', 'PEV'\n",
    "]\n",
    "\n",
    "# Device configuration\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Model parameters - now configurable via Optuna\n",
    "MODEL_CONFIG = {\n",
    "    \"04\": {\"BATCH_SIZE\": 64, \"EPOCHS\": 10},\n",
    "    \"10\": {\"BATCH_SIZE\": 128, \"EPOCHS\": 15},\n",
    "}\n",
    "\n",
    "# Create lag features\n",
    "@memory.cache\n",
    "def create_lag_features(train_df, test_df, target_column, lag_steps, groupby_cols):\n",
    "    \"\"\"Create lag features for the target column\"\"\"\n",
    "    result_df = test_df.copy()\n",
    "    \n",
    "    # Combine train and test for continuous time series\n",
    "    combined_df = pd.concat([train_df, test_df]).sort_values('DATETIME').reset_index(drop=True)\n",
    "    \n",
    "    # Create lag features\n",
    "    for lag in lag_steps:\n",
    "        combined_df[f'{target_column}_lag{lag}'] = combined_df.groupby(groupby_cols)[target_column].shift(lag)\n",
    "    \n",
    "    # Extract only the test portion with lag features\n",
    "    result_df = combined_df.iloc[len(train_df):].reset_index(drop=True)\n",
    "    return result_df\n",
    "\n",
    "# Create rolling statistics\n",
    "@memory.cache\n",
    "def create_rolling_statistics(train_df, test_df, target_column, window_sizes, groupby_cols):\n",
    "    \"\"\"Create rolling statistics features for the target column\"\"\"\n",
    "    result_df = test_df.copy()\n",
    "    \n",
    "    # Combine train and test for continuous rolling stats\n",
    "    combined_df = pd.concat([train_df, test_df]).sort_values('DATETIME').reset_index(drop=True)\n",
    "    \n",
    "    # Create rolling features\n",
    "    for window in window_sizes:\n",
    "        # Rolling mean\n",
    "        combined_df[f'{target_column}_rollmean_{window}'] = combined_df.groupby(groupby_cols)[target_column].transform(\n",
    "            lambda x: x.rolling(window, min_periods=1).mean())\n",
    "        # Rolling std\n",
    "        combined_df[f'{target_column}_rollstd_{window}'] = combined_df.groupby(groupby_cols)[target_column].transform(\n",
    "            lambda x: x.rolling(window, min_periods=1).std())\n",
    "    \n",
    "    # Extract only the test portion with rolling features\n",
    "    result_df = combined_df.iloc[len(train_df):].reset_index(drop=True)\n",
    "    return result_df\n",
    "\n",
    "# Handle missing values\n",
    "@memory.cache\n",
    "def handle_missing_values(df, lag_steps, window_sizes):\n",
    "    \"\"\"Handle missing values in the dataframe\"\"\"\n",
    "    result_df = df.copy()\n",
    "    \n",
    "    # Fill NaN values in lag features with 0\n",
    "    for lag in lag_steps:\n",
    "        lag_col = f'{Config.TARGET}_lag{lag}'\n",
    "        if lag_col in result_df.columns:\n",
    "            result_df[lag_col] = result_df[lag_col].fillna(0)\n",
    "    \n",
    "    # Fill NaN values in rolling features with 0\n",
    "    for window in window_sizes:\n",
    "        mean_col = f'{Config.TARGET}_rollmean_{window}'\n",
    "        std_col = f'{Config.TARGET}_rollstd_{window}'\n",
    "        \n",
    "        if mean_col in result_df.columns:\n",
    "            result_df[mean_col] = result_df[mean_col].fillna(0)\n",
    "        \n",
    "        if std_col in result_df.columns:\n",
    "            result_df[std_col] = result_df[std_col].fillna(0)\n",
    "    \n",
    "    # Fill remaining NaNs with 0\n",
    "    result_df = result_df.fillna(0)\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "\n",
    "\n",
    "# Modified load_and_process_data function to filter features\n",
    "@memory.cache\n",
    "@memory.cache\n",
    "def load_and_process_data(file_path, train_file_path=None, lag_steps=None, window_sizes=None, cluster_df=None, cluster_id=None):\n",
    "    \"\"\"\n",
    "    Load and process data from file_path with optional lag features and rolling statistics\n",
    "    If train_file_path is provided, use it for creating lag and rolling features\n",
    "    If cluster_df and cluster_id are provided, filter data by cluster\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        raw_df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Filter by cluster if specified\n",
    "        if cluster_df is not None and cluster_id is not None:\n",
    "            # Get ROW, COL pairs in this cluster\n",
    "            cluster_points = cluster_df[cluster_df['CLUSTER'] == cluster_id][['ROW', 'COL']].values.tolist()\n",
    "            \n",
    "            # Filter raw_df to keep only points in this cluster\n",
    "            raw_df = raw_df[raw_df.apply(lambda row: [row['ROW'], row['COL']] in cluster_points, axis=1)]\n",
    "            \n",
    "            if raw_df.empty:\n",
    "                print(f\" No data points found for cluster {cluster_id}\")\n",
    "                return pd.DataFrame()\n",
    "        \n",
    "        # Filter to keep only selected features plus essential columns\n",
    "        essential_cols = ['DATETIME', 'ROW', 'COL', Config.TARGET]\n",
    "        feature_cols = [col for col in selected_features if col in raw_df.columns]\n",
    "        filtered_cols = essential_cols + feature_cols\n",
    "        \n",
    "        # Keep only needed columns\n",
    "        raw_df = raw_df[filtered_cols]\n",
    "        \n",
    "        # Convert target to numeric and handle NaN/inf values\n",
    "        raw_df[Config.TARGET] = pd.to_numeric(raw_df[Config.TARGET], errors='coerce')\n",
    "        raw_df = raw_df.replace([np.inf, -np.inf], np.nan)\n",
    "        df = raw_df.dropna(subset=[Config.TARGET]).copy()\n",
    "        \n",
    "        # Sort by datetime for proper sequence handling\n",
    "        if 'DATETIME' in df.columns:\n",
    "            df = df.sort_values(\"DATETIME\").reset_index(drop=True)\n",
    "        \n",
    "        # If we're in train mode or not creating lag/rolling features\n",
    "        if train_file_path is None or (lag_steps is None and window_sizes is None):\n",
    "            return df\n",
    "        \n",
    "        # Otherwise, we're in eval mode and need to carefully create features\n",
    "        train_df = pd.read_csv(train_file_path)\n",
    "        \n",
    "        # Filter training data by cluster if specified\n",
    "        if cluster_df is not None and cluster_id is not None:\n",
    "            cluster_points = cluster_df[cluster_df['CLUSTER'] == cluster_id][['ROW', 'COL']].values.tolist()\n",
    "            train_df = train_df[train_df.apply(lambda row: [row['ROW'], row['COL']] in cluster_points, axis=1)]\n",
    "            \n",
    "            if train_df.empty:\n",
    "                print(f\" No training data points found for cluster {cluster_id}\")\n",
    "                return pd.DataFrame()\n",
    "        \n",
    "        # Filter training data to keep only selected features\n",
    "        train_df = train_df[filtered_cols]\n",
    "        \n",
    "        train_df[Config.TARGET] = pd.to_numeric(train_df[Config.TARGET], errors='coerce')\n",
    "        train_df = train_df.replace([np.inf, -np.inf], np.nan)\n",
    "        train_df = train_df.dropna(subset=[Config.TARGET]).copy()\n",
    "        \n",
    "        if 'DATETIME' in train_df.columns:\n",
    "            train_df = train_df.sort_values(\"DATETIME\").reset_index(drop=True)\n",
    "        \n",
    "        # Create lag features if needed\n",
    "        if Config.USE_LAG_FEATURES and lag_steps:\n",
    "            df = create_lag_features(train_df, df, Config.TARGET, lag_steps, ['ROW', 'COL'])\n",
    "        \n",
    "        # Create rolling statistics if needed\n",
    "        if Config.USE_ROLLING_STATISTICS and window_sizes:\n",
    "            df = create_rolling_statistics(train_df, df, Config.TARGET, window_sizes, ['ROW', 'COL'])\n",
    "        \n",
    "        # Handle missing values\n",
    "        if lag_steps or window_sizes:\n",
    "            df = handle_missing_values(df, lag_steps or [], window_sizes or [])\n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"[ERRORS] Error loading or processing data: {str(e)}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Enhanced LSTM Model\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=64, num_layers=2, dropout=0.0, time_step_out=1):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_size, time_step_out)\n",
    "        self.time_step_out = time_step_out\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        return self.fc(out[:, -1, :])\n",
    "\n",
    "# Create sequences with configurable input and output time steps\n",
    "def create_sequences(df, input_cols, target_col, time_step_in, time_step_out=1, stride=1):\n",
    "    \"\"\"\n",
    "    Create sequences from dataframe with configurable input and output time steps\n",
    "    - time_step_in: number of time steps for input\n",
    "    - time_step_out: number of future steps to predict\n",
    "    - stride: step size for sliding window\n",
    "    \"\"\"\n",
    "    sequences, targets = [], []\n",
    "    grouped = df.groupby(['ROW', 'COL'])\n",
    "    \n",
    "    for _, group in grouped:\n",
    "        # Make sure group is sorted by time\n",
    "        if 'DATETIME' in group.columns:\n",
    "            group = group.sort_values(\"DATETIME\")\n",
    "            \n",
    "        data = group[input_cols].values\n",
    "        target_data = group[target_col].values\n",
    "        \n",
    "        if len(data) < time_step_in + time_step_out:\n",
    "            continue\n",
    "        \n",
    "        for i in range(0, len(data) - time_step_in - time_step_out + 1, stride):\n",
    "            seq = data[i:i+time_step_in]\n",
    "            if time_step_out == 1:\n",
    "                target = target_data[i+time_step_in]\n",
    "                targets.append(target)\n",
    "            else:\n",
    "                target = target_data[i+time_step_in:i+time_step_in+time_step_out]\n",
    "                targets.append(target)\n",
    "            sequences.append(seq)\n",
    "            \n",
    "    if not sequences:\n",
    "        return torch.tensor([]), torch.tensor([])\n",
    "    \n",
    "    if time_step_out == 1:\n",
    "        return torch.tensor(sequences, dtype=torch.float32), torch.tensor(targets, dtype=torch.float32).unsqueeze(1)\n",
    "    else:\n",
    "        return torch.tensor(sequences, dtype=torch.float32), torch.tensor(targets, dtype=torch.float32)\n",
    "\n",
    "# Prepare data loaders\n",
    "# Modified prepare_data_loaders function\n",
    "def prepare_data_loaders(month, fold, lag_steps, window_sizes, time_step_in, time_step_out, batch_size, stride=1, cluster_df=None, cluster_id=None):\n",
    "    \"\"\"Prepare data loaders with specific time steps and features for a specific cluster\"\"\"\n",
    "    folder = os.path.join(base_path, month, fold)\n",
    "    \n",
    "    # Load train data\n",
    "    train_df = load_and_process_data(\n",
    "        os.path.join(folder, \"processed_train.csv\"), \n",
    "        cluster_df=cluster_df, \n",
    "        cluster_id=cluster_id\n",
    "    )\n",
    "    \n",
    "    # Load validation data\n",
    "    val_df = load_and_process_data(\n",
    "        os.path.join(folder, \"processed_val.csv\"), \n",
    "        cluster_df=cluster_df, \n",
    "        cluster_id=cluster_id\n",
    "    )\n",
    "    \n",
    "    # Load test data\n",
    "    test_df = load_and_process_data(\n",
    "        os.path.join(folder, \"merged_test.csv\"), \n",
    "        cluster_df=cluster_df, \n",
    "        cluster_id=cluster_id\n",
    "    )\n",
    "    \n",
    "    if train_df.empty or val_df.empty or test_df.empty:\n",
    "        print(f\" One or more datasets are empty for cluster {cluster_id}\")\n",
    "        return None, None, None, 0\n",
    "    \n",
    "    # Rest of the function remains the same as your original code...\n",
    "    # Sort data by time\n",
    "    if 'DATETIME' in train_df.columns:\n",
    "        train_df = train_df.sort_values(\"DATETIME\").reset_index(drop=True)\n",
    "    if 'DATETIME' in val_df.columns:\n",
    "        val_df = val_df.sort_values(\"DATETIME\").reset_index(drop=True)\n",
    "    if 'DATETIME' in test_df.columns:\n",
    "        test_df = test_df.sort_values(\"DATETIME\").reset_index(drop=True)\n",
    "    \n",
    "    # Create features before further processing\n",
    "    # 1. Create lag features separately for each dataset\n",
    "    if Config.USE_LAG_FEATURES and lag_steps:\n",
    "        # Create lag features for train set using itself\n",
    "        for lag in lag_steps:\n",
    "            train_df[f'{Config.TARGET}_lag{lag}'] = train_df.groupby(['ROW', 'COL'])[Config.TARGET].shift(lag)\n",
    "        \n",
    "        # Create lag features for validation set using train + val\n",
    "        train_val_df = pd.concat([train_df, val_df]).sort_values('DATETIME').reset_index(drop=True)\n",
    "        for lag in lag_steps:\n",
    "            train_val_df[f'{Config.TARGET}_lag{lag}'] = train_val_df.groupby(['ROW', 'COL'])[Config.TARGET].shift(lag)\n",
    "        val_df = train_val_df.iloc[len(train_df):].reset_index(drop=True)\n",
    "        \n",
    "        # Create lag features for test set using train + val + test\n",
    "        full_df = pd.concat([train_df, val_df, test_df]).sort_values('DATETIME').reset_index(drop=True)\n",
    "        for lag in lag_steps:\n",
    "            full_df[f'{Config.TARGET}_lag{lag}'] = full_df.groupby(['ROW', 'COL'])[Config.TARGET].shift(lag)\n",
    "        test_df = full_df.iloc[len(train_df) + len(val_df):].reset_index(drop=True)\n",
    "    \n",
    "    # 2. Create rolling statistics separately for each dataset\n",
    "    if Config.USE_ROLLING_STATISTICS and window_sizes:\n",
    "        # Create rolling stats for train set\n",
    "        for window in window_sizes:\n",
    "            train_df[f'{Config.TARGET}_rollmean_{window}'] = train_df.groupby(['ROW', 'COL'])[Config.TARGET].transform(\n",
    "                lambda x: x.rolling(window, min_periods=1).mean())\n",
    "            train_df[f'{Config.TARGET}_rollstd_{window}'] = train_df.groupby(['ROW', 'COL'])[Config.TARGET].transform(\n",
    "                lambda x: x.rolling(window, min_periods=1).std())\n",
    "        \n",
    "        # Create rolling stats for validation set\n",
    "        train_val_df = pd.concat([train_df, val_df]).sort_values('DATETIME').reset_index(drop=True)\n",
    "        for window in window_sizes:\n",
    "            train_val_df[f'{Config.TARGET}_rollmean_{window}'] = train_val_df.groupby(['ROW', 'COL'])[Config.TARGET].transform(\n",
    "                lambda x: x.rolling(window, min_periods=1).mean())\n",
    "            train_val_df[f'{Config.TARGET}_rollstd_{window}'] = train_val_df.groupby(['ROW', 'COL'])[Config.TARGET].transform(\n",
    "                lambda x: x.rolling(window, min_periods=1).std())\n",
    "        val_df = train_val_df.iloc[len(train_df):].reset_index(drop=True)\n",
    "        \n",
    "        # Create rolling stats for test set\n",
    "        full_df = pd.concat([train_df, val_df, test_df]).sort_values('DATETIME').reset_index(drop=True)\n",
    "        for window in window_sizes:\n",
    "            full_df[f'{Config.TARGET}_rollmean_{window}'] = full_df.groupby(['ROW', 'COL'])[Config.TARGET].transform(\n",
    "                lambda x: x.rolling(window, min_periods=1).mean())\n",
    "            full_df[f'{Config.TARGET}_rollstd_{window}'] = full_df.groupby(['ROW', 'COL'])[Config.TARGET].transform(\n",
    "                lambda x: x.rolling(window, min_periods=1).std())\n",
    "        test_df = full_df.iloc[len(train_df) + len(val_df):].reset_index(drop=True)\n",
    "    \n",
    "    # Handle missing values\n",
    "    train_df = train_df.fillna(0)\n",
    "    val_df = val_df.fillna(0)\n",
    "    test_df = test_df.fillna(0)\n",
    "    \n",
    "    # Prepare feature columns - exclude DATETIME, ROW, COL and target column\n",
    "    # Include selected_features that are in the DataFrame\n",
    "    basic_cols = [col for col in selected_features if col in train_df.columns]\n",
    "    lag_cols = [f'{Config.TARGET}_lag{lag}' for lag in lag_steps if f'{Config.TARGET}_lag{lag}' in train_df.columns]\n",
    "    roll_cols = []\n",
    "    \n",
    "    for window in window_sizes:\n",
    "        mean_col = f'{Config.TARGET}_rollmean_{window}'\n",
    "        std_col = f'{Config.TARGET}_rollstd_{window}'\n",
    "        if mean_col in train_df.columns:\n",
    "            roll_cols.append(mean_col)\n",
    "        if std_col in train_df.columns:\n",
    "            roll_cols.append(std_col)\n",
    "    \n",
    "    feature_cols = basic_cols + lag_cols + roll_cols\n",
    "    \n",
    "    # Check if we have any features\n",
    "    if not feature_cols:\n",
    "        print(\" No features detected! Creating default lag feature.\")\n",
    "        # Create at least one default lag feature\n",
    "        default_lag = 1\n",
    "        for df in [train_df, val_df, test_df]:\n",
    "            df[f'{Config.TARGET}_lag{default_lag}'] = df.groupby(['ROW', 'COL'])[Config.TARGET].shift(default_lag)\n",
    "            df = df.fillna(0)\n",
    "        \n",
    "        feature_cols = [f'{Config.TARGET}_lag{default_lag}']\n",
    "    \n",
    "    # Create sequences\n",
    "    train_x, train_y = create_sequences(train_df, feature_cols, Config.TARGET, time_step_in, time_step_out, stride)\n",
    "    val_x, val_y = create_sequences(val_df, feature_cols, Config.TARGET, time_step_in, time_step_out, stride)\n",
    "    test_x, test_y = create_sequences(test_df, feature_cols, Config.TARGET, time_step_in, time_step_out, stride)\n",
    "    \n",
    "    if train_x.numel() == 0 or val_x.numel() == 0 or test_x.numel() == 0:\n",
    "        print(f\" One or more sequence sets are empty for cluster {cluster_id}\")\n",
    "        return None, None, None, 0\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(TensorDataset(train_x, train_y), batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(TensorDataset(val_x, val_y), batch_size=batch_size)\n",
    "    test_loader = DataLoader(TensorDataset(test_x, test_y), batch_size=batch_size)\n",
    "    \n",
    "    return train_loader, val_loader, test_loader, train_x.shape[2]\n",
    "\n",
    "# Evaluate model\n",
    "def evaluate_model(model, loader):\n",
    "    \"\"\"Evaluate model and return metrics\"\"\"\n",
    "    model.eval()\n",
    "    preds, targets = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            xb = xb.to(DEVICE)\n",
    "            pred = model(xb).cpu()\n",
    "            preds.append(pred)\n",
    "            targets.append(yb)\n",
    "    \n",
    "    preds = torch.cat(preds).squeeze().numpy()\n",
    "    targets = torch.cat(targets).squeeze().numpy()\n",
    "    \n",
    "    # Handle multi-step output\n",
    "    if len(preds.shape) > 1 and preds.shape[1] > 1:\n",
    "        # For multi-step evaluation, we'll calculate metrics on the last predicted step\n",
    "        preds_last = preds[:, -1]\n",
    "        targets_last = targets[:, -1] if len(targets.shape) > 1 else targets\n",
    "        \n",
    "        rmse = mean_squared_error(targets_last, preds_last, squared=False)\n",
    "        bias = np.mean(preds_last - targets_last)\n",
    "        r = r2_score(targets_last, preds_last)\n",
    "        csi = np.sum((preds_last > 0.1) & (targets_last > 0.1)) / (np.sum((preds_last > 0.1) | (targets_last > 0.1)) + 1e-9)\n",
    "    else:\n",
    "        rmse = mean_squared_error(targets, preds, squared=False)\n",
    "        bias = np.mean(preds - targets)\n",
    "        r = r2_score(targets, preds)\n",
    "        csi = np.sum((preds > 0.1) & (targets > 0.1)) / (np.sum((preds > 0.1) | (targets > 0.1)) + 1e-9)\n",
    "    \n",
    "    return rmse, bias, r, csi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae5129fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T17:16:49.399140Z",
     "iopub.status.busy": "2025-05-06T17:16:49.398875Z",
     "iopub.status.idle": "2025-05-06T17:16:49.411728Z",
     "shell.execute_reply": "2025-05-06T17:16:49.410829Z"
    },
    "papermill": {
     "duration": 0.017513,
     "end_time": "2025-05-06T17:16:49.413155",
     "exception": false,
     "start_time": "2025-05-06T17:16:49.395642",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_cluster_evaluation_from_checkpoint():\n",
    "    \"\"\"Run evaluation on clusters using pre-trained models from checkpoints\"\"\"\n",
    "    # Load clustering information\n",
    "    cluster_df = load_clustering_info()\n",
    "    if cluster_df is None:\n",
    "        print(\"[ERRORS] Failed to load clustering information\")\n",
    "        return\n",
    "    \n",
    "    # Get unique cluster IDs\n",
    "    cluster_ids = cluster_df['CLUSTER'].unique()\n",
    "    \n",
    "    # Results storage\n",
    "    all_results = []\n",
    "    best_month_results = []  # Store best fold results for each month\n",
    "    \n",
    "    for month in months:\n",
    "        print(f\"\\n###### Processing month: {month}\")\n",
    "        \n",
    "        # Load best parameters for this month\n",
    "        best_params_path = f\"/kaggle/input/lstm-checkpoint/best_params_{month}.json\"\n",
    "        try:\n",
    "            with open(best_params_path, \"r\") as f:\n",
    "                best_params = json.load(f)\n",
    "            print(f\" Loaded best parameters from {best_params_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[ERRORS] Error loading best parameters: {str(e)}\")\n",
    "            continue\n",
    "        \n",
    "        # Store results for all folds of this month\n",
    "        month_fold_results = []\n",
    "        \n",
    "        # Process each fold for this month\n",
    "        for fold in folds:\n",
    "            print(f\"\\n##### Processing {month}, {fold}\")\n",
    "            \n",
    "            # Process each cluster\n",
    "            cluster_results = []\n",
    "            for cluster_id in cluster_ids:\n",
    "                print(f\"\\n##### Processing cluster {cluster_id}\")\n",
    "                # Use our evaluation function\n",
    "                result = evaluate_cluster_with_checkpoint(month, fold, best_params, cluster_df, cluster_id)\n",
    "                if result:\n",
    "                    cluster_results.append(result)\n",
    "                    all_results.append(result)\n",
    "            \n",
    "            # Calculate mean performance across clusters for this fold\n",
    "            if cluster_results:\n",
    "                mean_rmse = sum(r[\"test_rmse\"] for r in cluster_results) / len(cluster_results)\n",
    "                mean_bias = sum(r[\"test_bias\"] for r in cluster_results) / len(cluster_results)\n",
    "                mean_r = sum(r[\"test_r\"] for r in cluster_results) / len(cluster_results)\n",
    "                mean_csi = sum(r[\"test_csi\"] for r in cluster_results) / len(cluster_results)\n",
    "                \n",
    "                # Create fold summary\n",
    "                fold_summary = {\n",
    "                    \"month\": month,\n",
    "                    \"fold\": fold,\n",
    "                    \"mean_test_rmse\": round(mean_rmse, 4),\n",
    "                    \"mean_test_bias\": round(mean_bias, 4),\n",
    "                    \"mean_test_r\": round(mean_r, 4),\n",
    "                    \"mean_test_csi\": round(mean_csi, 4),\n",
    "                    \"num_clusters\": len(cluster_results)\n",
    "                }\n",
    "                \n",
    "                # Add to month's fold results\n",
    "                month_fold_results.append(fold_summary)\n",
    "                \n",
    "                print(f\"\\n Mean test performance across clusters for {month}, {fold}:\")\n",
    "                print(f\"  RMSE: {mean_rmse:.4f}, Bias: {mean_bias:.4f}, R²: {mean_r:.4f}, CSI: {mean_csi:.4f}\")\n",
    "                \n",
    "                # Save summary for this fold\n",
    "                with open(f\"cluster_summary_{month}_{fold}.json\", \"w\") as f:\n",
    "                    json.dump(fold_summary, f, indent=2)\n",
    "        \n",
    "        # Find best fold for this month (lowest RMSE)\n",
    "        if month_fold_results:\n",
    "            best_fold_result = min(month_fold_results, key=lambda x: x[\"mean_test_rmse\"])\n",
    "            best_month_results.append(best_fold_result)\n",
    "            \n",
    "            print(f\"\\n Best fold for {month}: {best_fold_result['fold']}\")\n",
    "            print(f\"  RMSE: {best_fold_result['mean_test_rmse']:.4f}, Bias: {best_fold_result['mean_test_bias']:.4f}, R²: {best_fold_result['mean_test_r']:.4f}, CSI: {best_fold_result['mean_test_csi']:.4f}\")\n",
    "    \n",
    "    # Create a dataframe with all results\n",
    "    if all_results:\n",
    "        all_results_df = pd.DataFrame([\n",
    "            {\n",
    "                \"month\": r[\"month\"],\n",
    "                \"fold\": r[\"fold\"],\n",
    "                \"cluster\": r[\"cluster\"],\n",
    "                \"test_rmse\": r[\"test_rmse\"],\n",
    "                \"test_bias\": r[\"test_bias\"],\n",
    "                \"test_r\": r[\"test_r\"],\n",
    "                \"test_csi\": r[\"test_csi\"],\n",
    "                \"val_rmse\": r[\"val_rmse\"],\n",
    "                \"val_bias\": r[\"val_bias\"],\n",
    "                \"val_r\": r[\"val_r\"],\n",
    "                \"val_csi\": r[\"val_csi\"]\n",
    "            } for r in all_results\n",
    "        ])\n",
    "        \n",
    "        # Save all results\n",
    "        all_results_df.to_csv(\"lstm_cluster_results.csv\", index=False)\n",
    "        print(\"\\n All cluster results saved to lstm_cluster_results.csv\")\n",
    "        \n",
    "        # Create a dataframe with best fold results per month\n",
    "        best_month_df = pd.DataFrame(best_month_results)\n",
    "        best_month_df.to_csv(\"lstm_best_fold_per_month.csv\", index=False)\n",
    "        print(\" Best fold results per month saved to lstm_best_fold_per_month.csv\")\n",
    "        \n",
    "        # Calculate overall mean performance across best folds of all months\n",
    "        if best_month_results:\n",
    "            overall_mean_rmse = sum(r[\"mean_test_rmse\"] for r in best_month_results) / len(best_month_results)\n",
    "            overall_mean_bias = sum(r[\"mean_test_bias\"] for r in best_month_results) / len(best_month_results)\n",
    "            overall_mean_r = sum(r[\"mean_test_r\"] for r in best_month_results) / len(best_month_results)\n",
    "            overall_mean_csi = sum(r[\"mean_test_csi\"] for r in best_month_results) / len(best_month_results)\n",
    "            \n",
    "            overall_results = {\n",
    "                \"overall_mean_rmse\": round(overall_mean_rmse, 4),\n",
    "                \"overall_mean_bias\": round(overall_mean_bias, 4),\n",
    "                \"overall_mean_r\": round(overall_mean_r, 4),\n",
    "                \"overall_mean_csi\": round(overall_mean_csi, 4),\n",
    "                \"num_months\": len(best_month_results)\n",
    "            }\n",
    "            \n",
    "            # Save overall results\n",
    "            with open(\"lstm_overall_results.json\", \"w\") as f:\n",
    "                json.dump(overall_results, f, indent=2)\n",
    "            \n",
    "            print(\"\\n Overall mean performance across best folds of all months:\")\n",
    "            print(f\"  RMSE: {overall_mean_rmse:.4f}, Bias: {overall_mean_bias:.4f}, R²: {overall_mean_r:.4f}, CSI: {overall_mean_csi:.4f}\")\n",
    "            \n",
    "            # Display best fold results for each month\n",
    "            print(\"\\n Best Fold Results by Month:\")\n",
    "            print(best_month_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1756f3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T17:16:49.419066Z",
     "iopub.status.busy": "2025-05-06T17:16:49.418843Z",
     "iopub.status.idle": "2025-05-06T17:16:49.427221Z",
     "shell.execute_reply": "2025-05-06T17:16:49.426524Z"
    },
    "papermill": {
     "duration": 0.012992,
     "end_time": "2025-05-06T17:16:49.428638",
     "exception": false,
     "start_time": "2025-05-06T17:16:49.415646",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_cluster_with_checkpoint(month, fold, best_params, cluster_df=None, cluster_id=None):\n",
    "    \"\"\"Evaluate a pre-trained model on a specific cluster without retraining\"\"\"\n",
    "    print(f\"\\n Evaluating cluster {cluster_id} for {month}, {fold} using checkpoint\")\n",
    "    \n",
    "    # Extract parameters for data preparation\n",
    "    time_step_in = best_params[\"time_step_in\"]\n",
    "    time_step_out = best_params[\"time_step_out\"]\n",
    "    stride = best_params[\"stride\"]\n",
    "    \n",
    "    # Extract lag steps and window sizes\n",
    "    num_lags = best_params[\"num_lags\"]\n",
    "    lag_steps = [best_params[f\"lag_{i}\"] for i in range(num_lags)]\n",
    "    \n",
    "    num_windows = best_params[\"num_windows\"]\n",
    "    window_sizes = [best_params[f\"window_{i}\"] for i in range(num_windows)]\n",
    "    \n",
    "    # Get config\n",
    "    config_key = month.split(\"-\")[1]\n",
    "    config = MODEL_CONFIG[config_key]\n",
    "    batch_size = config[\"BATCH_SIZE\"]\n",
    "    \n",
    "    # Prepare data for this cluster only\n",
    "    _, val_loader, test_loader, input_size = prepare_data_loaders(\n",
    "        month, fold, lag_steps, window_sizes, time_step_in, time_step_out, batch_size, stride,\n",
    "        cluster_df=cluster_df, cluster_id=cluster_id\n",
    "    )\n",
    "    \n",
    "    if val_loader is None or test_loader is None:\n",
    "        print(f\"[ERRORS] Failed to prepare data for cluster {cluster_id}\")\n",
    "        return None\n",
    "    \n",
    "    # Load the pre-trained model for this month\n",
    "    checkpoint_path = f\"/kaggle/input/lstm-checkpoint/best_model_{month}.pt\"\n",
    "    \n",
    "    # Create model with the same architecture as the pre-trained one\n",
    "    model = LSTMModel(\n",
    "        input_size=input_size,\n",
    "        hidden_size=best_params[\"hidden_size\"],\n",
    "        num_layers=best_params[\"num_layers\"],\n",
    "        dropout=best_params[\"dropout\"],\n",
    "        time_step_out=time_step_out\n",
    "    ).to(DEVICE)\n",
    "    \n",
    "    try:\n",
    "        # Load checkpoint state\n",
    "        model.load_state_dict(torch.load(checkpoint_path))\n",
    "        print(f\" Successfully loaded checkpoint from {checkpoint_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[ERRORS] Error loading checkpoint: {str(e)}\")\n",
    "        return None\n",
    "    \n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    print(f\" Evaluating on validation set for cluster {cluster_id}...\")\n",
    "    val_rmse, val_bias, val_r, val_csi = evaluate_model(model, val_loader)\n",
    "    print(f\"  Val RMSE: {val_rmse:.4f}, Bias: {val_bias:.4f}, R²: {val_r:.4f}, CSI: {val_csi:.4f}\")\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    print(f\" Evaluating on test set for cluster {cluster_id}...\")\n",
    "    test_rmse, test_bias, test_r, test_csi = evaluate_model(model, test_loader)\n",
    "    print(f\"  Test RMSE: {test_rmse:.4f}, Bias: {test_bias:.4f}, R²: {test_r:.4f}, CSI: {test_csi:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        \"month\": month,\n",
    "        \"fold\": fold,\n",
    "        \"cluster\": cluster_id,\n",
    "        \"test_rmse\": round(test_rmse, 4),\n",
    "        \"test_bias\": round(test_bias, 4),\n",
    "        \"test_r\": round(test_r, 4),\n",
    "        \"test_csi\": round(test_csi, 4),\n",
    "        \"val_rmse\": round(val_rmse, 4),\n",
    "        \"val_bias\": round(val_bias, 4),\n",
    "        \"val_r\": round(val_r, 4),\n",
    "        \"val_csi\": round(val_csi, 4)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fe799d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T17:16:49.434463Z",
     "iopub.status.busy": "2025-05-06T17:16:49.434202Z",
     "iopub.status.idle": "2025-05-06T17:23:02.356388Z",
     "shell.execute_reply": "2025-05-06T17:23:02.355298Z"
    },
    "papermill": {
     "duration": 372.926651,
     "end_time": "2025-05-06T17:23:02.357864",
     "exception": false,
     "start_time": "2025-05-06T17:16:49.431213",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loaded clustering info: 334 rows\n",
      "\n",
      "###### Processing month: 2019-04\n",
      " Loaded best parameters from /kaggle/input/lstm-checkpoint/best_params_2019-04.json\n",
      "\n",
      "##### Processing 2019-04, fold_1\n",
      "\n",
      "##### Processing cluster 0\n",
      "\n",
      " Evaluating cluster 0 for 2019-04, fold_1 using checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-62cb43d7e5fe>:233: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
      "  return torch.tensor(sequences, dtype=torch.float32), torch.tensor(targets, dtype=torch.float32)\n",
      "<ipython-input-5-ca89ff15378e>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully loaded checkpoint from /kaggle/input/lstm-checkpoint/best_model_2019-04.pt\n",
      " Evaluating on validation set for cluster 0...\n",
      "  Val RMSE: 0.0648, Bias: 0.0335, R²: -0.3288, CSI: 0.0000\n",
      " Evaluating on test set for cluster 0...\n",
      "  Test RMSE: 0.9646, Bias: -0.1126, R²: -0.0111, CSI: 0.0991\n",
      "\n",
      "##### Processing cluster 2\n",
      "\n",
      " Evaluating cluster 2 for 2019-04, fold_1 using checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-ca89ff15378e>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully loaded checkpoint from /kaggle/input/lstm-checkpoint/best_model_2019-04.pt\n",
      " Evaluating on validation set for cluster 2...\n",
      "  Val RMSE: 0.0569, Bias: 0.0381, R²: -0.8003, CSI: 0.0000\n",
      " Evaluating on test set for cluster 2...\n",
      "  Test RMSE: 1.0960, Bias: -0.1579, R²: -0.0099, CSI: 0.0901\n",
      "\n",
      "##### Processing cluster 1\n",
      "\n",
      " Evaluating cluster 1 for 2019-04, fold_1 using checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-ca89ff15378e>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully loaded checkpoint from /kaggle/input/lstm-checkpoint/best_model_2019-04.pt\n",
      " Evaluating on validation set for cluster 1...\n",
      "  Val RMSE: 0.0637, Bias: 0.0415, R²: -0.8127, CSI: 0.0000\n",
      " Evaluating on test set for cluster 1...\n",
      "  Test RMSE: 1.1323, Bias: -0.1296, R²: -0.0112, CSI: 0.0417\n",
      "\n",
      "##### Processing cluster 3\n",
      "\n",
      " Evaluating cluster 3 for 2019-04, fold_1 using checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-ca89ff15378e>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully loaded checkpoint from /kaggle/input/lstm-checkpoint/best_model_2019-04.pt\n",
      " Evaluating on validation set for cluster 3...\n",
      "  Val RMSE: 0.2836, Bias: 0.0382, R²: -0.0477, CSI: 0.0526\n",
      " Evaluating on test set for cluster 3...\n",
      "  Test RMSE: 1.0428, Bias: -0.0868, R²: 0.0506, CSI: 0.2222\n",
      "\n",
      " Mean test performance across clusters for 2019-04, fold_1:\n",
      "  RMSE: 1.0589, Bias: -0.1217, R²: 0.0046, CSI: 0.1133\n",
      "\n",
      "##### Processing 2019-04, fold_2\n",
      "\n",
      "##### Processing cluster 0\n",
      "\n",
      " Evaluating cluster 0 for 2019-04, fold_2 using checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-ca89ff15378e>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully loaded checkpoint from /kaggle/input/lstm-checkpoint/best_model_2019-04.pt\n",
      " Evaluating on validation set for cluster 0...\n",
      "  Val RMSE: 0.2620, Bias: 0.0026, R²: 0.0002, CSI: 0.0238\n",
      " Evaluating on test set for cluster 0...\n",
      "  Test RMSE: 0.9637, Bias: -0.1021, R²: -0.0093, CSI: 0.1667\n",
      "\n",
      "##### Processing cluster 2\n",
      "\n",
      " Evaluating cluster 2 for 2019-04, fold_2 using checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-ca89ff15378e>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully loaded checkpoint from /kaggle/input/lstm-checkpoint/best_model_2019-04.pt\n",
      " Evaluating on validation set for cluster 2...\n",
      "  Val RMSE: 0.4131, Bias: 0.0008, R²: -0.0035, CSI: 0.0000\n",
      " Evaluating on test set for cluster 2...\n",
      "  Test RMSE: 1.0945, Bias: -0.1454, R²: -0.0071, CSI: 0.1008\n",
      "\n",
      "##### Processing cluster 1\n",
      "\n",
      " Evaluating cluster 1 for 2019-04, fold_2 using checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-ca89ff15378e>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully loaded checkpoint from /kaggle/input/lstm-checkpoint/best_model_2019-04.pt\n",
      " Evaluating on validation set for cluster 1...\n",
      "  Val RMSE: 0.0507, Bias: 0.0285, R²: -0.4744, CSI: 0.0000\n",
      " Evaluating on test set for cluster 1...\n",
      "  Test RMSE: 1.1304, Bias: -0.1204, R²: -0.0080, CSI: 0.0789\n",
      "\n",
      "##### Processing cluster 3\n",
      "\n",
      " Evaluating cluster 3 for 2019-04, fold_2 using checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-ca89ff15378e>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully loaded checkpoint from /kaggle/input/lstm-checkpoint/best_model_2019-04.pt\n",
      " Evaluating on validation set for cluster 3...\n",
      "  Val RMSE: 0.3798, Bias: 0.0184, R²: 0.2688, CSI: 0.0377\n",
      " Evaluating on test set for cluster 3...\n",
      "  Test RMSE: 1.0421, Bias: -0.0752, R²: 0.0519, CSI: 0.2059\n",
      "\n",
      " Mean test performance across clusters for 2019-04, fold_2:\n",
      "  RMSE: 1.0577, Bias: -0.1108, R²: 0.0069, CSI: 0.1381\n",
      "\n",
      "##### Processing 2019-04, fold_3\n",
      "\n",
      "##### Processing cluster 0\n",
      "\n",
      " Evaluating cluster 0 for 2019-04, fold_3 using checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-ca89ff15378e>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully loaded checkpoint from /kaggle/input/lstm-checkpoint/best_model_2019-04.pt\n",
      " Evaluating on validation set for cluster 0...\n",
      "  Val RMSE: 0.9178, Bias: -0.1154, R²: -0.0095, CSI: 0.0867\n",
      " Evaluating on test set for cluster 0...\n",
      "  Test RMSE: 0.9637, Bias: -0.1021, R²: -0.0092, CSI: 0.1667\n",
      "\n",
      "##### Processing cluster 2\n",
      "\n",
      " Evaluating cluster 2 for 2019-04, fold_3 using checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-ca89ff15378e>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully loaded checkpoint from /kaggle/input/lstm-checkpoint/best_model_2019-04.pt\n",
      " Evaluating on validation set for cluster 2...\n",
      "  Val RMSE: 0.9449, Bias: -0.1115, R²: -0.0007, CSI: 0.0906\n",
      " Evaluating on test set for cluster 2...\n",
      "  Test RMSE: 1.0947, Bias: -0.1455, R²: -0.0074, CSI: 0.0952\n",
      "\n",
      "##### Processing cluster 1\n",
      "\n",
      " Evaluating cluster 1 for 2019-04, fold_3 using checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-ca89ff15378e>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully loaded checkpoint from /kaggle/input/lstm-checkpoint/best_model_2019-04.pt\n",
      " Evaluating on validation set for cluster 1...\n",
      "  Val RMSE: 0.5297, Bias: -0.0207, R²: -0.0004, CSI: 0.0234\n",
      " Evaluating on test set for cluster 1...\n",
      "  Test RMSE: 1.1305, Bias: -0.1204, R²: -0.0081, CSI: 0.0789\n",
      "\n",
      "##### Processing cluster 3\n",
      "\n",
      " Evaluating cluster 3 for 2019-04, fold_3 using checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-ca89ff15378e>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully loaded checkpoint from /kaggle/input/lstm-checkpoint/best_model_2019-04.pt\n",
      " Evaluating on validation set for cluster 3...\n",
      "  Val RMSE: 0.8012, Bias: -0.0695, R²: 0.0091, CSI: 0.0417\n",
      " Evaluating on test set for cluster 3...\n",
      "  Test RMSE: 1.0406, Bias: -0.0770, R²: 0.0547, CSI: 0.2121\n",
      "\n",
      " Mean test performance across clusters for 2019-04, fold_3:\n",
      "  RMSE: 1.0574, Bias: -0.1113, R²: 0.0075, CSI: 0.1382\n",
      "\n",
      "##### Processing 2019-04, fold_4\n",
      "\n",
      "##### Processing cluster 0\n",
      "\n",
      " Evaluating cluster 0 for 2019-04, fold_4 using checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-ca89ff15378e>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully loaded checkpoint from /kaggle/input/lstm-checkpoint/best_model_2019-04.pt\n",
      " Evaluating on validation set for cluster 0...\n",
      "  Val RMSE: 0.0599, Bias: 0.0374, R²: -0.6631, CSI: 0.0000\n",
      " Evaluating on test set for cluster 0...\n",
      "  Test RMSE: 0.9629, Bias: -0.0883, R²: -0.0076, CSI: 0.1818\n",
      "\n",
      "##### Processing cluster 2\n",
      "\n",
      " Evaluating cluster 2 for 2019-04, fold_4 using checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-ca89ff15378e>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully loaded checkpoint from /kaggle/input/lstm-checkpoint/best_model_2019-04.pt\n",
      " Evaluating on validation set for cluster 2...\n",
      "  Val RMSE: 0.0394, Bias: 0.0325, R²: -2.2075, CSI: 0.0000\n",
      " Evaluating on test set for cluster 2...\n",
      "  Test RMSE: 1.0918, Bias: -0.1275, R²: -0.0021, CSI: 0.1114\n",
      "\n",
      "##### Processing cluster 1\n",
      "\n",
      " Evaluating cluster 1 for 2019-04, fold_4 using checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-ca89ff15378e>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully loaded checkpoint from /kaggle/input/lstm-checkpoint/best_model_2019-04.pt\n",
      " Evaluating on validation set for cluster 1...\n",
      "  Val RMSE: 0.0681, Bias: 0.0428, R²: -0.6591, CSI: 0.0000\n",
      " Evaluating on test set for cluster 1...\n",
      "  Test RMSE: 1.1195, Bias: -0.1034, R²: 0.0114, CSI: 0.0789\n",
      "\n",
      "##### Processing cluster 3\n",
      "\n",
      " Evaluating cluster 3 for 2019-04, fold_4 using checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-ca89ff15378e>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully loaded checkpoint from /kaggle/input/lstm-checkpoint/best_model_2019-04.pt\n",
      " Evaluating on validation set for cluster 3...\n",
      "  Val RMSE: 0.0980, Bias: 0.0472, R²: -59.8929, CSI: 0.0667\n",
      " Evaluating on test set for cluster 3...\n",
      "  Test RMSE: 1.0373, Bias: -0.0646, R²: 0.0606, CSI: 0.1772\n",
      "\n",
      " Mean test performance across clusters for 2019-04, fold_4:\n",
      "  RMSE: 1.0529, Bias: -0.0959, R²: 0.0156, CSI: 0.1373\n",
      "\n",
      "##### Processing 2019-04, fold_5\n",
      "\n",
      "##### Processing cluster 0\n",
      "\n",
      " Evaluating cluster 0 for 2019-04, fold_5 using checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-ca89ff15378e>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully loaded checkpoint from /kaggle/input/lstm-checkpoint/best_model_2019-04.pt\n",
      " Evaluating on validation set for cluster 0...\n",
      "  Val RMSE: 0.4219, Bias: -0.0194, R²: -0.0084, CSI: 0.0064\n",
      " Evaluating on test set for cluster 0...\n",
      "  Test RMSE: 0.9626, Bias: -0.0874, R²: -0.0070, CSI: 0.1899\n",
      "\n",
      "##### Processing cluster 2\n",
      "\n",
      " Evaluating cluster 2 for 2019-04, fold_5 using checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-ca89ff15378e>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully loaded checkpoint from /kaggle/input/lstm-checkpoint/best_model_2019-04.pt\n",
      " Evaluating on validation set for cluster 2...\n",
      "  Val RMSE: 0.0645, Bias: 0.0264, R²: -0.0331, CSI: 0.0000\n",
      " Evaluating on test set for cluster 2...\n",
      "  Test RMSE: 1.0917, Bias: -0.1270, R²: -0.0020, CSI: 0.1161\n",
      "\n",
      "##### Processing cluster 1\n",
      "\n",
      " Evaluating cluster 1 for 2019-04, fold_5 using checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-ca89ff15378e>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully loaded checkpoint from /kaggle/input/lstm-checkpoint/best_model_2019-04.pt\n",
      " Evaluating on validation set for cluster 1...\n",
      "  Val RMSE: 0.1767, Bias: -0.0128, R²: 0.0230, CSI: 0.1449\n",
      " Evaluating on test set for cluster 1...\n",
      "  Test RMSE: 1.1209, Bias: -0.1034, R²: 0.0090, CSI: 0.0779\n",
      "\n",
      "##### Processing cluster 3\n",
      "\n",
      " Evaluating cluster 3 for 2019-04, fold_5 using checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-ca89ff15378e>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully loaded checkpoint from /kaggle/input/lstm-checkpoint/best_model_2019-04.pt\n",
      " Evaluating on validation set for cluster 3...\n",
      "  Val RMSE: 0.1464, Bias: -0.0103, R²: 0.0363, CSI: 0.2333\n",
      " Evaluating on test set for cluster 3...\n",
      "  Test RMSE: 1.0373, Bias: -0.0639, R²: 0.0606, CSI: 0.1750\n",
      "\n",
      " Mean test performance across clusters for 2019-04, fold_5:\n",
      "  RMSE: 1.0531, Bias: -0.0954, R²: 0.0152, CSI: 0.1397\n",
      "\n",
      " Best fold for 2019-04: fold_4\n",
      "  RMSE: 1.0529, Bias: -0.0959, R²: 0.0156, CSI: 0.1373\n",
      "\n",
      "###### Processing month: 2019-10\n",
      " Loaded best parameters from /kaggle/input/lstm-checkpoint/best_params_2019-10.json\n",
      "\n",
      "##### Processing 2019-10, fold_1\n",
      "\n",
      "##### Processing cluster 0\n",
      "\n",
      " Evaluating cluster 0 for 2019-10, fold_1 using checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.0036657529755497707 and num_layers=1\n",
      "  warnings.warn(\n",
      "<ipython-input-5-ca89ff15378e>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully loaded checkpoint from /kaggle/input/lstm-checkpoint/best_model_2019-10.pt\n",
      " Evaluating on validation set for cluster 0...\n",
      "  Val RMSE: 0.5648, Bias: 0.0379, R²: 0.4534, CSI: 0.6154\n",
      " Evaluating on test set for cluster 0...\n",
      "  Test RMSE: 0.3370, Bias: 0.0323, R²: 0.7544, CSI: 0.5723\n",
      "\n",
      "##### Processing cluster 2\n",
      "\n",
      " Evaluating cluster 2 for 2019-10, fold_1 using checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.0036657529755497707 and num_layers=1\n",
      "  warnings.warn(\n",
      "<ipython-input-5-ca89ff15378e>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully loaded checkpoint from /kaggle/input/lstm-checkpoint/best_model_2019-10.pt\n",
      " Evaluating on validation set for cluster 2...\n",
      "  Val RMSE: 0.4810, Bias: 0.0477, R²: 0.3449, CSI: 0.4326\n",
      " Evaluating on test set for cluster 2...\n",
      "  Test RMSE: 0.2288, Bias: 0.0115, R²: 0.4340, CSI: 0.7052\n",
      "\n",
      "##### Processing cluster 1\n",
      "\n",
      " Evaluating cluster 1 for 2019-10, fold_1 using checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.0036657529755497707 and num_layers=1\n",
      "  warnings.warn(\n",
      "<ipython-input-5-ca89ff15378e>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully loaded checkpoint from /kaggle/input/lstm-checkpoint/best_model_2019-10.pt\n",
      " Evaluating on validation set for cluster 1...\n",
      "  Val RMSE: 0.4553, Bias: 0.0653, R²: 0.1831, CSI: 0.5129\n",
      " Evaluating on test set for cluster 1...\n",
      "  Test RMSE: 0.1212, Bias: 0.0330, R²: 0.4389, CSI: 0.7052\n",
      "\n",
      "##### Processing cluster 3\n",
      "\n",
      " Evaluating cluster 3 for 2019-10, fold_1 using checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.0036657529755497707 and num_layers=1\n",
      "  warnings.warn(\n",
      "<ipython-input-5-ca89ff15378e>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully loaded checkpoint from /kaggle/input/lstm-checkpoint/best_model_2019-10.pt\n",
      " Evaluating on validation set for cluster 3...\n",
      "  Val RMSE: 0.7594, Bias: 0.0189, R²: 0.4677, CSI: 0.7861\n",
      " Evaluating on test set for cluster 3...\n",
      "  Test RMSE: 0.9093, Bias: -0.0028, R²: 0.7315, CSI: 0.6418\n",
      "\n",
      " Mean test performance across clusters for 2019-10, fold_1:\n",
      "  RMSE: 0.3991, Bias: 0.0185, R²: 0.5897, CSI: 0.6561\n",
      "\n",
      "##### Processing 2019-10, fold_2\n",
      "\n",
      "##### Processing cluster 0\n",
      "\n",
      " Evaluating cluster 0 for 2019-10, fold_2 using checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.0036657529755497707 and num_layers=1\n",
      "  warnings.warn(\n",
      "<ipython-input-5-ca89ff15378e>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully loaded checkpoint from /kaggle/input/lstm-checkpoint/best_model_2019-10.pt\n",
      " Evaluating on validation set for cluster 0...\n",
      "  Val RMSE: 0.5327, Bias: 0.0467, R²: 0.5146, CSI: 0.5356\n",
      " Evaluating on test set for cluster 0...\n",
      "  Test RMSE: 0.2283, Bias: 0.0382, R²: 0.5765, CSI: 0.5931\n",
      "\n",
      "##### Processing cluster 2\n",
      "\n",
      " Evaluating cluster 2 for 2019-10, fold_2 using checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.0036657529755497707 and num_layers=1\n",
      "  warnings.warn(\n",
      "<ipython-input-5-ca89ff15378e>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully loaded checkpoint from /kaggle/input/lstm-checkpoint/best_model_2019-10.pt\n",
      " Evaluating on validation set for cluster 2...\n",
      "  Val RMSE: 0.2623, Bias: 0.0424, R²: 0.5826, CSI: 0.4559\n",
      " Evaluating on test set for cluster 2...\n",
      "  Test RMSE: 0.2602, Bias: 0.0224, R²: 0.6164, CSI: 0.6214\n",
      "\n",
      "##### Processing cluster 1\n",
      "\n",
      " Evaluating cluster 1 for 2019-10, fold_2 using checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.0036657529755497707 and num_layers=1\n",
      "  warnings.warn(\n",
      "<ipython-input-5-ca89ff15378e>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully loaded checkpoint from /kaggle/input/lstm-checkpoint/best_model_2019-10.pt\n",
      " Evaluating on validation set for cluster 1...\n",
      "  Val RMSE: 0.2392, Bias: 0.0432, R²: 0.5107, CSI: 0.5503\n",
      " Evaluating on test set for cluster 1...\n",
      "  Test RMSE: 0.1895, Bias: 0.0276, R²: 0.7291, CSI: 0.6126\n",
      "\n",
      "##### Processing cluster 3\n",
      "\n",
      " Evaluating cluster 3 for 2019-10, fold_2 using checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.0036657529755497707 and num_layers=1\n",
      "  warnings.warn(\n",
      "<ipython-input-5-ca89ff15378e>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully loaded checkpoint from /kaggle/input/lstm-checkpoint/best_model_2019-10.pt\n",
      " Evaluating on validation set for cluster 3...\n",
      "  Val RMSE: 0.9549, Bias: 0.0192, R²: 0.4675, CSI: 0.7234\n",
      " Evaluating on test set for cluster 3...\n",
      "  Test RMSE: 1.1623, Bias: -0.0671, R²: 0.6928, CSI: 0.6679\n",
      "\n",
      " Mean test performance across clusters for 2019-10, fold_2:\n",
      "  RMSE: 0.4601, Bias: 0.0053, R²: 0.6537, CSI: 0.6238\n",
      "\n",
      "##### Processing 2019-10, fold_3\n",
      "\n",
      "##### Processing cluster 0\n",
      "\n",
      " Evaluating cluster 0 for 2019-10, fold_3 using checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.0036657529755497707 and num_layers=1\n",
      "  warnings.warn(\n",
      "<ipython-input-5-ca89ff15378e>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully loaded checkpoint from /kaggle/input/lstm-checkpoint/best_model_2019-10.pt\n",
      " Evaluating on validation set for cluster 0...\n",
      "  Val RMSE: 0.2699, Bias: 0.0596, R²: 0.6251, CSI: 0.5132\n",
      " Evaluating on test set for cluster 0...\n",
      "  Test RMSE: 0.2071, Bias: 0.0536, R²: 0.5181, CSI: 0.5930\n",
      "\n",
      "##### Processing cluster 2\n",
      "\n",
      " Evaluating cluster 2 for 2019-10, fold_3 using checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.0036657529755497707 and num_layers=1\n",
      "  warnings.warn(\n",
      "<ipython-input-5-ca89ff15378e>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully loaded checkpoint from /kaggle/input/lstm-checkpoint/best_model_2019-10.pt\n",
      " Evaluating on validation set for cluster 2...\n",
      "  Val RMSE: 0.2995, Bias: 0.0376, R²: 0.4710, CSI: 0.3702\n",
      " Evaluating on test set for cluster 2...\n",
      "  Test RMSE: 0.2773, Bias: 0.0355, R²: 0.4364, CSI: 0.5748\n",
      "\n",
      "##### Processing cluster 1\n",
      "\n",
      " Evaluating cluster 1 for 2019-10, fold_3 using checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.0036657529755497707 and num_layers=1\n",
      "  warnings.warn(\n",
      "<ipython-input-5-ca89ff15378e>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully loaded checkpoint from /kaggle/input/lstm-checkpoint/best_model_2019-10.pt\n",
      " Evaluating on validation set for cluster 1...\n",
      "  Val RMSE: 0.2418, Bias: 0.0419, R²: 0.3656, CSI: 0.5327\n",
      " Evaluating on test set for cluster 1...\n",
      "  Test RMSE: 0.1500, Bias: 0.0449, R²: 0.6542, CSI: 0.5728\n",
      "\n",
      "##### Processing cluster 3\n",
      "\n",
      " Evaluating cluster 3 for 2019-10, fold_3 using checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.0036657529755497707 and num_layers=1\n",
      "  warnings.warn(\n",
      "<ipython-input-5-ca89ff15378e>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully loaded checkpoint from /kaggle/input/lstm-checkpoint/best_model_2019-10.pt\n",
      " Evaluating on validation set for cluster 3...\n",
      "  Val RMSE: 0.8140, Bias: 0.0334, R²: 0.6160, CSI: 0.6995\n",
      " Evaluating on test set for cluster 3...\n",
      "  Test RMSE: 1.3272, Bias: -0.1441, R²: 0.6956, CSI: 0.6966\n",
      "\n",
      " Mean test performance across clusters for 2019-10, fold_3:\n",
      "  RMSE: 0.4904, Bias: -0.0025, R²: 0.5761, CSI: 0.6093\n",
      "\n",
      "##### Processing 2019-10, fold_4\n",
      "\n",
      "##### Processing cluster 0\n",
      "\n",
      " Evaluating cluster 0 for 2019-10, fold_4 using checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.0036657529755497707 and num_layers=1\n",
      "  warnings.warn(\n",
      "<ipython-input-5-ca89ff15378e>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully loaded checkpoint from /kaggle/input/lstm-checkpoint/best_model_2019-10.pt\n",
      " Evaluating on validation set for cluster 0...\n",
      "  Val RMSE: 0.1740, Bias: 0.0163, R²: 0.3683, CSI: 0.6025\n",
      " Evaluating on test set for cluster 0...\n",
      "  Test RMSE: 0.2701, Bias: 0.0577, R²: 0.2350, CSI: 0.5964\n",
      "\n",
      "##### Processing cluster 2\n",
      "\n",
      " Evaluating cluster 2 for 2019-10, fold_4 using checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.0036657529755497707 and num_layers=1\n",
      "  warnings.warn(\n",
      "<ipython-input-5-ca89ff15378e>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully loaded checkpoint from /kaggle/input/lstm-checkpoint/best_model_2019-10.pt\n",
      " Evaluating on validation set for cluster 2...\n",
      "  Val RMSE: 0.1567, Bias: 0.0057, R²: 0.5564, CSI: 0.5358\n",
      " Evaluating on test set for cluster 2...\n",
      "  Test RMSE: 0.3134, Bias: 0.0298, R²: 0.4856, CSI: 0.6135\n",
      "\n",
      "##### Processing cluster 1\n",
      "\n",
      " Evaluating cluster 1 for 2019-10, fold_4 using checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.0036657529755497707 and num_layers=1\n",
      "  warnings.warn(\n",
      "<ipython-input-5-ca89ff15378e>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully loaded checkpoint from /kaggle/input/lstm-checkpoint/best_model_2019-10.pt\n",
      " Evaluating on validation set for cluster 1...\n",
      "  Val RMSE: 0.1927, Bias: 0.0026, R²: 0.3056, CSI: 0.5968\n",
      " Evaluating on test set for cluster 1...\n",
      "  Test RMSE: 0.1338, Bias: 0.0462, R²: 0.5886, CSI: 0.5909\n",
      "\n",
      "##### Processing cluster 3\n",
      "\n",
      " Evaluating cluster 3 for 2019-10, fold_4 using checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.0036657529755497707 and num_layers=1\n",
      "  warnings.warn(\n",
      "<ipython-input-5-ca89ff15378e>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully loaded checkpoint from /kaggle/input/lstm-checkpoint/best_model_2019-10.pt\n",
      " Evaluating on validation set for cluster 3...\n",
      "  Val RMSE: 0.6930, Bias: 0.0345, R²: 0.6562, CSI: 0.7089\n",
      " Evaluating on test set for cluster 3...\n",
      "  Test RMSE: 1.3316, Bias: -0.1410, R²: 0.6709, CSI: 0.7680\n",
      "\n",
      " Mean test performance across clusters for 2019-10, fold_4:\n",
      "  RMSE: 0.5122, Bias: -0.0018, R²: 0.4950, CSI: 0.6422\n",
      "\n",
      "##### Processing 2019-10, fold_5\n",
      "\n",
      "##### Processing cluster 0\n",
      "\n",
      " Evaluating cluster 0 for 2019-10, fold_5 using checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.0036657529755497707 and num_layers=1\n",
      "  warnings.warn(\n",
      "<ipython-input-5-ca89ff15378e>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully loaded checkpoint from /kaggle/input/lstm-checkpoint/best_model_2019-10.pt\n",
      " Evaluating on validation set for cluster 0...\n",
      "  Val RMSE: 0.3042, Bias: 0.0049, R²: 0.5870, CSI: 0.5992\n",
      " Evaluating on test set for cluster 0...\n",
      "  Test RMSE: 0.4006, Bias: 0.0287, R²: 0.6511, CSI: 0.5882\n",
      "\n",
      "##### Processing cluster 2\n",
      "\n",
      " Evaluating cluster 2 for 2019-10, fold_5 using checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.0036657529755497707 and num_layers=1\n",
      "  warnings.warn(\n",
      "<ipython-input-5-ca89ff15378e>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully loaded checkpoint from /kaggle/input/lstm-checkpoint/best_model_2019-10.pt\n",
      " Evaluating on validation set for cluster 2...\n",
      "  Val RMSE: 0.2818, Bias: -0.0021, R²: 0.4641, CSI: 0.5621\n",
      " Evaluating on test set for cluster 2...\n",
      "  Test RMSE: 0.3579, Bias: 0.0338, R²: 0.5813, CSI: 0.5919\n",
      "\n",
      "##### Processing cluster 1\n",
      "\n",
      " Evaluating cluster 1 for 2019-10, fold_5 using checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.0036657529755497707 and num_layers=1\n",
      "  warnings.warn(\n",
      "<ipython-input-5-ca89ff15378e>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully loaded checkpoint from /kaggle/input/lstm-checkpoint/best_model_2019-10.pt\n",
      " Evaluating on validation set for cluster 1...\n",
      "  Val RMSE: 0.3234, Bias: 0.0049, R²: 0.5443, CSI: 0.5848\n",
      " Evaluating on test set for cluster 1...\n",
      "  Test RMSE: 0.3892, Bias: 0.0242, R²: 0.6292, CSI: 0.5754\n",
      "\n",
      "##### Processing cluster 3\n",
      "\n",
      " Evaluating cluster 3 for 2019-10, fold_5 using checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.0036657529755497707 and num_layers=1\n",
      "  warnings.warn(\n",
      "<ipython-input-5-ca89ff15378e>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully loaded checkpoint from /kaggle/input/lstm-checkpoint/best_model_2019-10.pt\n",
      " Evaluating on validation set for cluster 3...\n",
      "  Val RMSE: 0.7328, Bias: -0.0065, R²: 0.6495, CSI: 0.7293\n",
      " Evaluating on test set for cluster 3...\n",
      "  Test RMSE: 1.1629, Bias: -0.2433, R²: 0.6585, CSI: 0.7986\n",
      "\n",
      " Mean test performance across clusters for 2019-10, fold_5:\n",
      "  RMSE: 0.5776, Bias: -0.0392, R²: 0.6300, CSI: 0.6385\n",
      "\n",
      " Best fold for 2019-10: fold_1\n",
      "  RMSE: 0.3991, Bias: 0.0185, R²: 0.5897, CSI: 0.6561\n",
      "\n",
      "###### Processing month: 2020-04\n",
      " Loaded best parameters from /kaggle/input/lstm-checkpoint/best_params_2020-04.json\n",
      "\n",
      "##### Processing 2020-04, fold_1\n",
      "\n",
      "##### Processing cluster 0\n",
      "\n",
      " Evaluating cluster 0 for 2020-04, fold_1 using checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.06873939867362067 and num_layers=1\n",
      "  warnings.warn(\n",
      "<ipython-input-5-ca89ff15378e>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully loaded checkpoint from /kaggle/input/lstm-checkpoint/best_model_2020-04.pt\n",
      " Evaluating on validation set for cluster 0...\n",
      "  Val RMSE: 0.3387, Bias: -0.0670, R²: -0.1370, CSI: 0.5153\n",
      " Evaluating on test set for cluster 0...\n",
      "  Test RMSE: 0.1952, Bias: 0.1242, R²: 0.0000, CSI: 0.0000\n",
      "\n",
      "##### Processing cluster 2\n",
      "\n",
      " Evaluating cluster 2 for 2020-04, fold_1 using checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.06873939867362067 and num_layers=1\n",
      "  warnings.warn(\n",
      "<ipython-input-5-ca89ff15378e>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully loaded checkpoint from /kaggle/input/lstm-checkpoint/best_model_2020-04.pt\n",
      " Evaluating on validation set for cluster 2...\n",
      "  Val RMSE: 0.3046, Bias: 0.0293, R²: -0.2644, CSI: 0.4181\n",
      " Evaluating on test set for cluster 2...\n",
      "  Test RMSE: 0.3317, Bias: 0.1353, R²: -0.8809, CSI: 0.0000\n",
      "\n",
      "##### Processing cluster 1\n",
      "\n",
      " Evaluating cluster 1 for 2020-04, fold_1 using checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.06873939867362067 and num_layers=1\n",
      "  warnings.warn(\n",
      "<ipython-input-5-ca89ff15378e>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully loaded checkpoint from /kaggle/input/lstm-checkpoint/best_model_2020-04.pt\n",
      " Evaluating on validation set for cluster 1...\n",
      "  Val RMSE: 0.6031, Bias: -0.0714, R²: -0.0383, CSI: 0.5474\n",
      " Evaluating on test set for cluster 1...\n",
      "  Test RMSE: 0.2008, Bias: 0.1312, R²: -130.5210, CSI: 0.0096\n",
      "\n",
      "##### Processing cluster 3\n",
      "\n",
      " Evaluating cluster 3 for 2020-04, fold_1 using checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.06873939867362067 and num_layers=1\n",
      "  warnings.warn(\n",
      "<ipython-input-5-ca89ff15378e>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully loaded checkpoint from /kaggle/input/lstm-checkpoint/best_model_2020-04.pt\n",
      " Evaluating on validation set for cluster 3...\n",
      "  Val RMSE: 0.8708, Bias: -0.1536, R²: -0.0464, CSI: 0.6356\n",
      " Evaluating on test set for cluster 3...\n",
      "  Test RMSE: 0.3788, Bias: 0.1409, R²: 0.1332, CSI: 0.0285\n",
      "\n",
      " Mean test performance across clusters for 2020-04, fold_1:\n",
      "  RMSE: 0.2766, Bias: 0.1329, R²: -32.8172, CSI: 0.0095\n",
      "\n",
      "##### Processing 2020-04, fold_2\n",
      "\n",
      "##### Processing cluster 0\n",
      "\n",
      " Evaluating cluster 0 for 2020-04, fold_2 using checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.06873939867362067 and num_layers=1\n",
      "  warnings.warn(\n",
      "<ipython-input-5-ca89ff15378e>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully loaded checkpoint from /kaggle/input/lstm-checkpoint/best_model_2020-04.pt\n",
      " Evaluating on validation set for cluster 0...\n",
      "  Val RMSE: 0.7572, Bias: -0.2024, R²: 0.0820, CSI: 0.5318\n",
      " Evaluating on test set for cluster 0...\n",
      "  Test RMSE: 0.0568, Bias: 0.0328, R²: 0.0000, CSI: 0.0000\n",
      "\n",
      "##### Processing cluster 2\n",
      "\n",
      " Evaluating cluster 2 for 2020-04, fold_2 using checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.06873939867362067 and num_layers=1\n",
      "  warnings.warn(\n",
      "<ipython-input-5-ca89ff15378e>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully loaded checkpoint from /kaggle/input/lstm-checkpoint/best_model_2020-04.pt\n",
      " Evaluating on validation set for cluster 2...\n",
      "  Val RMSE: 0.5709, Bias: 0.0148, R²: -0.1996, CSI: 0.4092\n",
      " Evaluating on test set for cluster 2...\n",
      "  Test RMSE: 0.2496, Bias: 0.0298, R²: -0.0650, CSI: 0.0000\n",
      "\n",
      "##### Processing cluster 1\n",
      "\n",
      " Evaluating cluster 1 for 2020-04, fold_2 using checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.06873939867362067 and num_layers=1\n",
      "  warnings.warn(\n",
      "<ipython-input-5-ca89ff15378e>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully loaded checkpoint from /kaggle/input/lstm-checkpoint/best_model_2020-04.pt\n",
      " Evaluating on validation set for cluster 1...\n",
      "  Val RMSE: 0.8952, Bias: -0.2494, R²: 0.1583, CSI: 0.5569\n",
      " Evaluating on test set for cluster 1...\n",
      "  Test RMSE: 0.0647, Bias: 0.0381, R²: -12.6569, CSI: 0.0556\n",
      "\n",
      "##### Processing cluster 3\n",
      "\n",
      " Evaluating cluster 3 for 2020-04, fold_2 using checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.06873939867362067 and num_layers=1\n",
      "  warnings.warn(\n",
      "<ipython-input-5-ca89ff15378e>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully loaded checkpoint from /kaggle/input/lstm-checkpoint/best_model_2020-04.pt\n",
      " Evaluating on validation set for cluster 3...\n",
      "  Val RMSE: 0.8320, Bias: -0.2702, R²: 0.0992, CSI: 0.5567\n",
      " Evaluating on test set for cluster 3...\n",
      "  Test RMSE: 0.3256, Bias: 0.0186, R²: 0.3595, CSI: 0.1389\n",
      "\n",
      " Mean test performance across clusters for 2020-04, fold_2:\n",
      "  RMSE: 0.1742, Bias: 0.0298, R²: -3.0906, CSI: 0.0486\n",
      "\n",
      "##### Processing 2020-04, fold_3\n",
      "\n",
      "##### Processing cluster 0\n",
      "\n",
      " Evaluating cluster 0 for 2020-04, fold_3 using checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.06873939867362067 and num_layers=1\n",
      "  warnings.warn(\n",
      "<ipython-input-5-ca89ff15378e>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully loaded checkpoint from /kaggle/input/lstm-checkpoint/best_model_2020-04.pt\n",
      " Evaluating on validation set for cluster 0...\n",
      "  Val RMSE: 0.0457, Bias: -0.0222, R²: -0.3205, CSI: 0.0000\n",
      " Evaluating on test set for cluster 0...\n",
      "  Test RMSE: 0.0791, Bias: 0.0545, R²: 0.0000, CSI: 0.0000\n",
      "\n",
      "##### Processing cluster 2\n",
      "\n",
      " Evaluating cluster 2 for 2020-04, fold_3 using checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.06873939867362067 and num_layers=1\n",
      "  warnings.warn(\n",
      "<ipython-input-5-ca89ff15378e>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully loaded checkpoint from /kaggle/input/lstm-checkpoint/best_model_2020-04.pt\n",
      " Evaluating on validation set for cluster 2...\n",
      "  Val RMSE: 0.0453, Bias: -0.0107, R²: -0.0380, CSI: 0.0000\n",
      " Evaluating on test set for cluster 2...\n",
      "  Test RMSE: 0.2573, Bias: 0.0536, R²: -0.1320, CSI: 0.0000\n",
      "\n",
      "##### Processing cluster 1\n",
      "\n",
      " Evaluating cluster 1 for 2020-04, fold_3 using checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.06873939867362067 and num_layers=1\n",
      "  warnings.warn(\n",
      "<ipython-input-5-ca89ff15378e>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully loaded checkpoint from /kaggle/input/lstm-checkpoint/best_model_2020-04.pt\n",
      " Evaluating on validation set for cluster 1...\n",
      "  Val RMSE: 0.0383, Bias: -0.0141, R²: -0.2080, CSI: 0.0000\n",
      " Evaluating on test set for cluster 1...\n",
      "  Test RMSE: 0.0824, Bias: 0.0590, R²: -21.1496, CSI: 0.0260\n",
      "\n",
      "##### Processing cluster 3\n",
      "\n",
      " Evaluating cluster 3 for 2020-04, fold_3 using checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.06873939867362067 and num_layers=1\n",
      "  warnings.warn(\n",
      "<ipython-input-5-ca89ff15378e>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully loaded checkpoint from /kaggle/input/lstm-checkpoint/best_model_2020-04.pt\n",
      " Evaluating on validation set for cluster 3...\n",
      "  Val RMSE: 0.1427, Bias: -0.0224, R²: -0.0014, CSI: 0.2222\n",
      " Evaluating on test set for cluster 3...\n",
      "  Test RMSE: 0.3278, Bias: 0.0404, R²: 0.3508, CSI: 0.0748\n",
      "\n",
      " Mean test performance across clusters for 2020-04, fold_3:\n",
      "  RMSE: 0.1866, Bias: 0.0519, R²: -5.2327, CSI: 0.0252\n",
      "\n",
      "##### Processing 2020-04, fold_4\n",
      "\n",
      "##### Processing cluster 0\n",
      "\n",
      " Evaluating cluster 0 for 2020-04, fold_4 using checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.06873939867362067 and num_layers=1\n",
      "  warnings.warn(\n",
      "<ipython-input-5-ca89ff15378e>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully loaded checkpoint from /kaggle/input/lstm-checkpoint/best_model_2020-04.pt\n",
      " Evaluating on validation set for cluster 0...\n",
      "  Val RMSE: 0.3240, Bias: 0.0921, R²: -17.4141, CSI: 0.0538\n",
      " Evaluating on test set for cluster 0...\n",
      "  Test RMSE: 0.0915, Bias: 0.0666, R²: 0.0000, CSI: 0.0000\n",
      "\n",
      "##### Processing cluster 2\n",
      "\n",
      " Evaluating cluster 2 for 2020-04, fold_4 using checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.06873939867362067 and num_layers=1\n",
      "  warnings.warn(\n",
      "<ipython-input-5-ca89ff15378e>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully loaded checkpoint from /kaggle/input/lstm-checkpoint/best_model_2020-04.pt\n",
      " Evaluating on validation set for cluster 2...\n",
      "  Val RMSE: 0.1517, Bias: 0.0475, R²: -9.5100, CSI: 0.0000\n",
      " Evaluating on test set for cluster 2...\n",
      "  Test RMSE: 0.2627, Bias: 0.0668, R²: -0.1805, CSI: 0.0000\n",
      "\n",
      "##### Processing cluster 1\n",
      "\n",
      " Evaluating cluster 1 for 2020-04, fold_4 using checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.06873939867362067 and num_layers=1\n",
      "  warnings.warn(\n",
      "<ipython-input-5-ca89ff15378e>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully loaded checkpoint from /kaggle/input/lstm-checkpoint/best_model_2020-04.pt\n",
      " Evaluating on validation set for cluster 1...\n",
      "  Val RMSE: 0.5855, Bias: 0.0496, R²: -0.4401, CSI: 0.0472\n",
      " Evaluating on test set for cluster 1...\n",
      "  Test RMSE: 0.0925, Bias: 0.0701, R²: -26.8751, CSI: 0.0214\n",
      "\n",
      "##### Processing cluster 3\n",
      "\n",
      " Evaluating cluster 3 for 2020-04, fold_4 using checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.06873939867362067 and num_layers=1\n",
      "  warnings.warn(\n",
      "<ipython-input-5-ca89ff15378e>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully loaded checkpoint from /kaggle/input/lstm-checkpoint/best_model_2020-04.pt\n",
      " Evaluating on validation set for cluster 3...\n",
      "  Val RMSE: 0.3395, Bias: 0.0488, R²: -0.7229, CSI: 0.0538\n",
      " Evaluating on test set for cluster 3...\n",
      "  Test RMSE: 0.3296, Bias: 0.0524, R²: 0.3439, CSI: 0.0601\n",
      "\n",
      " Mean test performance across clusters for 2020-04, fold_4:\n",
      "  RMSE: 0.1941, Bias: 0.0640, R²: -6.6779, CSI: 0.0204\n",
      "\n",
      "##### Processing 2020-04, fold_5\n",
      "\n",
      "##### Processing cluster 0\n",
      "\n",
      " Evaluating cluster 0 for 2020-04, fold_5 using checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.06873939867362067 and num_layers=1\n",
      "  warnings.warn(\n",
      "<ipython-input-5-ca89ff15378e>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully loaded checkpoint from /kaggle/input/lstm-checkpoint/best_model_2020-04.pt\n",
      " Evaluating on validation set for cluster 0...\n",
      "  Val RMSE: 0.8968, Bias: -0.2741, R²: -0.0979, CSI: 0.6339\n",
      " Evaluating on test set for cluster 0...\n",
      "  Test RMSE: 0.0912, Bias: 0.0664, R²: 0.0000, CSI: 0.0000\n",
      "\n",
      "##### Processing cluster 2\n",
      "\n",
      " Evaluating cluster 2 for 2020-04, fold_5 using checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.06873939867362067 and num_layers=1\n",
      "  warnings.warn(\n",
      "<ipython-input-5-ca89ff15378e>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully loaded checkpoint from /kaggle/input/lstm-checkpoint/best_model_2020-04.pt\n",
      " Evaluating on validation set for cluster 2...\n",
      "  Val RMSE: 1.1554, Bias: -0.2639, R²: 0.0003, CSI: 0.4609\n",
      " Evaluating on test set for cluster 2...\n",
      "  Test RMSE: 0.2627, Bias: 0.0666, R²: -0.1799, CSI: 0.0000\n",
      "\n",
      "##### Processing cluster 1\n",
      "\n",
      " Evaluating cluster 1 for 2020-04, fold_5 using checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.06873939867362067 and num_layers=1\n",
      "  warnings.warn(\n",
      "<ipython-input-5-ca89ff15378e>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully loaded checkpoint from /kaggle/input/lstm-checkpoint/best_model_2020-04.pt\n",
      " Evaluating on validation set for cluster 1...\n",
      "  Val RMSE: 1.1182, Bias: -0.2996, R²: 0.0801, CSI: 0.6317\n",
      " Evaluating on test set for cluster 1...\n",
      "  Test RMSE: 0.0923, Bias: 0.0699, R²: -26.7671, CSI: 0.0219\n",
      "\n",
      "##### Processing cluster 3\n",
      "\n",
      " Evaluating cluster 3 for 2020-04, fold_5 using checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.06873939867362067 and num_layers=1\n",
      "  warnings.warn(\n",
      "<ipython-input-5-ca89ff15378e>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully loaded checkpoint from /kaggle/input/lstm-checkpoint/best_model_2020-04.pt\n",
      " Evaluating on validation set for cluster 3...\n",
      "  Val RMSE: 0.8308, Bias: -0.2924, R²: -0.1482, CSI: 0.7056\n",
      " Evaluating on test set for cluster 3...\n",
      "  Test RMSE: 0.3295, Bias: 0.0522, R²: 0.3442, CSI: 0.0608\n",
      "\n",
      " Mean test performance across clusters for 2020-04, fold_5:\n",
      "  RMSE: 0.1939, Bias: 0.0638, R²: -6.6507, CSI: 0.0207\n",
      "\n",
      " Best fold for 2020-04: fold_2\n",
      "  RMSE: 0.1742, Bias: 0.0298, R²: -3.0906, CSI: 0.0486\n",
      "\n",
      "###### Processing month: 2020-10\n",
      " Loaded best parameters from /kaggle/input/lstm-checkpoint/best_params_2020-10.json\n",
      "\n",
      "##### Processing 2020-10, fold_1\n",
      "\n",
      "##### Processing cluster 0\n",
      "\n",
      " Evaluating cluster 0 for 2020-10, fold_1 using checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-ca89ff15378e>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully loaded checkpoint from /kaggle/input/lstm-checkpoint/best_model_2020-10.pt\n",
      " Evaluating on validation set for cluster 0...\n",
      "  Val RMSE: 0.5074, Bias: 0.0689, R²: 0.8635, CSI: 0.6844\n",
      " Evaluating on test set for cluster 0...\n",
      "  Test RMSE: 0.8089, Bias: 0.1018, R²: 0.8522, CSI: 0.7280\n",
      "\n",
      "##### Processing cluster 2\n",
      "\n",
      " Evaluating cluster 2 for 2020-10, fold_1 using checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-ca89ff15378e>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully loaded checkpoint from /kaggle/input/lstm-checkpoint/best_model_2020-10.pt\n",
      " Evaluating on validation set for cluster 2...\n",
      "  Val RMSE: 0.4379, Bias: 0.0637, R²: 0.6651, CSI: 0.4786\n",
      " Evaluating on test set for cluster 2...\n",
      "  Test RMSE: 0.4735, Bias: 0.0711, R²: 0.7325, CSI: 0.5844\n",
      "\n",
      "##### Processing cluster 1\n",
      "\n",
      " Evaluating cluster 1 for 2020-10, fold_1 using checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-ca89ff15378e>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully loaded checkpoint from /kaggle/input/lstm-checkpoint/best_model_2020-10.pt\n",
      " Evaluating on validation set for cluster 1...\n",
      "  Val RMSE: 0.5098, Bias: 0.0309, R²: 0.8165, CSI: 0.7803\n",
      " Evaluating on test set for cluster 1...\n",
      "  Test RMSE: 0.6191, Bias: 0.0492, R²: 0.8338, CSI: 0.7938\n",
      "\n",
      "##### Processing cluster 3\n",
      "\n",
      " Evaluating cluster 3 for 2020-10, fold_1 using checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-ca89ff15378e>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully loaded checkpoint from /kaggle/input/lstm-checkpoint/best_model_2020-10.pt\n",
      " Evaluating on validation set for cluster 3...\n",
      "  Val RMSE: 0.9689, Bias: -0.0079, R²: 0.8082, CSI: 0.7429\n",
      " Evaluating on test set for cluster 3...\n",
      "  Test RMSE: 1.5566, Bias: -0.1246, R²: 0.7580, CSI: 0.8314\n",
      "\n",
      " Mean test performance across clusters for 2020-10, fold_1:\n",
      "  RMSE: 0.8645, Bias: 0.0244, R²: 0.7941, CSI: 0.7344\n",
      "\n",
      "##### Processing 2020-10, fold_2\n",
      "\n",
      "##### Processing cluster 0\n",
      "\n",
      " Evaluating cluster 0 for 2020-10, fold_2 using checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-ca89ff15378e>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully loaded checkpoint from /kaggle/input/lstm-checkpoint/best_model_2020-10.pt\n",
      " Evaluating on validation set for cluster 0...\n",
      "  Val RMSE: 0.5619, Bias: 0.0969, R²: 0.8703, CSI: 0.6482\n",
      " Evaluating on test set for cluster 0...\n",
      "  Test RMSE: 0.8576, Bias: 0.1022, R²: 0.8473, CSI: 0.7774\n",
      "\n",
      "##### Processing cluster 2\n",
      "\n",
      " Evaluating cluster 2 for 2020-10, fold_2 using checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-ca89ff15378e>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully loaded checkpoint from /kaggle/input/lstm-checkpoint/best_model_2020-10.pt\n",
      " Evaluating on validation set for cluster 2...\n",
      "  Val RMSE: 0.5516, Bias: 0.0898, R²: 0.6224, CSI: 0.4830\n",
      " Evaluating on test set for cluster 2...\n",
      "  Test RMSE: 0.2165, Bias: 0.0648, R²: 0.4301, CSI: 0.5136\n",
      "\n",
      "##### Processing cluster 1\n",
      "\n",
      " Evaluating cluster 1 for 2020-10, fold_2 using checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-ca89ff15378e>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully loaded checkpoint from /kaggle/input/lstm-checkpoint/best_model_2020-10.pt\n",
      " Evaluating on validation set for cluster 1...\n",
      "  Val RMSE: 0.7941, Bias: 0.0364, R²: 0.7463, CSI: 0.7389\n",
      " Evaluating on test set for cluster 1...\n",
      "  Test RMSE: 0.7465, Bias: 0.0430, R²: 0.8450, CSI: 0.8281\n",
      "\n",
      "##### Processing cluster 3\n",
      "\n",
      " Evaluating cluster 3 for 2020-10, fold_2 using checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-ca89ff15378e>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully loaded checkpoint from /kaggle/input/lstm-checkpoint/best_model_2020-10.pt\n",
      " Evaluating on validation set for cluster 3...\n",
      "  Val RMSE: 1.3064, Bias: -0.1057, R²: 0.7691, CSI: 0.7339\n",
      " Evaluating on test set for cluster 3...\n",
      "  Test RMSE: 1.3929, Bias: -0.1248, R²: 0.7768, CSI: 0.8137\n",
      "\n",
      " Mean test performance across clusters for 2020-10, fold_2:\n",
      "  RMSE: 0.8034, Bias: 0.0213, R²: 0.7248, CSI: 0.7332\n",
      "\n",
      "##### Processing 2020-10, fold_3\n",
      "\n",
      "##### Processing cluster 0\n",
      "\n",
      " Evaluating cluster 0 for 2020-10, fold_3 using checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-ca89ff15378e>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully loaded checkpoint from /kaggle/input/lstm-checkpoint/best_model_2020-10.pt\n",
      " Evaluating on validation set for cluster 0...\n",
      "  Val RMSE: 0.8036, Bias: 0.0957, R²: 0.8151, CSI: 0.7173\n",
      " Evaluating on test set for cluster 0...\n",
      "  Test RMSE: 0.5153, Bias: 0.1235, R²: 0.7867, CSI: 0.7159\n",
      "\n",
      "##### Processing cluster 2\n",
      "\n",
      " Evaluating cluster 2 for 2020-10, fold_3 using checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-ca89ff15378e>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully loaded checkpoint from /kaggle/input/lstm-checkpoint/best_model_2020-10.pt\n",
      " Evaluating on validation set for cluster 2...\n",
      "  Val RMSE: 0.3829, Bias: 0.0931, R²: 0.7329, CSI: 0.4718\n",
      " Evaluating on test set for cluster 2...\n",
      "  Test RMSE: 0.1726, Bias: 0.0691, R²: 0.3489, CSI: 0.4648\n",
      "\n",
      "##### Processing cluster 1\n",
      "\n",
      " Evaluating cluster 1 for 2020-10, fold_3 using checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-ca89ff15378e>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully loaded checkpoint from /kaggle/input/lstm-checkpoint/best_model_2020-10.pt\n",
      " Evaluating on validation set for cluster 1...\n",
      "  Val RMSE: 0.7019, Bias: 0.0539, R²: 0.8566, CSI: 0.8104\n",
      " Evaluating on test set for cluster 1...\n",
      "  Test RMSE: 0.4109, Bias: 0.0871, R²: 0.5690, CSI: 0.7382\n",
      "\n",
      "##### Processing cluster 3\n",
      "\n",
      " Evaluating cluster 3 for 2020-10, fold_3 using checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-ca89ff15378e>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully loaded checkpoint from /kaggle/input/lstm-checkpoint/best_model_2020-10.pt\n",
      " Evaluating on validation set for cluster 3...\n",
      "  Val RMSE: 1.6815, Bias: -0.1209, R²: 0.7012, CSI: 0.7776\n",
      " Evaluating on test set for cluster 3...\n",
      "  Test RMSE: 1.2389, Bias: -0.0699, R²: 0.7697, CSI: 0.8178\n",
      "\n",
      " Mean test performance across clusters for 2020-10, fold_3:\n",
      "  RMSE: 0.5844, Bias: 0.0524, R²: 0.6186, CSI: 0.6842\n",
      "\n",
      "##### Processing 2020-10, fold_4\n",
      "\n",
      "##### Processing cluster 0\n",
      "\n",
      " Evaluating cluster 0 for 2020-10, fold_4 using checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-ca89ff15378e>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully loaded checkpoint from /kaggle/input/lstm-checkpoint/best_model_2020-10.pt\n",
      " Evaluating on validation set for cluster 0...\n",
      "  Val RMSE: 0.6335, Bias: 0.0798, R²: 0.8917, CSI: 0.7240\n",
      " Evaluating on test set for cluster 0...\n",
      "  Test RMSE: 0.2133, Bias: 0.0895, R²: 0.6456, CSI: 0.6592\n",
      "\n",
      "##### Processing cluster 2\n",
      "\n",
      " Evaluating cluster 2 for 2020-10, fold_4 using checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-ca89ff15378e>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully loaded checkpoint from /kaggle/input/lstm-checkpoint/best_model_2020-10.pt\n",
      " Evaluating on validation set for cluster 2...\n",
      "  Val RMSE: 0.2601, Bias: 0.0767, R²: 0.4494, CSI: 0.4147\n",
      " Evaluating on test set for cluster 2...\n",
      "  Test RMSE: 0.1501, Bias: 0.0678, R²: 0.2774, CSI: 0.3835\n",
      "\n",
      "##### Processing cluster 1\n",
      "\n",
      " Evaluating cluster 1 for 2020-10, fold_4 using checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-ca89ff15378e>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully loaded checkpoint from /kaggle/input/lstm-checkpoint/best_model_2020-10.pt\n",
      " Evaluating on validation set for cluster 1...\n",
      "  Val RMSE: 1.0152, Bias: -0.0006, R²: 0.6924, CSI: 0.7439\n",
      " Evaluating on test set for cluster 1...\n",
      "  Test RMSE: 0.1976, Bias: 0.0614, R²: 0.8297, CSI: 0.7011\n",
      "\n",
      "##### Processing cluster 3\n",
      "\n",
      " Evaluating cluster 3 for 2020-10, fold_4 using checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-ca89ff15378e>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully loaded checkpoint from /kaggle/input/lstm-checkpoint/best_model_2020-10.pt\n",
      " Evaluating on validation set for cluster 3...\n",
      "  Val RMSE: 1.8055, Bias: -0.1843, R²: 0.6795, CSI: 0.8181\n",
      " Evaluating on test set for cluster 3...\n",
      "  Test RMSE: 0.8991, Bias: 0.0136, R²: 0.7675, CSI: 0.8044\n",
      "\n",
      " Mean test performance across clusters for 2020-10, fold_4:\n",
      "  RMSE: 0.3650, Bias: 0.0581, R²: 0.6300, CSI: 0.6370\n",
      "\n",
      "##### Processing 2020-10, fold_5\n",
      "\n",
      "##### Processing cluster 0\n",
      "\n",
      " Evaluating cluster 0 for 2020-10, fold_5 using checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-ca89ff15378e>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully loaded checkpoint from /kaggle/input/lstm-checkpoint/best_model_2020-10.pt\n",
      " Evaluating on validation set for cluster 0...\n",
      "  Val RMSE: 0.5907, Bias: 0.0963, R²: 0.6238, CSI: 0.6265\n",
      " Evaluating on test set for cluster 0...\n",
      "  Test RMSE: 0.1716, Bias: 0.0744, R²: 0.8353, CSI: 0.6439\n",
      "\n",
      "##### Processing cluster 2\n",
      "\n",
      " Evaluating cluster 2 for 2020-10, fold_5 using checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-ca89ff15378e>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully loaded checkpoint from /kaggle/input/lstm-checkpoint/best_model_2020-10.pt\n",
      " Evaluating on validation set for cluster 2...\n",
      "  Val RMSE: 0.2312, Bias: 0.0583, R²: 0.5093, CSI: 0.4409\n",
      " Evaluating on test set for cluster 2...\n",
      "  Test RMSE: 0.2137, Bias: 0.0783, R²: -0.1077, CSI: 0.3783\n",
      "\n",
      "##### Processing cluster 1\n",
      "\n",
      " Evaluating cluster 1 for 2020-10, fold_5 using checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-ca89ff15378e>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Successfully loaded checkpoint from /kaggle/input/lstm-checkpoint/best_model_2020-10.pt\n",
      " Evaluating on validation set for cluster 1...\n",
      "  Val RMSE: 0.5491, Bias: 0.0713, R²: 0.7199, CSI: 0.6839\n",
      " Evaluating on test set for cluster 1...\n",
      "  Test RMSE: 0.1953, Bias: 0.0613, R²: 0.8744, CSI: 0.7149\n",
      "\n",
      "##### Processing cluster 3\n",
      "\n",
      " Evaluating cluster 3 for 2020-10, fold_5 using checkpoint\n",
      " Successfully loaded checkpoint from /kaggle/input/lstm-checkpoint/best_model_2020-10.pt\n",
      " Evaluating on validation set for cluster 3...\n",
      "  Val RMSE: 1.7074, Bias: -0.3005, R²: 0.6417, CSI: 0.8255\n",
      " Evaluating on test set for cluster 3...\n",
      "  Test RMSE: 0.6467, Bias: 0.0535, R²: 0.7158, CSI: 0.7916\n",
      "\n",
      " Mean test performance across clusters for 2020-10, fold_5:\n",
      "  RMSE: 0.3068, Bias: 0.0669, R²: 0.5795, CSI: 0.6322\n",
      "\n",
      " Best fold for 2020-10: fold_5\n",
      "  RMSE: 0.3068, Bias: 0.0669, R²: 0.5794, CSI: 0.6322\n",
      "\n",
      " All cluster results saved to lstm_cluster_results.csv\n",
      " Best fold results per month saved to lstm_best_fold_per_month.csv\n",
      "\n",
      " Overall mean performance across best folds of all months:\n",
      "  RMSE: 0.4832, Bias: 0.0048, R²: -0.4765, CSI: 0.3685\n",
      "\n",
      " Best Fold Results by Month:\n",
      "     month    fold  mean_test_rmse  mean_test_bias  mean_test_r  \\\n",
      "0  2019-04  fold_4          1.0529         -0.0959       0.0156   \n",
      "1  2019-10  fold_1          0.3991          0.0185       0.5897   \n",
      "2  2020-04  fold_2          0.1742          0.0298      -3.0906   \n",
      "3  2020-10  fold_5          0.3068          0.0669       0.5794   \n",
      "\n",
      "   mean_test_csi  num_clusters  \n",
      "0         0.1373             4  \n",
      "1         0.6561             4  \n",
      "2         0.0486             4  \n",
      "3         0.6322             4  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-ca89ff15378e>:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path))\n"
     ]
    }
   ],
   "source": [
    "run_cluster_evaluation_from_checkpoint()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7091976,
     "sourceId": 11340032,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7117290,
     "sourceId": 11369580,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7142988,
     "sourceId": 11403913,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6984394,
     "sourceId": 11443624,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7173004,
     "sourceId": 11448922,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7186553,
     "sourceId": 11467955,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 384.038939,
   "end_time": "2025-05-06T17:23:04.626423",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-06T17:16:40.587484",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
